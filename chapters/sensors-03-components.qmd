# Components {#sec-sensors-components}

In addition to the photodiode and underlying circuitry, CMOS image sensors incorporate several crucial optical components that play a vital role in capturing high-quality images. These elements -color filter arrays and microlens arrays- are engineered to enhance light collection and enable accurate color reproduction, making them essential for modern imaging performance.

![The color filter array and microlens array above the photodiode array. Not sure where.  Lookup.](images/sensors/03-components-overview1.png){#fig-components-overview width=50%}

To make a color image, sensors use a color filter array (CFA) placed above the photodiodes. Since a photodiode alone cannot distinguish between different wavelengths, the CFA ensures that each pixel is sensitive to a specific spectral band. The most common CFA pattern is the Bayer arrangement, which uses red, green, and blue filters distributed across the sensor. This allows the sensor to sample the visible spectrum at different locations, and the resulting data can be combined to reconstruct a full-color image. Some sensors use alternative filter patterns or additional spectral bands for specialized applications. Together, microlens arrays and color filter arrays are essential for the function and versatility of modern digital cameras.

The original sensors were  built using a technology that required stacking multiple metal layers above the substrate that contained the photodiode. This architecture, called front-side illuminated (FSI), required photons incident at the pixel to make their way down a tunnel to arrive at the light sensitive photodiode. With this architecture, photons incident at an angle This  shown 

![The improved design, Backside Illuminated (BSI) CMOS, is similar in concept to regular CMOS, but these chips arrange the components differently. In short, the photosites are further forward on the die and the line-by-line readout speed is brisker. This change enables practical advantages: Generally speaking, a BSI CMOS is around an f-stop better when it comes to image noise. That means a BSI CMOS shows as much noise at ISO 12800 as a similar CMOS chip would at ISO 6400. It also means that APS-C and Micro Four Thirds cameras with BSI chips play on more even footing with full-frame CMOS cameras. Those aren't hard-and-fast rules, but they're good guidelines to follow. Stacked CMOS chips improve upon the BSI CMOS concept. They place components in a similar arrangement, but the design also stacks the image signal processor and its ultra-fast DRAM memory into the same silicon. This makes readout speeds even faster. The first mainstream Stacked CMOS camera, the Sony a9 from 2019, made waves by offering an interruption-free photographic experienceâ€”you can use it to fire off photos at 20fps without losing view of your scene.](images/sensors/03-sensor-evolution.png){#fig-sensor-evolution width=80%}

<!--# https://www.pcmag.com/how-to/whats-the-difference-between-cmos-bsi-cmos-and-stacked-cmos -->

![The color filter array and microlens array above the photodiode array. From the El Gamal and Eltoukhy article](images/sensors/03-microlens-cfa.png){#fig-components-overview2 width=50%}

The microlens array is a layer of tiny lenses placed above the color filter array. Each microlens is precisely positioned relative to the main lens, color filter, and photodiode. It serves to focus incoming light from the main lens onto the photodiode within the pixel. The microlens increases light-gathering efficiency, which is especially important as pixel sizes shrink. It also prevents cross-talk, a condition in which light passes at a large angle through a color filter and ends up generating electrons in a pixel that has a different color filter. Over time, microlens arrays have evolved to support additional functions, such as optimizing focus and enabling advanced imaging techniques like light field capture.

### Color filter array

### Microlens arrays

Light field possibility.