# Transform domain {#sec-optics-linear-harmonics}
We have mainly been analyzingd optical systems using point-based stimuli (impulses and point spread functions). This is one of many useful signal representations (@sec-appendix-linear-systems). In this section, we introduce a second class of stimuli: image harmonics. These stimuli are commonly used in the image systems engineering literature for both theory and measurement. They provide a valuable and insightful approach to measuring how image systems behave.

There are two practical motivations for considering alternative stimuli. First, point stimuli are not convenient tool for predicting how finely a system can resolve detail; the spatial resolution of an image system is often easier to analyze using harmonics. Second, point stimuli are photon-inefficient and thus difficult to measure precisely. Extended harmonic targets deliver more light, produce higher signal-to-noise measurements, and allow precise control of spatial frequency, orientation, and phase.

The next sections define image harmonics and show how to use them to characterize system performance. The mathematical foundations underpinning this representation appear in @sec-appendix-linear-systems and @sec-appendix-spaceinvariance. In brief: for linear, space-invariant systems, harmonics form a spatial basis for arbitrary stimuli (@sec-ls-spatial-basis) and are nearly eigenfunctions of the system (@sec-ls-eigenfunctions). These properties make harmonics especially valuable for analysis and design.

## Image harmonics {#sec-optics-harmonics}
For real-valued signals —such as light intensity— the harmonics are built upon the sine and cosine functions. You likely first met these as one-dimensional functions: they take a single input and produce a single output that varies from $[-1,1]$.

$$
I(x) = \sin(2\pi f_x x + \phi_x)
$${#eq-harmonics-1d}

Here, $f_x$ is the spatial frequency (in cycles per unit distance) and $\phi_x$ is the phase (a spatial shift).  Image intensities are positive numbers, so to model them with harmonics we add $1$ to the value.

$$
I(x) = 1 + \sin(2\pi f_x x + \phi_x)
$${#eq-harmonics-1d-v2}

In imaging, we typically need a two-dimensional representation to describe variation across both $x$ and $y$. A useful form that keeps intensities non-negative and includes two dimensions is

$$
I(x,y) = M\big(1 + A \sin(2\pi f_x x + \phi_x + 2\pi f_y y + \phi_y)\big).
$${#eq-harmonics-2d}

- $M$ is the mean (DC) intensity.
- $A$ is the contrast or modulation depth. To ensure $I(x,y) \ge 0$, we require $|A| \le 1$. In practice, we often take $A \in [0,1]$ and absorb any sign into the phase.
- The pair $(f_x, f_y)$ is the 2D spatial frequency. When both are nonzero, the pattern has an orientation; the bars are perpendicular to the vector $(f_x, f_y)$, with angle $\theta = \mathrm{atan2}(f_y, f_x)$.

@fig-optics-harmonics-2d shows four image harmonics. When $f_y = 0$ the pattern is vertical (varies only along $x$); when $f_x = 0$ it is horizontal (varies only along $y$).[^spatial-frequency]

[^spatial-frequency]: Different fields use different terminology. Vision scientists often call these spatial frequency gratings. Engineers sometimes approximate sinusoidal patterns with evenly spaced bars or lines. We use the term harmonics.

![Harmonic images. These have different $f_x$ and $f_y$ values, but all have contrast $A=1$. The image is vertical if $f_y = 0$ and horizontal if $f_x = 0$.](images/optics/optics-harmonics.png){#fig-optics-harmonics-2d width="80%"}

For many linear-systems analyses, say when the system is circularly symmetric, it is enough to consider one-dimensional harmonics by fixing $f_y = 0$. The examples in @fig-optics-harmonics-1d vary only along $x$ and illustrate different spatial frequencies $f_x$ and contrasts $A$.

![A set of one-dimensional image harmonics. They vary in $x$ with $f_y = 0$. The contrast $A$ varies from top to bottom $(1, 0.5, 0.1)$. The $x$-range is $(0,1)$, and the spatial frequencies are $f_x = (1, 2, 4, 8)$.](images/optics/optics-harmonics-1d.png){#fig-optics-harmonics-1d width="60%"}

## Harmonics and lines {#eq-optics-harmonics-lines}
To many people it is counterintuitive that a thin line can be constructed by summing harmonics. The line is very compact, but each harmonic extends across the entire image. How can the sum of these harmonics functions result in such a localized image?

@fig-optics-reconstruction shows how the image evolves as we sum increasing numbers of harmonics: Starting with just a few, the result is broad and diffuse, but as more harmonics are added, the image becomes increasingly concentrated. The key is that the positive and negative regions of the higher frequency harmonics cancel each other out everywhere except at the center, where all the cosine terms are positive ($\cos(0)$). With enough harmonics, the sum converges to a single, sharp line.

In this example, we reconstruct a line at the center (column 65) of a 129-column image by setting all harmonic weights to $w_f = 1$. Because the target image is even symmetric, only the cosine terms are needed. The red traces in the figure show the intensity profile: as more harmonics are added, the central peak narrows and side ripples diminish. By the 64th harmonic, the line is well-formed; adding more harmonics briefly reintroduces some ringing, which disappears when the full set is included. This phenomenon is a classic result in linear systems—ask your instructor for more details!

![Summing harmonics to become a line. The panels show the sum of the first 4, 16, 64, 72, and finally all 128 harmonics. To match a single line in the middle (col=65) of this 129 column image, the weights of each harmonic are all $w_f = 1$. Because the image is even symmetric, we need to sum only the $cos()$ terms. The red traces superimposed on the images are the intensity. The central region becomes thinner and the ripples on the side are eliminated by the 64th harmonic.  They return as we keep going to f = 72, but are eliminated again at f=128.  Ask your linear systems instructor about this; s/he will like you for it.](images/optics/optics-reconstruction.png){#fig-optics-reconstruction width="100%"}

::: {.callout-note collapse="false" title="Line reconstruction: the movie"}
This movie illustrates how the sum converges as harmonics are added one by one. Initially, the harmonics are distributed across the image. As more are included, their contributions cancel everywhere except at the central position ($0$), where all are positive ($\cos(0)$). 

Adding harmonics from $f=0$ to $f=64$ produces the line; adding $f=65$ to $f=128$ introduces some ringing, which is eliminated when the sum is complete. This is a special case for even symmetric functions, where only cosines are required.

![Video showing a line reconstructed as we add harmonics (cosines) at different frequencies. I only added the contrast terms, keeping the mean the same. See [fise_harmonicsLine](../code/02Optics/fise_harmonicsLine.html). ](images/optics/lineReconstruct.mp4){#fig-optics-reconstruction-movie width="60%" fig-align="center"}

:::

## Harmonic characterization {#sec-optics-characterization}
There are many reasons why people would like to describe the quality of an optical system.  Commercial vendors that sell parts may need to specify the quality and the tolerance of the quality measure.  We may want to optimize the properties of a design, using the image quality measure as a metric for the optimization.  We may wish to simulate the system and learn which signals are preserved by the optics and which are lost to image quality.

The point spread function characterizes the system using many values measured from a single stimulus. The harmonic characterization uses only two parameters, but from multiple stimuli (@fig-optics-harmonic-eigen).  For each harmonic frequency, we measure how much its amplitude is scaled, $s(\mathbf{f})$, and how much the image has been shifted $\phi(\mathbf{f})$.

![A shift invariant linear system transforms a one-dimensional image harmonic into a harmonic image of the same frequency. The output differs by a scale factor and a spatial shift (phase).  The mean levels of the input $M_i$ and output $M_o$ differ by a scale factor, as well. [fise_harmonicsLine.m]()](images/optics/harmonics-eigen.png){#fig-optics-harmonic-eigen width=70%}

## Transfer Functions {#sec-optics-transfer-function}
For a linear, space-invariant system, the effect of the optics on any harmonic stimulus is simple: the output is also a harmonic of the same frequency, but its amplitude is scaled and its phase is shifted. There is a small collection of **transfer functions** that serve as useful, compact mathematical descriptions of this scaling and shifting across all spatial frequencies.

### Optical Transfer Function {#sec-OTF}
The **optical transfer function (OTF)** describes the complete effect of a space-invariant optical system on an image. It is a complex-valued function that captures both the amplitude scaling and phase shift for every spatial frequency, $\mathbf{f}$.

$$
\mathrm{OTF}(\mathbf{f}) = s(\mathbf{f}) \cdot e^{-i \phi(\mathbf{f})}
$${#eq-otf-definition}

Here, $s(\mathbf{f})$ is the real-valued amplitude scaling factor, and $\phi(\mathbf{f})$ is the phase shift (in radians).

The OTF provides a powerful way to predict the system's output. Using the convolution theorem (@sec-ls-convolution-theorem), we can calculate the output image, $O(x,y)$, by multiplying the Fourier transform of the input image, $I(x,y)$, with the OTF and then taking the inverse Fourier transform:

$$
O(x,y) = \mathscr{F}^{-1}\big(\mathscr{F}\{I(x,y)\} \cdot \mathrm{OTF}(\mathbf{f})\big)
$${#eq-otf-calculation}

Just like the point spread function, the OTF completely characterizes a linear, space-invariant system. In fact, the OTF is the Fourier transform of the point spread function.

### Modulation Transfer Function {#sec-MTF}
Many times we are primarily interested in how the system affects the contrast (or modulation) of the input harmonics, without regard to the phase shift. This information is captured by the **modulation transfer function (MTF)**. 

$$
\mathrm{MTF}(\mathbf{f}) = s(\mathbf{f})
$${#eq-MTF-defined}

The MTF is a real-valued, non-negative function. For many optical systems, particularly those with symmetric point spread functions, the phase shifts are negligible ($\delta_\mathbf{f} \approx 0$). In these common cases, the OTF is approximately equal to the MTF.

@fig-optics-harmonics-mtf illustrates the effect of the MTF. An input image with a sweep of spatial frequencies (top) is passed through an optical system. The output image (bottom) shows that the contrast of the high-frequency patterns is significantly reduced, a direct visualization of the MTF's attenuation of higher frequencies.

![A sweep frequency pattern demonstrates the MTF. The input (top) has uniform contrast across all frequencies. The output (bottom) shows reduced contrast at higher frequencies, as described by the system's MTF. This simulation is for a diffraction-limited lens with an f-number of 4 at a wavelength of 550 nm. [See fise_opticsMTF.m](../code/02Optics/fise_opticsMTF.html){target=_blank}](images/optics/harmonics-mtf.png){#fig-optics-harmonics-mtf width=90%}

### Phase Transformation Function {#sec-PTF}
It is always good to check the phase term, as well.  The phase shift (in radians) as a function of frequency is called the **phase transfer function (PTF)** and it is simply

$$
\mathrm{PTF}(\mathbf{f}) = \phi(\mathbf{f})
$$ {#eq-phasetransform-definition}

Putting these terms together, we have simply

$$
\mathrm{OTF}(\mathbf{f}) 
= \mathrm{MTF}(\mathbf{f}) \, e^{\,i \, \mathrm{PTF}(\mathbf{f})} .
$$ {#eq-otf-ptf-mtf}

### The OTF and PSF

In which we explain that the PSF and the OTF are related by a Fourier Transform.

### Contrast Sensitivity Function {#sec-CSF}
For some systems, we cannot directly measure the output signal. The human visual system is a prime example: we can ask a person what they see, but we cannot easily measure the neural response at the retina or in the cortex. This "black box" problem is common in many fields.

A clever way to characterize such systems is to measure the input required to produce a constant, predefined output. This general approach is known by various names: "input-referred measurement" in engineering, "action spectrum" in photobiology, and "Type A" experiments in physiology (@brindley1970-book).

In vision science, this method is used to define the **contrast sensitivity function (CSF)**. To measure the CSF, an observer is shown a harmonic pattern of a specific frequency, and the contrast is adjusted until the pattern is just barely visible (at the detection threshold). This process is repeated for many different spatial frequencies.

The contrast sensitivity for a given frequency, $\mathbf{f}$, is defined as the reciprocal of the threshold contrast, $A_\mathbf{f}$:

$$
\mathrm{CSF}(\mathbf{f}) = \frac{1}{A_\mathbf{f}}
$$

For example, if a low-frequency pattern is detectable at 1% contrast ($A=0.01$), the contrast sensitivity is $1/0.01 = 100$. If a high-frequency pattern requires 10% contrast ($A=0.10$) to be seen, its sensitivity is $1/0.10 = 10$. The CSF curve plots this sensitivity across all spatial frequencies, providing a comprehensive characterization of the visual system's ability to perceive spatial detail. This same principle can be applied to characterize the end-to-end performance of a complete camera system, from optics to final processed image.

## Two-dimensional Fourier Transforms representation

Start an image of the 2D FFT amplitude, perhaps.  

Get to image representations of the harmonic images.

Parts of the Fourier representation (center, edges, and so forth)

### High frequency fall off.


### Develop the ISO 12233 standard, relating edges and MTF50

Not sure we introduce it here or in sensors.

Maybe we illustrate it here in the abstract and then again when we get to the sensors, later.

### Spatial aliasing

Not sure we introduce it here or in sensors.

Maybe we illustrate it here in the abstract and then again when we get to the sensors, later.

### Separability 
One of the more interesting features of mathematical reasoning is the fact that there are properties present in higher dimensional analyses that have no counterpart in lower dimensions. A very simple, but important, example is the property of **separability**.  

$$
F(x,y) = f(x) g(y)
$$ {#eq-separability-definition}

:::{.callout-note title='2D Fourier Transforms' collapse='false'}
Bracewell and Goodman for introducing the 2D Fourier transform for image applications.

[Link to Google resource.](resources/history-2D-fourier-transform.html){target=_blank}

:::
