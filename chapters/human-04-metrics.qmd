---
date: last-modified
---

# Human visual metrics {#sec-human-metrics}
{{< include "includes/WIP-callout.qmd" >}}

<!--
Thinking about Bob Hunt.  https://www.perplexity.ai/search/robert-hunt-from-kodak-researc-pIEYaPICQzWNhpK4mWIcCQ 

That single channel metrics guy Barten
Based on your description, I'm quite confident you're thinking of **Peter G. J. Barten** and his work on image quality, particularly his **Square-root integral (SQRI)** model.

He fits your description perfectly:
* **Name:** "Barten" is very similar to your recollection of "Bartlett."
* **Field:** He was a highly influential display consultant and engineer who specialized in spatial image metrics and visual sensitivity.
* **Timeframe:** His key book, *"Contrast Sensitivity of the Human Eye and Its Effects on Image Quality,"* was published in 1999, and his SQRI model was widely discussed in the 1990s and 2000s, placing him exactly in the "about 20 years ago" period.
* **Model:** His work focused on luminance (black and white) and is famous for a single metric that predicts perceived image quality. This metric is precisely what you described: **a single integral**.

### The Barten Model and the "Square-root integral" (SQRI)

The simple formula you're remembering is likely the **Square-root integral (SQRI)**. This model calculates a single number (often called $J$) to represent the perceived quality of an image on a display.

The model is conceptually a single-channel integral across spatial frequencies. In simple terms, it does this:

1.  **It uses the Contrast Sensitivity Function (CSF):** Barten developed a comprehensive (though complex) set of equations to model the human eye's contrast sensitivity function ($CSF$), which is our ability to see fine detail (high spatial frequencies) versus coarse detail (low spatial frequencies). This is the "visual sensitivity model" part.
2.  **It Compares Display to Eye:** The SQRI formula integrates the ratio of the display's modulation transfer function ($MTF$, what the display can *show*) to the eye's modulation threshold ($M_t$, what the eye can *see*) at each spatial frequency.
3.  **The "One Integral":** The simplified form of the SQRI metric is an integral that looks conceptually like this:

    $$J \propto \int \sqrt{\frac{\text{Display Contrast}(f)}{\text{Human Threshold Contrast}(f)}} \, d(\log f)$$

This single number, $J$, is expressed in "Just Noticeable Differences" (JNDs) and provides a powerful metric for "how good" an image looks, which is exactly what he gave many seminars about.

Does Peter B. Barten and the Square-root integral model sound like what you were thinking of?
-->

# Human visual metrics overview {#sec-human-metrics-overview}

Engineering progress relies on measurement. Improving a system is an iterative process that involves a loop of designing, measuring, and redesigning. Consequently, performance metrics are fundamental to nearly all engineering disciplines.

It is also a common principle that systems of even moderate complexity have more than one performance measure. We are often forced to make trade-offs, for example, between a system's speed and its accuracy. We see this in modern AI systems that offer a choice between a 'fast' mode and a more thorough 'thinking' mode.

Imaging systems are no different. They present numerous trade-offs. For instance, increasing a sensor's spatial resolution can reduce the number of photons captured per pixel, thus lowering the signal-to-noise ratio (SNR). Conversely, increasing SNR by using wider color filter bandwidths may reduce color accuracy.

When there is only one parameter to optimize, assessing system design is straightforward. However, most systems involve optimizing multiple parameters simultaneously. A design change might improve some metrics while degrading others, making it difficult to determine an overall improvement.

This complexity is reflected in the field of image quality metrics. Many different metrics exist. Some assess a specific aspect of system performance, guiding the design of a particular component. Others, however, aim to capture the general notion of image quality as a human would judge it. The most famous of these—the Structural Similarity Index Measure (SSIM), with over 100,000 citations—is a prime example.

Engineers, computer scientists, and product managers often desire a single number they can optimize and market. As a student or young researcher, you might be tempted to resist this simplification. A word of advice: understand the limitations of single-number metrics, but don't let their imperfection stall your progress. Use them as the valuable, albeit incomplete, tools they are.

## Human metrics
In the image processing section, I introduce a number of image systems metrics that are designed to evaluate the system and its components directly (@sec-imgprocessing-metrics-overview). Those metrics might assess the signal-to-noise (SNR) of a pixel, or the MTF of a lens.

In this section, I review metrics that are designed with the human viewer in mind:  How sharp will the image appear?  Will the noise be visible?  Do the colors in the rendering match those in the original?  I have divided these human-centric metrics into three parts.  The frist part covers metrics that are largely dependent on the spatial image properties, such as image sharpness and noise.  The second part covers metrics that are largely dependent on color properties.  The third section describes metrics that measure the temporal sensitivity, including the visibility of flicker or motion blur.

## Spatial metrics {#sec-human-spatial-metrics}

I have links to both original measurements, modern measurements (Standard Spatial Observer), and many commercial versions of spatial metrics that are implemented in ISETCam.  This section will describe those.

<!--
Material collected for incorporating here.  There are even some tables describing many of the metrics.  Helped from FISE-Human, I think.  Maybe Gemini, too, not sure.

Section 1:  https://docs.google.com/document/d/1vbsVXmAgqLxVCneZ8HmjsBioLJv-FAHhoLatnnXlx7c/edit?usp=sharing 
Section 2:  https://docs.google.com/document/d/1j5DB83pqyV0VfGew10sO0PTrh20jbB_JRGUiIvwRzSw/edit?usp=sharing 
Section 3:  https://docs.google.com/document/d/1qASkzf8CM2NUnT7FzNa4a3GIDfyfn5Ps0_uBGXP4qkM/edit?usp=sharing
Section 4:  https://docs.google.com/document/d/1jYQCZ6ZnKL9VJjcCyapttxKmELhJi2jD5o7rsI0V_38/edit?usp=sharing  
-->

### Classical

That single channel guy with his metric and formula.  Repeated everywhere. Barten.  SQRI.

Earlier single channel. Value of multiple channel metrics?  Existence?  S-CIELAB accounts for distance

### Modern

SSIM and MS-SSIM

LPIP goes here because it is human judgments of image quality?

Pyramid from Beau? Multi-parameter

I forked the [Mantiuk github repository: ](https://github.com/isetbio/stelaCSF) 
[The Mantiuk repository is here: ](https://github.com/gfxdisp/stelaCSF.git).
 His metric goes here, I think.  His code reads classic datasets.  Maybe we include the data files in the book? 

The surprising metric LPIPS


## Color metrics

CIELAB

S-CIELAB

Mark Fairchild contributions. Others?

## Temporal metrics

temporal MTF metrics





