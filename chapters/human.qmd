# Human vision {#sec-human}

<!--# https://library.brown.edu/create/libnews/victorian-optics/  TODO: Remember the Newton bodnick pressure on the eye. https://cudl.lib.cam.ac.uk/view/MS-ADD-03975/21 a tip until he saw ‘several white darke and colored circles. Which circles were plainest when I continued to rub my eye with the point of the bodkin.’ Yet when he held both eyes and bodkin still, the circles would begin to fade. Was light a manifestation of pressure, then? Almost as recklessly, he stared with one eye at the sun, reflected in a looking glass, for as long as he could bear. He sensed that color—perhaps more than any of the other qualities of things—depends on imagination and fantasy and invention. He looked away at a dark wall and saw circles of color. There was a motion of spirits in his eye. These slowly decayed and finally vanished. Were they real or phantasm? Could such colors ever be real, like the colors he had learned to make from crushed berries or sheep’s blood? After looking at the sun he seemed to perceive light objects as red and dark objects as blue.” (Gleick, James. Isaac Newton. New York: Pantheon Books, 2003:61–2.)-->

Consumer photography systems are designed to capture the light field and transform it into display images that are visually compelling and faithful to human perception. Because these systems deliver information to the human visual system, both the image systems' capture and display components are engineered with quantitative properties of human vision in mind. This chapter describes many visual system properties that are used to guide the implementation of image systems. We particularly highlight the quantitative measures that are widely adopted as industry standards.

The scientific research and discoveries underlying these standards have deep biological roots and are critical to understanding how imaging systems align with human perception. This book includes brief insights into this background, and for those seeking a more detailed exploration of vision science, please refer to *Foundations of Vision* [@wandellFoundationsVision2024], which delves into the biological mechanisms that underpin human vision.

Finally, a note for image systems engineers: while the quantitative properties discussed here are central to achieving functional and reliable imaging, the ultimate value of consumer photography lies beyond mere technical fidelity. People value images not only for their precision but for their ability to evoke memories, emotions, and connections. An effective imaging system is one that balances technical accuracy with the capacity to convey the essence of a scene, preserving the emotions and experiences that make an image meaningful. In this way, engineering for consumer photography is about creating systems that are not just accurate but also impactful.

<!--# The chapters with David have a lot of the material.  -->

## The eye

We can distinguish image systems components that acquire information about the light field (cameras) from components that recreate a light field (displays). The properties of the human visual system are important for many aspects of display systems. Some features of the human visual system are also important for the design of cameras. In this section, we describe basic anatomical and functional properties of the eye, the human visual system component whose properties have strong implications for the design of image systems.

The eye includes two systems [@fig-retina-color]. The optics converts the incident light field into the optical light field, forming an image at the retina. The retina converts the optical light field into a neural signal that is transmitted to the brain. There is no feedback from the brain to the retina itself. Rather, the feedback from the brain is made by body, head and eye movements that enable us to acquire the light field from different positions and directions. The importance of these movements for the human visual system, but not for cameras, is one reason why direct comparisons between the eye and a camera are not great.

The physiological optics is divided into two parts: a cornea and flexible lens. Together, their optical properties determine the transformation of the incident light field to the optical light field. The optics are dynamic in two ways: both the size of the entrance pupil and the optical power of the lens can vary. The pupil size changes depending on the ambient light conditions and as well as some non-visual events in the brain. The flexible lens changes its shape, and thus refractive power, enabling people to bring either close or far objects into focus on the retina. The lens flexibility is lost with age (presbyopia, CITATION NEEDED). The direction of gaze also varies as people move their head and eyes, depending on the viewer's intention.

The neural tissue of the retina lines the curved surface at the back of the eye. The image at the retina is converted from light into a neural signal by a special class of neurons, the photoreceptors. The retina contains additional specialized cells and circuits whose outputs, on the optic nerve, are transmitted to several brain regions. These circuits are also dynamic in the sense that the circuit response properties vary with changes in the mean and variance of the retinal image.

There are some similarities between the eye and a conventional camera. For example, the optics and light sensing components are integrated into a single package, and the components are adaptive with respect to light level and focus. A major difference is that the retinal encoding does not sample the image uniformly; it is very inhomogeneous compared to modern cameras. The central human retina is specialized for the cone photoreceptors, which have small (\~ 1.5 um) apertures and are tightly packed. The size of the photoreceptor apertures increases significantly from fovea to periphery, and the receptors for nighttime vision (rods) are inserted between the cones, further increasing their center-to-center spacing. This spatial sampling is quite unlike a typical image sensor whose pixels are all of the same size. Finally, the human visual system relies on eye movements to bring regions of interest into focus at the fovea. The keep integration of eye movements is very important for such a spatially inhomogeneous system.

![Overview of the eye.](/images/human/retina-fovea-color.png){#fig-retina-color width="100%" fig-align="center" width="75%"}

I will describe measurements of the optics and encoding in several sections below. These are selected to support calculations of image quality and engineering design. For more about the biology and the scientific methods used to derive these measurements, consult [@wandellFoundationsVision2024]

### Adaptive optics

The ability to measure certain properties of the optics was revolutionized by adpative optics - a method that makes real time measurements of the wavefront aberrations of the physiological optics using a Shack-Hartmann wavefront sensor. Just the measurement of the aberrations alone is useful. In addition, it has proben possible to engineer systems that correct for these aberrations in real time, and thus visualize the apertures of the photoreceptors (1-5 $\um$ diameter) cells in the retina. Further, using video tracking of the eye movements it has proven possible to deliver stimuli to specific, targeted photoreceptors.

First order approximations of the human optics. Simulations with ISETBio of maybe the Westheimer or Ijspeert functions. Eye models?

### Pointspread functions

Where should the adaptive optics measurement method be? Here or FOV? Adaptive optics measurements of wavefront aberrations, expressed as point spread functions. Thibos and Artal data.

### Chromatic aberrations

Wavelength dependence (chromatic aberration)

### Field height dependence

Artal data. Point to ISETBio and maybe the other book.

## The retina

The retina is a 200-300 micron thick layered structure of neural tissue that lines the back of the eye (5 cm x 5 cm). There are about 80 different cell types that can be identified through their genetic expression. Specific retinal cell types form stereotypical connections that make up specific, identifiable circuits. There are about 20 known circuits, and these are likely to account for nearly all of the circuits in the retina. The output signals from these circuits are carried on axons in the optic nerve that project to a variety of locations in the brain.

The vast majority of light-driven activity is initiated in the photoreceptors (rods and cones). The rods are the dominant source under very low light levels, and the cones are the dominant source under moderate to high light levels. The typical retinal circuit is driven by activity that starts in a local region of the photoreceptors. The same basic circuit will be present throughout the retina, tiling the photoreceptor mosaic, though the absolute size of the cells and their input regions generally vary as one measures across the retina. The size of the region increases as one measures from the highly specialized central fovea into the periphery.

### Photoreceptor sampling

Maybe point mainly to the other book. Image showing the fovea and inhomogeneous sampling of the photoreceptor mosaics. Maybe Curcio. Maybe the S-cone image sampling mosaic. Adaptive optics measurements of retinal sampling Rods, ipRGCs, too in here. Other book - ISETBio: Examples of simulation. David also has these new measurements.

## Pattern, Time and Motion

spatial MTF - Look through modern measurements of the spatial MTF.

temporal MTF

### Image pattern metrics

SSIM. Simpler ones. Pyramid from Beau? But earlier single channel, multiple channel.

SSIM and MS-SSIM

Sharpness metrics

I forget the guy

temporal MTF. Flicker. Luminance.

## Color

<!--# What about the color matching experiment? Maybe James Clerk Maxwell mentioned but referred to FOV -->

Color representations: XYZ, luminance, chromaticity, cones

Color discrimination: ellipses

### Color metrics

CIELAB

S-CIELAB

Mark Fairchild contributions. Others?

## Computer vision metrics

They should be described elsewhere.

A lot of these might have been used in those directional cosine errors in Zheng's dissertation