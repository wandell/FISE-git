# Photoelectric {#sec-sensors}

The [Preface](../index.qmd#sec-preface) provides a very brief discussion of the history of image sensor technologies, from film to charge-coupled devices (CCD), and to the invention of CMOS image sensors (CIS). Here is a bit more.

Film, the first major commercial technology for capturing and storing image irradiance, relied heavily on chemistry. Light-sensitive molecules were placed in multiple layers onto flexible rolls of plastic, and the roll was loaded into the darkened body of the camera. With the body closed, the film was mechanically advanced, placing a small flat section of film in the focal plane behind the lens.

![Film was the dominant image sensor and recording material for a hundred years. The chemistry of film for both encoding and developing into images was the core scientific discipline. Film could not be reused, producing a steady commercial profit for large companies, such as Kodak, Fuji, Polaroid and Agfa.](images/sensors/film.png){#fig-film width="60%"}

To take a picture, shutter was opened and the spectral irradiance from the lens (optical light field) formed an image on the film. The light changed the structure of molecules in the film layers that were designed to encode the image. For color film, there were multiple layers that differed in their wavelength sensitivity. These molecular changes represented the local brightness of the captured image in different wavebands. Using chemical processes, the density of changes to the light-sensitive molecules could be measured and transferred to other media, such as prints. This process required a variety of chemical consumables, and the film could not be reused. Specialized labs were needed to create the film and to develop and printing the image. Some home hobbyists could develop the film, but mainly the processes were carried out by large commercial organizations.

The transition to electronics emerged with the discovery that semiconductor technology could also be used to record irradiance @boyle1970-ccd-first. Light incident on the silicon releases electrons (photoelectric effect), and the spatial pattern of these electrons can be stored and measured. This breakthrough was first implemented in 1970 by Michael Tompsett, who developed the image sensor known as the charge-coupled device (CCD). The semiconductor based sensor revolutionized imaging, moving it from a field based on chemistry to electrical engineering. Importantly, the digital readout from these electrical devices could be immediately integrated with computers. Images could be stored, shared, edited and analyzed directly from the camera output.

The first successful implementation of this principle in an image sensor was the charge-coupled device (CCD), developed in 1970 by Michael Tompsett, building on earlier work by George Smith and Willard Boyle [@boyle1970-ccd-first]. This innovation marked a fundamental shift in imaging, transitioning from a field rooted in chemistry (like photographic film) to one based on electrical engineering. A key advantage was the digital nature of the readout, allowing immediate integration with computers for storage, sharing, editing, and analysis of images directly from the camera.

While both CCD and modern CMOS (Complementary Metal-Oxide-Semiconductor) imagers utilize the photoelectric effect to detect light, they are built using distinct semiconductor technologies. These differences typically necessitate separate fabrication facilities or specialized process flows within a general CMOS facility. A pivotal development was Eric Fossum's circuit design - the active pixel sensor (APS) - which demonstrated that image sensors could be successfully implemented using mainstream CMOS microelectronics processes (@Fossum2023-invention).

![CMOS image sensors incorporate circuitry, comprising multiple subsystems and enabling many different image processing features. Maybe get a figure from one of Eric's earlier papers.](images/sensors/olympusCMOSSensorImage.png){#fig-olympus-overview style=".float-right" width="489"}

Fossum's CMOS imager breakthrough was very significant. By leveraging standard CMOS technology, it became possible to integrate not only the light-sensing pixels but also the timing, control, and signal processing circuitry onto the same sensor chip. This integration enabled new functionalities directly at the sensor level (@fig-olympus-overview). Furthermore, this shift dramatically reduced power consumption, a crucial factor that opened the door to the widespread adoption of image sensors in mobile devices. Thus, beyond the technology itself, the breakthrough enabled the massive global adoption of electronic image sensors. Their widespread use continues to impact many aspects of societies across the globe.

Considering the technological advantages and widespread adoption of CMOS image sensors, we primarily focus on their properties and operation. We will dedicate separate sections to explore the characteristics of CCD imagers and single-photon avalanche detectors (SPADs).

<!-- Fossum says: power reduced (100×) as well as avoid many of the charge‐transfer degradation issues associated with exposure to radiation in space [11] (see Figure 23.6).  (From the Book chapter https://onlinelibrary.wiley.com/doi/chapter-epub/10.1002/9781394202478.ch23)-->

## The photoelectric effect

Image sensors all include arrays of tiny, light-sensitive photodiodes. When electromagnetic radiation, such as light, arrives a photodiode, its energy is converted into electrons. This process, known as the **photoelectric effect**, is fundamental to all modern imaging sensors. Understanding how materials convert light into electrical signals is a fascinating chapter in the history of physics and engineering, shaped by groundbreaking experiments and theories.

That certain materials convert light to electrons was first reported by Heinrich Hertz [-@Hertz1887-photoelectric2; -@Hertz1887-photoelectric1]. He used a simple apparatus: a loop of wire with a small gap. When exposed to a strong electromagnetic wave at the right frequency, a current was induced in the loop, and if strong enough, a spark would jump across the gap. Hertz discovered that illuminating the wire loop with ultraviolet (UV) light made the spark stronger, and it could jump across a larger gap between the wires. He concluded that UV light generated additional current in the wire, demonstrating that light can produce electrical signals.

```{=html}
<!--
He also noticed that glass, which blocks UV light, eliminated the effect. Quartz (which transmits UV light) did not.
-->
```

The central challenge of the photoelectric effect is to model how electromagnetic radiation—light—interacts with a material to generate an electrical signal.

## The birth of the photon

Hertz' initial photoelectric demonstration was in 1887, and it was not until 1897 that JJ Thomson conclusively demonstrated that electrons are discrete, countable particles. Thomson's experiments revealed that cathode rays are composed of negatively charged particles with a specific mass and charge, much smaller than that of an atom.

In 1902, armed with knowledge of electrons, Philipp Lenard carried out a series of revealing experiments. He observed that increasing the intensity of the incident light increased the number of emitted electrons but **did not** increase their kinetic energy. Instead, the energy of the emitted electrons depended on the **wavelength** of the light: shorter wavelengths (higher frequencies) produced more energetic electrons. Lenard also identified a **threshold wavelength**—if the light’s wavelength was too long (i.e., its frequency too low), no electrons were emitted, regardless of how intense the light was. These results posed a serious challenge to classical wave theory, which predicted that energy should increase smoothly with intensity, not depend on frequency.

At the same time, physicists were trying to explain the spectrum of light emitted by a blackbody—a perfect absorber and emitter of radiation. In 1900, **Max Planck** tackled this problem. After much effort, he found a formula that matched the observed spectrum, but only if he assumed that energy exchange (joules) between matter and radiation occurred in discrete amounts.

$$
E = n h \nu
$$

Here, $n$ is an integer; $\nu$ is the frequency ($1/sec$) of the light; and $h$ is a constant he discovered — now called Planck’s constant ($h = 6.62607015 \times 10^{-34}$ joule-seconds). Planck proposed that the oscillators in the material’s walls could only transfer energies in discrete steps. This quantization explained why the measured absorption and emission of light matched the observed spectrum, even though the light field itself was continuous.

In 1905, Albert Einstein offered a revolutionary explanation. He proposed that we should not think of light as a continuous wave that becomes quantized through an interaction with the material. Rather, he argued, light itself **quantized** into discrete packets of energy—later called **photons**. The energy of each photon is proportional to its frequency,

$$
E = h \nu
$$

where $h$ is Planck’s constant and $\nu$ is the frequency of the light. This hypothesis went beyond Max Planck’s work, which assumed the quantization was part of the exchange between matter and radiation — not that light itself came in packets. Einstein suggested that **light in free space** behaves as localized energy quanta, capable of transferring energy to electrons one photon at a time. His theory explained both Planck's observations and all of Lenard’s experiments. His photoelectric theory laid the groundwork for the next generation's work in quantum physics.

## Wave particle duality

For much of the 19th century, Newton’s idea that light was made of tiny particles (corpuscles) was set aside, as experiments overwhelmingly supported the wave theory of light—interference and diffraction patterns provided strong evidence for wave-like behavior. However, the photoelectric effect presented results that could not be explained by wave theory alone, forcing physicists to recognize that light sometimes behaves as a particle as well. This is the essence of the **wave-particle duality**.

In quantum mechanics, light is described by a mathematical object called the **wavefunction**, which provides the probabilities of different outcomes. When experiments are designed to reveal wave-like effects (such as interference), light behaves as a wave. When experiments probe particle-like effects (such as the photoelectric effect), light behaves as a particle. Both descriptions are necessary, and neither alone is sufficient to fully describe the nature of light.

This duality remains a central and intriguing feature of quantum physics. If you don't find all of this a bit puzzling, you may not be paying enough attention.

::: {#lenard-einstein-bohr .callout-note collapse="true"}
## The Duality of Light, the Duality of People

![Lenard made measurements that defined important properties of the photoelectric effect. Einstein offered a bold theoretical idea, what we now call the photon, that explained Lenard's and Planck's measurements. Einstein, who was Jewish, had a complex personal relationship with Planck, as they navigated Hitler's rise to power. Lenard became strongly anti-Semitic.](images/people/03-Lenard-Einstein.png){#lenard-einstein width="50%" fig-align="center"}

Einstein’s proposal of the photon was initially met with skepticism, as the wave theory of light was deeply established in physics. Even Einstein himself was uneasy with the resulting **wave-particle duality**, believing it pointed to an incomplete understanding of nature. He famously rejected the probabilistic foundations of quantum mechanics, remarking that “God does not play dice.” Niels Bohr, a leading figure in quantum theory, responded, “Einstein, don’t tell God what to do.” The tension between wave and particle descriptions remains a central—and still unresolved—theme in physics.

In 1905—Einstein’s *annus mirabilis*—he published four groundbreaking papers that reshaped modern physics. In addition to the photoelectric effect, for which he was awarded the Nobel Prize, he introduced Special Relativity, showing that **simultaneity is relative** depending on the observer’s frame of reference. Walter Isaacson’s biography of Einstein (@Isaacson2008-einstein) provides an accessible account of these discoveries and the broader scientific context. Isaacson also details how Lenard, who was also a Nobel Laureate, became an outspoken anti-Semite who actively opposed Einstein’s recognition. <!--
Photoelectric effect and Lenard
https://www.perplexity.ai/search/when-einstein-worked-out-the-p-_doyK0P0SPCj2lF728iVpg 
-->
:::

## Quantifying the photoelectric effect

When we model light as a wavefunction, we can only predict the probability that a photon will generate an electron. This means that even with a perfectly stable light source, the number of electrons generated will fluctuate from one measurement to the next. These fundamental statistical fluctuations are a key feature of how light interacts with matter and are central to quantum optics.

The number of photon absorptions in a photodiode follows the Poisson probability distribution. This statistical property was formalized in the 1950s by two groups: one studying visual sensitivity in the retina (@Pirenne1951-poisson, @Barlow1956-retinalnoise), and another investigating the physics of electromagnetic radiation and image sensors (@Mandel1959-poissonabsorptions).[^sensors-01-photoelectric-1]

[^sensors-01-photoelectric-1]: The history of these discoveries is fascinating but too detailed to cover here. For more, see [these notes](resources/Poisson-history.html).

The mean number of electrons generated is proportional to the light intensity: doubling the light intensity doubles the **mean** number of electrons (@Preece2022-photontransfer). This linearity holds over a wide range, until the sensor material saturates (when no more electrons can be generated). Within this linear range, the number of electrons is a noisy estimate of the mean number of incident photons.

Not every photon generates an electron. The ratio of generated electrons to incident photons is called the photodiode's **quantum efficiency (QE)**. QE can be measured as the slope of the line relating the number of incident photons (x-axis) to the number of generated electrons (y-axis). A QE of 1 (or 100%) means every photon generates one electron; a QE of 0.5 means, on average, half of the photons generate an electron.

$$
\mathrm{QE}(\lambda) = \frac{\text{number of electrons generated}}{\text{number of incident photons at wavelength } \lambda}
$$

In practice, QE depends on wavelength due to the sensor material and device design. Manufacturers often provide QE curves showing efficiency as a function of wavelength, and we will examine examples later.

The photodiode is part of a circuit that stores and reads out the generated charge. This circuitry can introduce nonlinearities and additional noise, affecting the overall system response (@Bohndiek2008-sensorlinearity). However, the initial conversion from light to electrons is linear over a large range. Understanding this linear process is fundamental to CMOS image sensor operation; understanding the full system requires further study of the sensor's electronic components, which we discuss in later sections.

```{=html}
<!--
Bohndiek2008-sensorlinearity paper has figures.  Notice how nonlinear Figures 7 and 17 are.  But earlier figures (e.g., I probably have class data with response linearity and nonlinearity.  The Thieuwissen paper has an analysis of the impact of floating diffusion.
-->
```

## Statistics of the photoelectric effect

The principles underlying the Poisson distribution of electrons are straightforward. Suppose we have a **steady source** of photons, all with the same wavelength. The probability of a photon arriving in any given small time interval, $\delta t$, is constant. This is the defining property of a Poisson process: events occur independently, with a constant average rate.

If the probability that a photon generates an electron is also constant (equal to the quantum efficiency, QE), then each photon arrival is an independent chance to generate an electron. The resulting number of electrons generated in a given interval is also Poisson distributed, with a mean scaled by the quantum efficiency. This statistical fluctuation in the number of electrons is known as the **shot noise** of the sensor.

::: {#photoelectric-poisson .callout-note collapse="true"}
## Siméon Denis Poisson

We met Poisson earlier as the French academician who tried to disprove Fresnel's wave theory calculations. He predicted [a bright point that appears at the center of a circular object's shadow](https://en.wikipedia.org/wiki/Arago_spot) based on that theory—thinking it impossible, but it was observed!

![Siméon Denis Poisson.](images/sensors/03-Image-of-Poisson.png){#fig-image-poisson width="40%"}

Poisson described this distribution in his 1837 work "Recherches sur la probabilité des jugements en matière criminelle et en matière civile (Researches on the Probability of Judgments in Criminal and Civil Matters)". His goal was to describe the number of discrete events occurring in a fixed interval of time or space, given a known constant mean rate and independence between events. His applications included jurisprudence and statistics such as the number of soldiers killed by horse kicks in the Prussian army.

The mathematical framework he established applies directly to the arrival of photons from a constant light source. In imaging, each electron generation is considered an 'event', all events are identical, and the probability of an event in any small time interval is the same.
:::

The Poisson formula describes the probability of observing $n$ electron events, given a mean $\lambda$:
$$
P(n; \lambda) = \frac{\lambda^n e^{-\lambda}}{n!}
$$

Here, $\lambda$ is both the expected (mean) number of events and the variance of the distribution. For large $\lambda$ (greater than about 15 or 20), the Poisson distribution closely resembles the Normal (Gaussian) distribution (@fig-sensor-poisson). The main differences are that the Poisson distribution only takes integer values and is skewed for small $\lambda$. As $\lambda$ increases, the distribution becomes more symmetric and approaches the Normal distribution.

![Poisson distribution examples. The Poisson formula (red lines) and simulations of Poisson counts (bars) are shown for three mean levels.](images/sensors/03-Poisson.png){#fig-sensor-poisson width="70%"}

A key fact we will use later: for a Poisson distribution, the mean and variance are equal. This property distinguishes Poisson noise from other types of noise.

:::{#shotnoise-poisson .callout-note collapse="true"}
## ISETCam: shot noise
You can see a step-by-step statistical explanation of this process in the [ISETCam script](../code/fise_photonsElectrons.html). The script demonstrates why, in conventional CMOS image sensors, both the incident photons and the resulting electrons follow Poisson statistics. Note, however, that this relationship may not apply to other sensor types—such as those that can generate multiple electrons from a single photon.
:::
