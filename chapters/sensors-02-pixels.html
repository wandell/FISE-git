<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-11-08">
<meta name="description" content="An integrated overview of image systems, from physical scene formation through sensors, optics, and human vision.">

<title>15&nbsp; Pixels and sensors – Foundations of Image Systems Engineering</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/sensors-03-parameters.html" rel="next">
<link href="../chapters/sensors-01-photoelectric.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles/hover.css">
<link rel="stylesheet" href="../styles/callouts.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/part-sensors.html">Sensors</a></li><li class="breadcrumb-item"><a href="../chapters/sensors-02-pixels.html"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Pixels and sensors</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Foundations of Image Systems Engineering</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Preface</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Scenes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-scenes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part I: Scenes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/lightfields-01-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Light and seeing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/lightfields-02-measurement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Measuring light</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/lightfields-03-properties.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Light field properties</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/lightfields-04-properties-spectral.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Spectral regularities</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/lightfields-05-properties-spatial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Spatial regularities</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Optics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-optics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part II: Optics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/optics-01-geometric.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Geometric optics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/optics-02-lenses.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Lens principles</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/optics-03-thinlens.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Thin lenses</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/optics-04-morelenses.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Lenses and ray transfer</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/optics-05-linear-space.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Spatial domain</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/optics-06-linear-transform.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Transform domain</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/optics-07-wavefront.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Wavefronts</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Sensors</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-sensors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part III: Sensors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/sensors-01-photoelectric.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Photons and Electrons</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/sensors-02-pixels.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Pixels and sensors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/sensors-03-parameters.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Sensor parameters</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/sensors-04-components.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">System components</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/sensors-05-control.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Control systems</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/sensors-06-characterization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Image system modeling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/sensors-07-innovations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Sensor innovations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Human</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-human.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part IV: Human Vision</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/human-01-seeing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Seeing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/human-02-spatial-encoding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Human spatial encoding</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/human-03-wavelength-encoding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Human wavelength encoding</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/human-04-metrics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Human visual metrics</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Displays</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-displays.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part V: Displays</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/displays-01-principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Display Principles</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Image processing</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-processing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part VI: Image processing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/imgprocessing-01-hardware.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Hardware processing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/imgprocessing-02-rendering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Rendering</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part VII: Appendix</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/appendix-01-linearsystems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Linear systems</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/appendix-02-spaceinvariance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Linear Space-Invariant (LSI) Systems</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/appendix-03-isetcam.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Image Systems Simulation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-pixels-overview" id="toc-sec-pixels-overview" class="nav-link active" data-scroll-target="#sec-pixels-overview"><span class="header-section-number">15.1</span> Pixels and sensors</a></li>
  <li><a href="#sec-semiconductor-physics" id="toc-sec-semiconductor-physics" class="nav-link" data-scroll-target="#sec-semiconductor-physics"><span class="header-section-number">15.2</span> Semiconductors and electrons</a>
  <ul class="collapse">
  <li><a href="#sec-bandgap-photon-absorption" id="toc-sec-bandgap-photon-absorption" class="nav-link" data-scroll-target="#sec-bandgap-photon-absorption"><span class="header-section-number">15.2.1</span> Bandgap</a></li>
  <li><a href="#sec-wavelength-effects" id="toc-sec-wavelength-effects" class="nav-link" data-scroll-target="#sec-wavelength-effects"><span class="header-section-number">15.2.2</span> Wavelength effects in silicon sensors</a></li>
  </ul></li>
  <li><a href="#sec-cmos-pixel-fsi" id="toc-sec-cmos-pixel-fsi" class="nav-link" data-scroll-target="#sec-cmos-pixel-fsi"><span class="header-section-number">15.3</span> CMOS Pixel: Front-side illuminated</a></li>
  <li><a href="#sec-sensor-circuits" id="toc-sec-sensor-circuits" class="nav-link" data-scroll-target="#sec-sensor-circuits"><span class="header-section-number">15.4</span> CMOS circuits</a>
  <ul class="collapse">
  <li><a href="#sec-3T-pixel-design" id="toc-sec-3T-pixel-design" class="nav-link" data-scroll-target="#sec-3T-pixel-design"><span class="header-section-number">15.4.1</span> Three-Transistor (3T) Pixel Design</a></li>
  <li><a href="#sec-4T-pixel-design" id="toc-sec-4T-pixel-design" class="nav-link" data-scroll-target="#sec-4T-pixel-design"><span class="header-section-number">15.4.2</span> Four-Transistor (4T) pixel design</a></li>
  </ul></li>
  <li><a href="#multiplex-readout" id="toc-multiplex-readout" class="nav-link" data-scroll-target="#multiplex-readout"><span class="header-section-number">15.5</span> Multiplex readout</a></li>
  <li><a href="#sec-rolling-shutter" id="toc-sec-rolling-shutter" class="nav-link" data-scroll-target="#sec-rolling-shutter"><span class="header-section-number">15.6</span> Rolling shutter</a></li>
  <li><a href="#sec-sensor-evolution" id="toc-sec-sensor-evolution" class="nav-link" data-scroll-target="#sec-sensor-evolution"><span class="header-section-number">15.7</span> Sensor evolution</a></li>
  <li><a href="#sec-sensor-bsi" id="toc-sec-sensor-bsi" class="nav-link" data-scroll-target="#sec-sensor-bsi"><span class="header-section-number">15.8</span> Back-side illuminated (BSI)</a></li>
  <li><a href="#sec-sensor-deepdiode" id="toc-sec-sensor-deepdiode" class="nav-link" data-scroll-target="#sec-sensor-deepdiode"><span class="header-section-number">15.9</span> Deep photodiodes</a></li>
  <li><a href="#sec-sensor-stacked" id="toc-sec-sensor-stacked" class="nav-link" data-scroll-target="#sec-sensor-stacked"><span class="header-section-number">15.10</span> Stacked sensors</a></li>
  <li><a href="#sec-digital-pixel" id="toc-sec-digital-pixel" class="nav-link" data-scroll-target="#sec-digital-pixel"><span class="header-section-number">15.11</span> Digital pixel sensor</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/part-sensors.html">Sensors</a></li><li class="breadcrumb-item"><a href="../chapters/sensors-02-pixels.html"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Pixels and sensors</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-pixels" class="quarto-section-identifier"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Pixels and sensors</span></span></h1>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 8, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Work in Progress
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>The book is still taking shape, and your feedback is an important part of the process. Suggestions of all kinds are welcome—whether it’s fixing small errors, raising bigger questions, or offering new perspectives. I’ll do my best to respond, but please keep in mind that the text will continue to change significantly over the next two years.</p>
<p>You can share comments through <a href="https://github.com/wandell/FISE-git/issues" target="_blank">GitHub Issues</a>.</p>
<p>Feel free to open a new issue or join an existing discussion. To make feedback easier to address, please point to the section you have in mind—by section number or a short snippet of text. Adding a label characterizing your issue would also be helpful.</p>
<p>Last updated: November 8, 2025</p>
</div>
</div>
</div>
<section id="sec-pixels-overview" class="level2" data-number="15.1">
<h2 data-number="15.1" class="anchored" data-anchor-id="sec-pixels-overview"><span class="header-section-number">15.1</span> Pixels and sensors</h2>
<p>I now connect the physics of photon-to-electron conversion to the engineering of image sensor pixels. First, we review how electrons behave in semiconductor materials and how photons create mobile charge carriers (<a href="#sec-semiconductor-physics" class="quarto-xref"><span>Section 15.2</span></a>). Then I examine how CMOS pixel architectures (e.g., classic 3T and 4T designs, and their modern extensions) store, transfer, and read out that charge.</p>
<p>Subsequent sections explain how pixel structures have evolved (front-side to back-side illumination, deep photodiodes, stacking, and digital pixels) to improve sensitivity, speed, and dynamic range. Finally, I describe how to model and measure sensor performance (<a href="sensors-06-characterization.html#sec-system-modeling-overview" class="quarto-xref"><span>Section 19.1</span></a>) and how additional on-sensor components—such as color filters and microlenses—shape the captured data (<a href="sensors-04-components.html" class="quarto-xref"><span>Chapter 17</span></a>).</p>
<p>The goal of these chapters is to build an intuition that links semiconductor physics to practical design trade-offs in modern image sensors.</p>
</section>
<section id="sec-semiconductor-physics" class="level2" data-number="15.2">
<h2 data-number="15.2" class="anchored" data-anchor-id="sec-semiconductor-physics"><span class="header-section-number">15.2</span> Semiconductors and electrons</h2>
<p>Atoms in a silicon semiconductor are arranged in a crystalline structure, and their electrons occupy specific energy levels grouped into two main bands: the <strong>valence band</strong> (lower energy) and the <strong>conduction band</strong> (higher energy). Under normal conditions, most electrons remain in the valence band. When a silicon atom absorbs a photon, an electron can be excited from the valence band to the conduction band (<a href="#fig-sensor-bandgap" class="quarto-xref">Figure&nbsp;<span>15.1</span></a>).</p>
<!--
A particularly clear explanation with figures and a video.
https://scientificimaging.com/knowledge-base/photoelectric-effect/ 
-->
<section id="sec-bandgap-photon-absorption" class="level3" data-number="15.2.1">
<h3 data-number="15.2.1" class="anchored" data-anchor-id="sec-bandgap-photon-absorption"><span class="header-section-number">15.2.1</span> Bandgap</h3>
<p>The minimum energy required for this transition is called the <strong>bandgap</strong>, and it is measured in electron volts (eV). For silicon at room temperature (<span class="math inline">\(21 \deg C\)</span>), the bandgap is 1.12 eV. Only photons with energy equal to or greater than this value can generate free electrons in silicon.</p>
<div id="fig-sensor-bandgap" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sensor-bandgap-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/sensors/14-pixels/03-sensor-bandgap.png" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sensor-bandgap-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.1: Energy bands in silicon semiconductors. A photon can excite an electron in the Valence band. If the photon has enough energy, the electron can shift to the conduction band, becoming a free electron that can be stored and counted.
</figcaption>
</figure>
</div>
<p>Without special circuitry, the hole and electron will re-combine. To make an image sensor, we need a method to measure the number of electrons. In a CCD an electric field between the bands prevents recombination. In CMOS electrons are trapped in capacitors placed in the silicon. We explain this circuitry below.</p>
</section>
<section id="sec-wavelength-effects" class="level3" data-number="15.2.2">
<h3 data-number="15.2.2" class="anchored" data-anchor-id="sec-wavelength-effects"><span class="header-section-number">15.2.2</span> Wavelength effects in silicon sensors</h3>
<p>There are several wavelength-dependent effects worth noting about silicon sensors. First, we can calculate the energy in Joules of a photon of wavelength <span class="math inline">\(\lambda\)</span> using this the photon energy formula:</p>
<p>We can convert from Joules (J) to electron volts (eV) with this formula</p>
<p><span id="eq-joules-ev"><span class="math display">\[
1~\text{eV} = {1.602 \times 10^{-19}}~\text{J}
\tag{15.1}\]</span></span></p>
<p>A wavelength of 1100 nm has just enough energy (1.12 eV) to transition an electron across the bandgap: Thus, silicon sensors are insensitive to electromagnetic radiation beyond 1100 nm and infrared sensors must use a different material. Second, photons with wavelengths less than 1100 nm have enough energy to excite electrons across the bandgap, and silicon will absorb radiation at these shorter wavelengths. It is notable that the eye does not encode wavelengths below about 400 nm.</p>
<p>Third, the chance that a photon excites an electron that crosses the bandgrap depends on the photon’s energy level. Higher energy (shorter wavelength) photons are more likely to cause the electron to change bands. For this reason, different wavelengths are absorbed at different spatial depths in the material. Short-wavelength photons are much more likely to generate electrons near the surface compared to long-wavelength photons. Conversely, long-wavelength photons are relatively more likely to generate electrons deeper in the material. This depth-dependence on wavelength has been used to create color image sensors (<a href="sensors-07-innovations.html#sec-sensor-foveon" class="quarto-xref"><span>Section 20.5</span></a>).</p>
</section>
</section>
<section id="sec-cmos-pixel-fsi" class="level2" data-number="15.3">
<h2 data-number="15.3" class="anchored" data-anchor-id="sec-cmos-pixel-fsi"><span class="header-section-number">15.3</span> CMOS Pixel: Front-side illuminated</h2>
<p>CMOS image sensors use photodiodes—and the photoelectric effect—to measure and store the optical light field at the sensor surface. The key technical breakthrough that enabled CMOS sensors was the invention of circuitry to store and then transmit the photon-generated electrons from the photodiode to the computer.</p>
<p>The photodiode and this circuitry are critical parts of the pixel; there are other essential components as well (<a href="#fig-pixel-overview" class="quarto-xref">Figure&nbsp;<span>15.2</span></a>). For example, effective image sensors place a small lens (microlens) above each pixel. Color image sensors place a color filter between the microlens and the photodiode that passes certain wavelengths and blocks others.</p>
<div id="fig-pixel-overview" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pixel-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/sensors/14-pixels/03-pixel-overview.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pixel-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.2: Schematic of the early CMOS pixel architecture. This image shows a microlens and color filter, which are typically part of the pixel. The microlens is centered over the pixel here, but for pixels at the edge of the sensor array it will be positioned a bit to the side. This color filter passes long wavelength (red-appearing) light, but different pixels will have different color filters. The first layer of silicon, with its photodiode and classic circuitry sharing space, are shown. Source: <a href="https://evidentscientific.com/en/microscope-resource/knowledge-hub/digital-imaging/cmosimagesensors" target="_blank">Evident Scientific.</a>
</figcaption>
</figure>
</div>
<p><a href="#fig-pixel-overview" class="quarto-xref">Figure&nbsp;<span>15.2</span></a> is a schematic that omits many details. For example, notice the gap between the photodiode and the color filter. In early CMOS imagers, this gap contained many metal lines that carried control and data signals. The metal lines were organized into layers and they are illustrated in <a href="#fig-pixel-layers" class="quarto-xref">Figure&nbsp;<span>15.3</span></a>. In the first generation of image sensors the distance from the microlens at the top to the photodiode at the bottom was fairly large compared to the size of the photodiode. In these early pixels, light from the main lens had to travel through what was effectively a tunnel to reach the photodiode.</p>
<div id="fig-pixel-layers" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pixel-layers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/sensors/14-pixels/03-pixel-overview2.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pixel-layers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.3: Color imagers use an array of color filters to create pixels with different wavelength selectivity. The color filters are typically arranged in a repeating pattern, and the smallest repeating unit of the color filter array is called a <strong>super pixel</strong>. The image illustrates a super pixel for a sensor with cyan, magenta, and yellow color filters. This image emphasizes the metal lines, omitted in <a href="#fig-pixel-overview" class="quarto-xref">Figure&nbsp;<span>15.2</span></a>. In the original CMOS imagers, light from the main imaging lens had to pass through these metal layers before reaching the photodiode.
</figcaption>
</figure>
</div>
<!-- fig-pixel-layers:  not sure where this image comes from -->
<p>Pixel architecture has evolved significantly over the years, and there continue to be many novel designs. The most straightforward change is that technology has scaled, enabling pixel sizes to shrink and thus increasing spatial sampling resolution. In addition, the placement of the circuitry and metal lines has changed to below the photodiode; light no longer passes through a deep tunnel. There are other improvements to the circuitry, some experimental, that we will review later in <a href="sensors-07-innovations.html" class="quarto-xref"><span>Chapter 20</span></a>. It is helpful to first understand the concepts behind the classic circuitry, so that we can better appreciate these innovations.</p>
<p>The logical flow of the circuitry is as follows:</p>
<ul>
<li>Before image capture, the sensor circuitry resets each pixel, clearing residual charge from previous exposures.</li>
<li>During image acquisition, the photodiode array collects electrons generated by incoming light; these electrons are stored within the photodiode (3T) or in a nearby capacitor (4T).</li>
<li>During readout, the circuitry transfers the stored charge to an analog-to-digital converter (ADC).</li>
<li>The digital image array records the amount of light captured by each pixel.</li>
</ul>
<p>The role of the other essential pixel components, the color filter arrays and microlenses, is explained in Section <a href="sensors-04-components.html" class="quarto-xref"><span>Chapter 17</span></a>. In <a href="sensors-06-characterization.html#sec-system-modeling-overview" class="quarto-xref"><span>Section 19.1</span></a> I describes how to calibrate and model sensor performance, from the scene light field to image capture.</p>
</section>
<section id="sec-sensor-circuits" class="level2" data-number="15.4">
<h2 data-number="15.4" class="anchored" data-anchor-id="sec-sensor-circuits"><span class="header-section-number">15.4</span> CMOS circuits</h2>
<section id="sec-3T-pixel-design" class="level3" data-number="15.4.1">
<h3 data-number="15.4.1" class="anchored" data-anchor-id="sec-3T-pixel-design"><span class="header-section-number">15.4.1</span> Three-Transistor (3T) Pixel Design</h3>
<div id="fig-sensor-3T-circuit" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sensor-3T-circuit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/sensors/14-pixels/03-3T-circuit.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sensor-3T-circuit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.4: The original CMOS 3-transistor (3T) circuit design (<span class="citation" data-cites="Fossum1997-early">Fossum (<a href="references.html#ref-Fossum1997-early" role="doc-biblioref">1997</a>)</span>).
</figcaption>
</figure>
</div>
<p>The original CMOS pixel design uses a three-transistor (3T) circuit to store and read out the charge collected by the photodiode (<a href="#fig-sensor-3T-circuit" class="quarto-xref">Figure&nbsp;<span>15.4</span></a>). Each pixel contains three key transistors: <span class="math inline">\(M_{rst}\)</span> (reset), <span class="math inline">\(M_{sel}\)</span> (select), and <span class="math inline">\(M_{sf}\)</span> (source follower). The <span class="math inline">\(M_{rst}\)</span> transistor resets the photodiode by connecting it to the supply voltage (Vdd), clearing any residual charge before image capture. The <span class="math inline">\(M_{sel}\)</span> transistor selects a specific row of pixels, connecting them to the readout circuitry. The <span class="math inline">\(M_{sf}\)</span> transistor acts as a buffer, transferring the stored charge to the analog-to-digital converter (ADC) for measurement. In most sensors, each column has its own ADC, but some designs use a single ADC shared among multiple columns—a technique known as multiplexing (mux).</p>
<p>Ideally, the photodiode’s response to light is linear, with the number of generated electrons following Poisson statistics. However, the surrounding circuitry introduces additional sources of noise and nonlinearity. For example, the storage capacitor has a limited capacity, so it can saturate at high light levels. The transistors used for readout can also introduce noise and small nonlinearities. Furthermore, variations in pixel properties across the sensor array can cause fixed-pattern noise. In modern CMOS sensors, these nonlinearities and noise sources are typically small—on the order of a few percent <span class="citation" data-cites="Wang2017-CMOSLinearity">(<a href="references.html#ref-Wang2017-CMOSLinearity" role="doc-biblioref">Wang and Theuwissen 2017</a>)</span> -but they can still affect image quality. Careful characterization and calibration are necessary to minimize these effects and produce high-quality images.</p>
<!-- 
 (http://encyclopedia2.thefreedictionary.com/Vdd also the drain voltage), Vrst is the reset voltage Vee is the negative supply voltage Ground is ground
http://en.wikipedia.org/wiki/Active_pixel_sensor , http://encyclobeamia.solarbotics.net/articles/vxx.html , 
http://en.wikipedia.org/wiki/Active_pixel_sensor , http://encyclobeamia.solarbotics.net/articles/vxx.html , 
Vdd is positive supply voltage  (http://encyclopedia2.thefreedictionary.com/Vdd also the drain voltage), Vrst is the reset voltage Vee is the negative supply voltage Ground is ground
-->
</section>
<section id="sec-4T-pixel-design" class="level3" data-number="15.4.2">
<h3 data-number="15.4.2" class="anchored" data-anchor-id="sec-4T-pixel-design"><span class="header-section-number">15.4.2</span> Four-Transistor (4T) pixel design</h3>
<div id="fig-sensor-4T-circuit" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sensor-4T-circuit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/sensors/14-pixels/03-4T-circuit.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sensor-4T-circuit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.5: The 4T pixel circuit introduces a pinned photodiode and an additional transistor. When activated, the new transistor transfers the accumulated charge from the photodiode to a storage capacitor (the floating diffusion node, <span class="math inline">\(C_{fd}\)</span>). The rest of the circuit, including readout and row select, is similar to the 3T design.
</figcaption>
</figure>
</div>
<p>Since about 2000, most CMOS image sensors have used a four-transistor (4T) pixel circuit <span class="citation" data-cites="Fossum2014-pinnedpd">(<a href="references.html#ref-Fossum2014-pinnedpd" role="doc-biblioref">Fossum and Hondongwa 2014</a>)</span>. The 4T pixel adds two important features: a pinned photodiode (PPD) and a transfer gate transistor (<a href="#fig-sensor-4T-circuit" class="quarto-xref">Figure&nbsp;<span>15.5</span></a>). The pinned photodiode improves charge storage and reduces noise, while the transfer gate allows precise movement of the collected charge from the photodiode to a storage node called the floating diffusion, which has a capacitance <span class="math inline">\(C_{fd}\)</span>. The other circuit elements—reset, row select, and source follower—remain the same as in the 3T design.</p>
<p>The transfer gate and floating diffusion give the circuit better control over when and how charge is transferred and measured, which helps reduce noise and improve image quality.</p>
<p>Today, the 4T pixel is the standard in almost all high-performance CMOS image sensors, including those found in smartphones, industrial cameras, cars, and scientific instruments.</p>
<!--
There is also Theuwissen diagram, with five transistors that he calls a 4T circuit.  In the paper 'Linearity analysis ...' @Wang2017-CMOSLinearity.  He says the source follower is shared by multiple rows of pixels. It is Figure 2.  

The text: "Figure 2 shows the schematic of a typical voltage mode 4T pixel. The pixel circuit consists of a pinned photodiode, a charge
transfer switch (M1), a reset switch (M2), a source follower (M3) and a row select switch (M4). The current source transistor (M5) is shared by multiple rows of pixels. VDD is the power supply while VPIX is the output voltage of pixel. VLN provides an adjustable bias current. In the following analysis, the nonlinearity caused by the row select transistor (M4) is omitted to simplify the analysis."
-->
</section>
</section>
<section id="multiplex-readout" class="level2" data-number="15.5">
<h2 data-number="15.5" class="anchored" data-anchor-id="multiplex-readout"><span class="header-section-number">15.5</span> Multiplex readout</h2>
<p>The use of unity gain amplifiers at the pixel was one important innovation. A second innovation is the way the pixel data are read from the image sensor. In the original CCD devices, the important innovation was to find a way to move the electrons across the silicon array to a single analog-to-digital converter. But the electrons in the CMOS pixels are voltages on a large number of output lines. How shall we convert the voltages on all of these separate lines into digital readout values?</p>
<div id="fig-cmos-multiplex" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cmos-multiplex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/sensors/14-pixels/03-CMOS-multiplex-readout.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cmos-multiplex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.6: Multiplex readout of the image sensor. The analog-to-digital converters are very fast. Each ADC serves to convert the readout voltages from multiple columns during the readout process.
</figcaption>
</figure>
</div>
<p>The readout process begins with a control signal sent to a specific row of pixels, activating the row and placing the voltage from each pixel onto its corresponding column readout line. These column lines are connected to amplifiers, which buffer and amplify the signals to ensure accurate transmission. These amplified signals are then passed to an analog-to-digital converter (ADC). The gain settings on the amplifiers, prior to the ADC, are often adjustable allowing gain settings from 1x to 4x.</p>
<p>In most CMOS sensors, ADCs are shared among groups of columns to reduce complexity and save space. This sharing is achieved through a process called <strong>multiplexing</strong>, where the ADC sequentially converts the analog signals from each column in its group into digital values. Typically, ADCs multiplex signals from 8 or 16 columns, depending on the sensor design and application. Once the data from the active row is fully read out, the control signal moves to the next row, and the process repeats.</p>
</section>
<section id="sec-rolling-shutter" class="level2" data-number="15.6">
<h2 data-number="15.6" class="anchored" data-anchor-id="sec-rolling-shutter"><span class="header-section-number">15.6</span> Rolling shutter</h2>
<p>So that all of the pixels have the same exposure duration, it is necessary to reset and integrate the pixels in each row a little before the pixels in the subsequent row. Thus, the data in each row is captured a little bit before the data in each of the following rows. This sequential row-by-row readout introduces a temporal pattern known as a <strong>rolling shutter</strong> into the image data.</p>
<p><a href="#fig-rolling-shutter" class="quarto-xref">Figure&nbsp;<span>15.7</span></a> illustrates the impact of this readout timing. The telephone poles captured in by this CMOS camera from a bullet train in Japan appear slanted. This is because the train is moving quickly, and the rows at the top are captured before the rows at the bottom. During this time, the telephone pole has shifted position to the right. The Japanese are very good at construction: the poles are straight. Very straight.</p>
<div id="fig-rolling-shutter" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rolling-shutter-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<video src="images/sensors/14-pixels/rollingShutter-movie.mp4" class="img-fluid" style="width:60.0%" controls=""><a href="images/sensors/14-pixels/rollingShutter-movie.mp4">Video</a></video>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rolling-shutter-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.7: Movie illustrating a rolling shutter capture effect.
</figcaption>
</figure>
</div>
<p>Technology developments described below enable a different capture method. Some memory is put into each pixel, enabling the sensor to store the pixel value locally. All of the pixels are exposed at the same time, and the data is stored in the local memory. This design, called a <span id="def-global-shutter"><strong>global shutter</strong></span> eliminates the rolling shutter effect.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Rolling shutter simulation">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Rolling shutter simulation
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>This <a href="../code/03Sensor/fise_sensorRollingShutter.html" target="_blank">ISETCam script</a> simulates a rolling shutter. The timing and spatial parameter details of the sensor are included.</p>
<div id="fig-rolling-shutter-simulated" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rolling-shutter-simulated-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/sensors/14-pixels/rolling-shutter-simulated.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rolling-shutter-simulated-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.8: Simulated rolling shutter effect.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="sec-sensor-evolution" class="level2" data-number="15.7">
<h2 data-number="15.7" class="anchored" data-anchor-id="sec-sensor-evolution"><span class="header-section-number">15.7</span> Sensor evolution</h2>
<p>There has been a large engineering effort to reduce various sources of noise, including temporal and fixed pattern noise, as well as other limitations in the sensor design relating to color and dynamic range. The engineering effort was supported by the enormous demand for CMOS sensors. In 2020, approximately 6.5 billion sensors were shipped. In 2025, we expect about 13 billion sensors to be produced. That’s a lot of sensors and the demand motivates a lot of engineering. This section covers the evolution of the pixel and sensor design.</p>
<p>The sensor architecture I have described is known as <strong>front-side illumination (FSI)</strong>. The architecture has the obvious challenge of placing multiple metal layers above the semiconductor substrate (<a href="#fig-pixel-layers" class="quarto-xref">Figure&nbsp;<span>15.3</span></a>). Even at the time of the original implementation, it was clear that requiring light to pass through the metal layers to reach the light-sensitive photodiode created many problems.</p>
<p>Additionally, both the photodiodes and their associated circuitry share the same substrate. Requiring the circuitry and photodiode to share space reduced the sensitivity of the sensor. Finally, the original pixels were fairly large, <span class="math inline">\(6 \mu \text{m}\)</span> or more. As technology scaled and pixels became smaller -many CMOS imagers have pixels as small as <span class="math inline">\(0.8 \mu \text{m}\)</span> and a reduction in area of <span class="math inline">\(50x\)</span>- additional problems arose. Different opportunities arose as well.</p>
<p>These challenges, and the huge success of CMOS sensors, were met by a massive, world-wide, engineering effort to improve the system. The evolution of image sensor pixel technology that came from this effort enabled dramatic improvements in image quality, sensitivity, and device functionality. The following sections describe the key milestones that were achieved through academic and industry partnerships. For an authoritative review, consult <span class="citation" data-cites="Oike2022-stackedevolution">Oike (<a href="references.html#ref-Oike2022-stackedevolution" role="doc-biblioref">2022</a>)</span>.</p>
<!--# https://www.pcmag.com/how-to/whats-the-difference-between-cmos-bsi-cmos-and-stacked-cmos 
https://news.skhynix.com/evolution-of-pixel-technology-in-cmos-image-sensor

https://image-sensors-world.blogspot.com/2023/06/sonys-world-first-two-layer-image.html

-->
<div class="callout callout-style-default callout-note callout-titled" title="Pixel Evolution timeline">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Pixel Evolution timeline
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<!-- See Research doc 'The Genesis and Evolution of Stacked Pixel Structures ....' -->
<p>Here is a timeline for the key milestones described in the sections below.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 29%">
<col style="width: 19%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Technology</th>
<th>Commercialization</th>
<th>Key Benefit</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Front-Side Illumination (FSI)</strong></td>
<td>1990s–2000s</td>
<td>Simplicity, but limited by wiring obstruction</td>
</tr>
<tr class="even">
<td><strong>Back-Side Illumination (BSI)</strong></td>
<td>~2007–2010</td>
<td>Higher QE, better low-light, smaller pixels</td>
</tr>
<tr class="odd">
<td><strong>Deep Trench Isolation (DTI)</strong></td>
<td>~2010s</td>
<td>Reduced crosstalk, higher pixel density</td>
</tr>
<tr class="even">
<td><strong>Deep Photodiode</strong></td>
<td>~2015+</td>
<td>Higher sensitivity, dynamic range</td>
</tr>
<tr class="odd">
<td><strong>Stacked Sensor</strong></td>
<td>~2015+</td>
<td>Advanced features, compact design</td>
</tr>
</tbody>
</table>
<!--
- **Front-Side Illumination (FSI):** Early standard; light passes through wiring before reaching the photodiode.
- **Back-Side Illumination (BSI):** Introduced ~2010; light enters from the back, improving efficiency for small pixels.
- **Deep Trench Isolation (DTI):** Early 2010s; insulating trenches reduce crosstalk between pixels.
- **Deep Photodiode:** Mid-2010s; deeper photodiodes increase sensitivity and dynamic range.
- **Stacked Sensor:** Mid-2010s onward; sensor and circuitry are stacked for advanced features and compact design.


- **Front-Side Illumination (FSI) (1970s–2000s)**
    - Standard architecture for early CCD and CMOS sensors.
    - Light enters from the front, passing through metal wiring and transistors before reaching the photodiode.
    - Wiring blocks some light, reducing quantum efficiency, especially as pixel sizes shrink.

- **Back-Side Illumination (BSI) (Late 2000s, commercialization ~2007–2010)**
    - Sensor wafer is thinned and flipped so light enters from the back, directly reaching the photodiode.
    - Dramatically improves quantum efficiency, especially for small pixels.
    - First widely adopted in smartphone cameras (e.g., iPhone 4 in 2010).

- **Deep Trench Isolation (DTI) (Early 2010s)**
    - Introduced to reduce electrical and optical crosstalk between pixels.
    - Trenches filled with insulating material are etched between pixels, confining photo-generated electrons.
    - Enables higher pixel density and better color fidelity.

- **Deep Photodiode (Mid 2010s)**
    - Photodiodes are engineered to extend deeper into the silicon substrate.
    - Increases the volume for photon absorption, improving sensitivity and full-well capacity.
    - Particularly beneficial for small pixels and high dynamic range imaging.

- **Stacked Sensor (3D Stacking) (Mid–Late 2010s)**
    - Sensor and circuitry are fabricated on separate silicon layers and then stacked (bonded) together.
    - Allows for more complex circuitry (e.g., faster readout, on-chip memory, AI processing) without sacrificing pixel area.
    - Now common in high-end smartphone and professional sensors.
  
  -->
</div>
</div>
</div>
</section>
<section id="sec-sensor-bsi" class="level2" data-number="15.8">
<h2 data-number="15.8" class="anchored" data-anchor-id="sec-sensor-bsi"><span class="header-section-number">15.8</span> Back-side illuminated (BSI)</h2>
<p>After years of incremental improvements, engineers developed a new architecture to overcome the limitations of front-side illuminated (FSI) sensors. The resulting design, known as <strong>Back-Side illuminated (BSI)</strong> CMOS, rearranges the device layers to improve sensitivity. In BSI sensors, the photodiode and wiring layers are flipped; the light no longer needs to pass through the wires.</p>
<div id="fig-sensor-bsi2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sensor-bsi2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/sensors/14-pixels/03-sensor-bsi2.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sensor-bsi2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.9: The back-side illuminated pixel. (a) The front-side illuminated pixel has metal lines above the silicon substrate. (b) The back side illuminated sensor flips the metal lines and silicon substrate. Source: <a href="https://scientificimaging.com/knowledge-base/front-side-illuminated-and-back-side-illuminated-imagers" target="_blank">Scientific Imaging.</a>
</figcaption>
</figure>
</div>
<p>In addition to flipping the order of the silicon and wires, it was necessary to change the thickness of the substrate (<a href="#fig-sensor-bsi2" class="quarto-xref">Figure&nbsp;<span>15.9</span></a>). In the FSI pixel, the photodiode is embedded in a relatively thick layer of silicon. Flipping this structure would require the light to pass through a substantial amount of silicon prior to reaching the photodiode. This is problematic because the silicon absorbs light, and particularly short-wavelength light (<a href="sensors-04-components.html#sec-sensor-wavelength" class="quarto-xref"><span>Section 17.3</span></a>). Thus, it was necessary to find a way to thin the silicon substrate and still have a working photodiode and circuitry.</p>
<div id="sensor-bsi" class="callout callout-style-default callout-note callout-titled" title="BSI technology development">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
BSI technology development
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>The concept of back-side illuminated (BSI) CMOS image sensors was first proposed by Eric Fossum in 1994 to address the limitations caused by metal wiring obstructing incoming light and to improve sensitivity. While the benefits of rearranging the sensor layers were clear to many, developing a practical manufacturing process proved challenging. It took more than a decade for BSI technology to become commercially viable. OmniVision Technologies was among the first to introduce a commercial BSI sensor, releasing the OV8810 (1.4 μm pixels, 8 megapixels) in September 2008. Sony soon followed, launching the first widely adopted BSI sensors in 2009. See more in this <a href="https://en.wikipedia.org/wiki/Back-illuminated_sensor">Wikipedia article on BSI</a>.</p>
<p>Here is an SEM cross section of an early BSI sensor from Sony. You can see the photodetector (PD) is close to the microlens array level without all the intervening metal layers.</p>
<div id="fig-bsi-sony-sem" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bsi-sony-sem-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/sensors/14-pixels/sensor-bsi-SEM.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bsi-sony-sem-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.10: Sony 1.65 micron BSI sensor. Source: <a href="https://image-sensors-world.blogspot.com/2010/02/isscc-2010-sony-165um-bsi-pixel-cross.html">Image Sensors World</a>
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="sec-sensor-deepdiode" class="level2" data-number="15.9">
<h2 data-number="15.9" class="anchored" data-anchor-id="sec-sensor-deepdiode"><span class="header-section-number">15.9</span> Deep photodiodes</h2>
<p><a href="#fig-sensor-skhynix" class="quarto-xref">Figure&nbsp;<span>15.11</span></a> illustrates a further improvement in the BSI design. SK Hynix, Omnivision and other manufacturers recognized that simply flipping the sensor (BSI) improved light capture. But as pixel sizes continued to shrink there was relatively little ability to store electrons. Thus the well capacity was reduced which limited the pixel’s dynamic range (<a href="sensors-03-parameters.html#sec-wellcapacity-dynamicrange" class="quarto-xref"><span>Section 16.3</span></a>). Moreover, the sensitivity to longer wavelengths, which penetrates deeper into silicon, became a challenge (<a href="sensors-04-components.html#sec-sensor-wavelength" class="quarto-xref"><span>Section 17.3</span></a>).</p>
<p>To overcome these limitations, many vendors invented methods to build photodiodes that extend significantly deeper into the silicon (deep photodiode technology). Increasing the volume of the photodiode has two benefits. First, the photodiode can gather more charge before saturating. Second, the photodiode has higher long-wavelength sensitivity.</p>
<div id="fig-sensor-skhynix" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sensor-skhynix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/sensors/14-pixels/03-sensor-bsi.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sensor-skhynix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.11: Deep photodiodes in the BSI. (a) A super pixel of a front-side illuminated CMOS sensor, including the microlenses, color filters, metal lines, and silicon. (b) A back-side illuminated super pixel with deep photodiode technology. Source: <a href="https://news.skhynix.com/evolution-of-pixel-technology-in-cmos-image-sensor/" target="_blank">Skhynix.</a>
</figcaption>
</figure>
</div>
</section>
<section id="sec-sensor-stacked" class="level2" data-number="15.10">
<h2 data-number="15.10" class="anchored" data-anchor-id="sec-sensor-stacked"><span class="header-section-number">15.10</span> Stacked sensors</h2>
<p>In the original planar technology, photodiodes are adjacent to the transistor circuits within the silicon substrate. Thus, photodiodes must compete for space with the transistors. Reducing the photodiode area means less light efficiency; reducing the transistor size means noisier performance. Youse pays yer money and yer makes yer choice.</p>
<p>The <strong>stacked sensor</strong> architecture overcomes this limitation by physically separating the photodiode layer from the readout and processing circuitry. In a stacked sensor, the photodiodes occupy one silicon layer, while the supporting electronics are fabricated on a separate layer beneath. This structure maximizes the light-sensitive area (fill factor) for each pixel and enables the use of more advanced, lower-noise circuitry without sacrificing pixel size.</p>
<div id="fig-sensor-stacked" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sensor-stacked-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/sensors/14-pixels/03-pixel-stacked.png" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sensor-stacked-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.12: Pixels in the stacked sensor are based on die stacking technology. Several layers of silicon that are bonded and connected using Through-Silicon Via (TSV) technology. The technology began with 2-layers, but when have you ever known Silicon Valley to stop?
</figcaption>
</figure>
</div>
<p>The key enabling technology is called <strong>die stacking</strong>. The silicon layers are bonded together and electrically connected using two main methods. The original approach used <strong>Through-Silicon Vias (TSVs)</strong>—tiny holes etched through the silicon and filled with a conductive material (such as copper or tungsten) to create vertical electrical connections.</p>
<p>More recently, <strong>Cu-Cu (copper-to-copper)</strong> direct bonding has become common. In this method, patterned copper pads on each wafer are precisely aligned and bonded under heat and pressure, allowing for dense, fine-pitch interconnects between the pixel and logic layers. Cu-Cu bonding is ideal for high-resolution, high-speed sensors, enabling features like per-pixel memory used for <a href="#def-global-shutter">global shutters</a> which are sold by many companies. TSVs are still used for tasks such as power delivery and global I/O routing.</p>
<p>Stacked sensors have unlocked new capabilities in image sensor design. By separating the photodiode and circuitry layers, manufacturers can improve light sensitivity, reduce noise, and add advanced processing features directly beneath the pixel array. This architecture forms the foundation for ongoing innovation in sensor performance and functionality.</p>
<!-- 
Stacked Sensor Structures Google doc 
A significant step towards multi-layer integration was taken by Mitsumasa Koyanagi of Tohoku University, who pioneered the technique of wafer-to-wafer bonding with TSV in 1989
-->
<div class="callout callout-style-default callout-note callout-titled" title="Stacked sensor applications">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Stacked sensor applications
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Stacked CMOS sensors build on the BSI CMOS architecture by integrating the pixel array with a separate logic layer. This close integration enables advanced features such as high dynamic range (HDR) imaging, faster frame rates, and on-chip processing—including artificial intelligence (AI) functions.</p>
<p>Some stacked sensors incorporate high-speed DRAM directly beneath the pixel array, allowing for rapid data readout and temporary storage. This architecture made possible innovations like the Sony a9 (2019), which could capture images at 20 frames per second (fps) with a continuous, blackout-free viewfinder experience.</p>
<div id="fig-sem-cmos-stacked" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sem-cmos-stacked-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/sensors/14-pixels/CMOS-stacked-Sony.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sem-cmos-stacked-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.13: Scanning electron microscope (SEM) image of a cross section through a Sony stacked CMOS image sensor. The image was published in a <a href="https://image-sensors-world.blogspot.com/2023/06/sonys-world-first-two-layer-image.html">blog post</a> by Image Sensors World in 2023. The article describes many of the components in detail.
</figcaption>
</figure>
</div>
<p>The complexity of the silicon and the multiple functions achieved by these stacked sensors is very impressive; it reminds me of the complexity of the retina. Many important functions for image systems are integrated into these sensing devices, and these functions are typically localized in space. Many other functions are carried out in the central processing units which have access to the image across larger regions of the visual field.</p>
</div>
</div>
</div>
</section>
<section id="sec-digital-pixel" class="level2" data-number="15.11">
<h2 data-number="15.11" class="anchored" data-anchor-id="sec-digital-pixel"><span class="header-section-number">15.11</span> Digital pixel sensor</h2>
<p>The Digital Pixel Sensor (DPS) was a significant parallel development in image sensor technology. The initial ideas were presented in the mid 1990s, at roughly the same time as the APS 3T and 4T circuits were implemented. The APS circuitry included an analog-to-digital conversion (ADC) at the column or chip level. The DPS architecture extended the pixel circuit by including an ADC within the pixel circuit <span class="citation" data-cites="fowler1995-dps-patent">Fowler and El (<a href="references.html#ref-fowler1995-dps-patent" role="doc-biblioref">1995</a>)</span> <span class="citation" data-cites="Udoy2025-dps-review">Udoy et al. (<a href="references.html#ref-Udoy2025-dps-review" role="doc-biblioref">2025</a>)</span>.</p>
<p>Digitizing the signal at the pixel had several advantages for high dynamic range imaging, global shuttering and readout speed (<span class="citation" data-cites="elgamal2005-cmos-imagesensors">El Gamal and Eltoukhy (<a href="references.html#ref-elgamal2005-cmos-imagesensors" role="doc-biblioref">2005</a>)</span>, <span class="citation" data-cites="kleinfelder2001-10000fps">Kleinfelder et al. (<a href="references.html#ref-kleinfelder2001-10000fps" role="doc-biblioref">2001</a>)</span>, <span class="citation" data-cites="Wandell2002-CommonPrinciples">Wandell et al. (<a href="references.html#ref-Wandell2002-CommonPrinciples" role="doc-biblioref">2002</a>)</span>). An important feature of the original digital pixel sensors was that the pixel voltage was read non-destructively and repeatedly, say at 1 ms, 2 ms, 4 ms, and so forth. As the photon generated electrons increased in the well, the voltage was sampled. The voltage for each pixel was reported when the pixel had passed one half well capacity, assuring it was much larger than the noise. It would be reported at a time before the well capacity was reached, so that it was below saturation. The information from each pixel was the voltage and the time at which it reached that voltage. Thus, each pixel had its own exposure duration -or put another way, the sensor had a space-varying exposure duration. Pixels in dark regions of the scene had longer exposure times than pixels in the bright regions. We explain the value of this approach for high dynamic range imaging in <a href="sensors-05-control.html#sec-exposure-control" class="quarto-xref"><span>Section 18.3</span></a>.</p>
<p>The DPS concept was introduced at an early point in the development of CMOS imagers, and thus it faced significant hurdles in miniaturization. The idea of an ADC on the sensor foreshadowed an opportunity that has arisen as pixel architecture evolves. The stacked pixel structure offers a remedy by allowing the ADC and memory circuits to be placed in a separate layer underneath the photodiode. This enables higher pixel density and broader application of in-pixel conversion. The next generation of image sensors will implement the DPS concept (<span class="citation" data-cites="fossum2024-arvs">Fossum et al. (<a href="references.html#ref-fossum2024-arvs" role="doc-biblioref">2024</a>)</span>).</p>
<div class="callout callout-style-default callout-note callout-titled" title="Commercialization of the digital pixel sensor">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Commercialization of the digital pixel sensor
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>El Gamal co-founded Pixim, Inc.&nbsp;in 1998, a fabless semiconductor company that commercialized chipsets for security cameras based on this DPS technology. A challenge for early DPS implementations was the reduced photodiode area in the planar array due to the additional ADC circuitry. This increased the cost of the chip and narrowed the field of potential applications and prevented widespread mainstream adoption for many years. Pixim was acquired by Sony Electronics in 2012.</p>
<p>In 2023 Sony introduced the <a href="https://en.wikipedia.org/wiki/Sony_%CE%B19_III">Sony a9 iii</a>. It has 24.6 Megapixels and a global shutter. The camera can operate at high frame rates <a href="https://www.sony.co.uk/interchangeable-lens-cameras/products/ilce-9m3?locale=en_GB">(120 frames per sec)</a>. It appears to be using a digital pixel approach.</p>
<p>It’s highly probable that <a href="https://sites.google.com/site/yusukeoike">Yusuke Oike</a> who worked in the El Gamal group from 2010-2012, played a crucial role in the development and design of the groundbreaking global shutter sensor that is at the core of the a9 III’s capabilities. He has been with Sony Corporation and Sony Semiconductor Solutions Corporation for many years, focusing on research and development of CMOS image sensors, pixel architecture, circuit design, and imaging device technologies. He’s held positions like Senior General Manager of Research Division and is even listed as the newly appointed CTO of Sony Semiconductor Solutions Corporation in a 2025 news release.</p>
</div>
</div>
</div>



<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-elgamal2005-cmos-imagesensors" class="csl-entry" role="listitem">
El Gamal A, Eltoukhy H (2005) <span>CMOS</span> image sensors. IEEE Circuits and Devices Magazine 21:6–20
</div>
<div id="ref-Fossum1997-early" class="csl-entry" role="listitem">
Fossum ER (1997) <span>CMOS</span> image sensors: <span>Electronic</span> camera-on-a-chip. IEEE Transactions on Electron Devices 44:1689–1698
</div>
<div id="ref-Fossum2014-pinnedpd" class="csl-entry" role="listitem">
Fossum ER, Hondongwa DB (2014) <a href="http://dx.doi.org/10.1109/jeds.2014.2306412">A review of the pinned photodiode for <span>CCD</span> and <span>CMOS</span> image sensors</a>. IEEE J Electron Devices Soc 2:33–43
</div>
<div id="ref-fossum2024-arvs" class="csl-entry" role="listitem">
Fossum ER, Teranishi N, Theuwissen AJP (2024) <a href="http://dx.doi.org/10.1146/annurev-vision-101322-105538">Digital image sensor evolution and new frontiers</a>. Annu Rev Vis Sci 10:171–198
</div>
<div id="ref-fowler1995-dps-patent" class="csl-entry" role="listitem">
Fowler B, El GA (1995) <a href="https://patentimages.storage.googleapis.com/5e/23/0b/9905270680ea81/US5461425.pdf"><span>U</span>.<span>S</span>. Patent no. 5,461,425</a>. US Patent 5,461,425
</div>
<div id="ref-kleinfelder2001-10000fps" class="csl-entry" role="listitem">
Kleinfelder S, Lim S, Liu X, El Gamal A (2001) <a href="http://dx.doi.org/10.1109/4.972156">A 10000 frames/s <span>CMOS</span> digital pixel sensor</a>. IEEE J Solid-State Circuits 36:2049–2059
</div>
<div id="ref-Oike2022-stackedevolution" class="csl-entry" role="listitem">
Oike Y (2022) <a href="https://ieeexplore.ieee.org/abstract/document/9494712/">Evolution of image sensor architectures with stacked device technologies</a>. IEEE Trans Electron Devices 69:2757–2765
</div>
<div id="ref-Udoy2025-dps-review" class="csl-entry" role="listitem">
Udoy MRI, Alam S, Islam MM, et al (2025) <a href="http://dx.doi.org/10.1109/ACCESS.2025.3526879">A review of digital pixel sensors</a>. IEEE Access 13:8533–8551
</div>
<div id="ref-Wandell2002-CommonPrinciples" class="csl-entry" role="listitem">
Wandell BA, El Gamal A, Girod B (2002) Common principles of image acquisition systems and biological vision. Proceedings of the IEEE 90:5–17
</div>
<div id="ref-Wang2017-CMOSLinearity" class="csl-entry" role="listitem">
Wang F, Theuwissen A (2017) <a href="http://dx.doi.org/10.2352/issn.2470-1173.2017.11.imse-191">Linearity analysis of a <span>CMOS</span> image sensor</a>. IS&amp;T Int Symp Electron Imaging 29:84–90
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/sensors-01-photoelectric.html" class="pagination-link" aria-label="Photons and Electrons">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Photons and Electrons</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/sensors-03-parameters.html" class="pagination-link" aria-label="Sensor parameters">
        <span class="nav-page-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Sensor parameters</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>