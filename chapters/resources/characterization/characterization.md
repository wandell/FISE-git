<div>

[]{.c0}

</div>

[Characterization of Visual Stimuli using the Standard Display
Model]{.c44}

[Joyce E. Farrell 1]{.c0}

[Haomiao Jiang 1]{.c0}

[Brian A. Wandell 1,2]{.c0}

[]{.c0}

[1 Department of Electrical Engineering ]{.c0}

[2 Psychology Department]{.c0}

[Stanford University, Stanford, CA 94305]{.c0}

[]{.c0}

[Corresponding author:]{.c31}  J.E. Farrell,
[[joyce_farrell@stanford.edu](mailto:joyce_farrell@stanford.edu){.c4}]{.c28}

[]{.c0}

[Key Words:]{.c31}[  Display technology, calibration, modeling,
simulation, visual stimuli, psychophysics, pixel point spread function,
spectral power distribution]{.c0}

[]{.c0}

# Introduction {#h.c10xgcgj8jx9 .c37}

[]{.c0}

Human vision science advances by experiments that measure how sensations
and perceptions arise from carefully controlled visual stimuli.
 Progress depends in large part on the type of display technology that
is available to generate visual stimuli. In this chapter, we first
describe the strengths and limitations of the display technologies that
are currently used to study human vision. We then describe a standard
display model that guides the calibration and characterization of visual
stimuli on these displays [[(Brainard et al., 2002; Post,
1992)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/gGuZ%2B0yTJ&sa=D&source=editors&ust=1738042993768375&usg=AOvVaw1KGhKFflieR2ykp5AX5HIs){.c4}]{.c5}.
 We illustrate how to use the standard display model to specify the
spatial-spectral radiance of any stimulus rendered on a calibrated
display.  This model is used by engineers to assess the tradeoffs in
display design, and by scientists to specify stimuli. The ability to
quantify the stimulus is essential for reproducible research and to
support the development of image-computable vision models. Finally, we
discuss trends for new display systems that integrate light generation
with optics, sensors, and computation.  Calibrating and characterizing
such systems will require extending the standard display model through
digital twin simulation, advancing both technology and science.

[]{.c0}

# [Display technologies for vision science]{.c5 .c9 .c13} {#h.pord7a672qc7 .c38}

[]{.c0}

An ideal display system for science and commerce would deliver the
complete spectral, spatial, directional, and temporal distribution of
light rays, as if these rays were generated by a real three-dimensional
scene.  The full radiometric description of light rays in the
three-dimensional scene is called the "light field" [[(Gershun,
1939)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/yLhf&sa=D&source=editors&ust=1738042993769352&usg=AOvVaw1mrpJkajsdtaTCKNas0tEL){.c4}]{.c5}.
 For vision science, the simplified and related stimulus is the portion
of the environmental light field that is incident at the cornea - this
is the only part of the stimulus that the retina encodes. The incident
light field changes as the head and eyes move.  

[]{.c0}

[Most displays fall short of reproducing the incident light field and
lack the capability to dynamically adjust the displayed image in
response to an observer\'s head and eye movements. Despite these
limitations, modern displays create a very compelling perceptual
experience that captures many important perceptual elements of a real
three-dimensional scene.  The ability to control these displays with
computers that have digital frame buffers and graphics cards has greatly
enlarged the range of stimuli used in visual psychophysics compared to
the optical benches and tachistoscopes used by previous
generations.]{.c0}

[]{.c0}

[![](images/image32.png){style="width: 662.00px; height: 329.14px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 662.00px; height: 329.14px;"}

[![](images/image31.png){style="width: 720.00px; height: 345.04px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 720.00px; height: 345.04px;"}

All modern color displays are designed with three types of subpixels
whose spectral power distributions (SPD) peak in the long-, middle- and
short-wavelength regions of the visible spectrum (Figure 1).  Each type
of subpixel is called a display primary and the whole mosaic is called a
color channel.  The relative SPD of each primary is designed to be
invariant as its intensity changes (spectral homogeneity).  In normal
operation, the intensities of the three subpixels are set to match the
color appearance of an experimental stimulus.  Three primaries are used
because human color-matching experiments show that subjects can match
the color appearance of a wide range of spectral power distributions
using the mixture of just three independent light sources [[(Maxwell,
1860; Wandell, 1995; Wyszecki & Stiles,
1982)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/b1Ta%2B2zzl%2BE40X&sa=D&source=editors&ust=1738042993770452&usg=AOvVaw2x1CAci232mQFNyO4slb0k){.c4}]{.c5}.
 Modern displays effectively comprise a very large number of
color-matching experiments, one for each pixel in every frame[. ]{.c0}

[]{.c0}

The three main display technologies used in vision experiments today are
CRTs (cathode ray tubes), LCDs (liquid-crystal displays) and OLEDs
(organic light emitting diodes).  Color CRTs were developed by RCA in
the 1950s [[(Law,
1976)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/Cc3X&sa=D&source=editors&ust=1738042993770797&usg=AOvVaw1_UGZA5NCbPPEK3DNq-LuB){.c4}]{.c5} and
were the nearly universal display technology for several decades. They
remain an important display technology for vision researchers, although
now they are rarely sold as consumer products.  Invented at RCA labs in
the 1970s [[(Kawamoto,
2002)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/Fz8U&sa=D&source=editors&ust=1738042993770936&usg=AOvVaw2oMuytWFkSvJ5wZGyrzoVb){.c4}]{.c5},
LCDs were introduced as small mobile displays in digital watches,
calculators and other handheld devices; later they enabled the
widespread adoption of laptop computers.  OLEDs were invented at Kodak
in the 1980s [[(Tang & Vanslyke,
1987)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/Vf1l&sa=D&source=editors&ust=1738042993771086&usg=AOvVaw3wz9pWBxbStYNO767-bnxt){.c4}]{.c5}[ and
were first introduced as displays for digital cameras. Large OLED
displays are expensive, but they have some advantages over LCDs: they
achieve a deeper black and they have better temporal resolution. ]{.c0}

[]{.c0}

In the realm of vision research, CRTs have long been valued for their
ability to accurately control primary color intensities beyond 10 bits
[[(Brainard et al.,
2002)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/gGuZ&sa=D&source=editors&ust=1738042993771339&usg=AOvVaw1hcfryCI2MuPJCPFipWh6w){.c4}]{.c5},
a critical feature for precise psychophysical experiments.  The
discontinuation of CRT mass production has led scientists to develop
software solutions like ViewPixx and Display++  that enable researchers
to achieve 10 bits of intensity resolution from LCD monitors [[(Ghodrati
et al.,
2015)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/fO5b&sa=D&source=editors&ust=1738042993771585&usg=AOvVaw0rKE2VJZ83yP87t-NEt9Dc){.c4}]{.c5}. 
In recent years, OLED displays have gained popularity due to their
superior contrast ratios and higher refresh rates, making them ideal for
experiments requiring precise temporal control and high-fidelity visual
stimuli [[(Cooper et al.,
2013)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/SSHP&sa=D&source=editors&ust=1738042993771723&usg=AOvVaw1g7BT1aEiSF8lCrt09ePE-){.c4}]{.c5}[.
 ]{.c0}

[]{.c0}

Digital light projection (DLP)  displays [[(Hornbeck,
1991)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/zQ5t&sa=D&source=editors&ust=1738042993772044&usg=AOvVaw2FKkGMGWXy06eNHqTIlxsN){.c4}]{.c5} are
spatial light modulators that use an array of small, deformable mirrors.
 They are not used widely in visual psychophysics.
^[\[a\]](#cmnt1){#cmnt_ref1}^However, they have been adapted for use in
studies of color constancy [[(Brainard, 1998; Brainard et al.,
1997)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/VIgL%2Bg9Yn&sa=D&source=editors&ust=1738042993772396&usg=AOvVaw3Qeo3Z5w1CZxt2iyrzY0GL){.c4}]{.c5},
in vitro primate retina intracellular recordings [[(Packer et al.,
2001)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/sh8P&sa=D&source=editors&ust=1738042993772530&usg=AOvVaw1ypCrB4_0ib97b7-XeAPAx){.c4}]{.c5},
and functional magnetic resonance imaging [[(Engel et al.,
1997)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/Ie9F&sa=D&source=editors&ust=1738042993772682&usg=AOvVaw3uF-e0gPmUzubcecp7Ca7M){.c4}]{.c5}[.
The advantages of DLP technology, such as high contrast ratios, fast
response times, MRI compatibility, and flexibility in stimulus
presentation, have made it a useful tool in these specialized research
applications.]{.c0}

[]{.c0}

MicroLEDs are a promising technology for the next-generation of displays
[[(Jiang et al.,
2002)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/K9T7&sa=D&source=editors&ust=1738042993773063&usg=AOvVaw1fVLLB0S25vLGxnJ0yqItn){.c4}]{.c5}.
 The initial report has been followed up by many groups, both in
academia and industry^[\[b\]](#cmnt2){#cmnt_ref2}^[. At present,
microLEDs are primarily used in compact displays for personal devices
like smartwatches, smartphones, and head-mounted displays. Several
manufacturers have demonstrated the capability to produce large-scale
microLED displays, but widespread consumer adoption hinges on lowering
manufacturing costs.]{.c0}

[]{.c0}

## [Cathode Ray Tubes (CRT)]{.c20 .c9} {#h.t7w398cxzlrd .c16}

[]{.c0}

CRTs  create light by directing an electron beam through a metal shadow
mask onto one of three different types of phosphors [[(Castellano, 1992;
Law,
1976)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/RRqX%2BCc3X&sa=D&source=editors&ust=1738042993773722&usg=AOvVaw1aniUKX2oaRHKzGHvbZAak){.c4}]{.c5}.[ When
irradiated by electrons, each of the phosphors emits light with a
spectral radiance distribution that is unique to that phosphor. The CRT
phosphors are painted on a transparent glass surface in a pattern of
alternating dots or stripes (Figure 2A), and they are selected to emit
predominantly in the long (red), middle (green) and short (blue)
wavebands (Figure 1A).  The amount of light from each type of phosphor
is controlled by the intensity of the electron beam that is incident on
the phosphor.  The spatial properties of the display are determined by
the size and spacing of the phosphor dots or stripes.  ]{.c0}

[]{.c0}

The temporal properties of the display are determined by the frequency
with which each phosphor is stimulated by electrons and the rate at
which the phosphorescence decays (see Figure 3B). The refresh rate is
determined by how fast an electron beam can scan across the many rows of
pixels in a display.  The more rows there are, the more time it takes
for the electron beam to return to the same phosphor dot.  When the
refresh rate is slow and the phosphor decay is fast,  the display
appears to flicker. Longer phosphor decay times reduce the visibility of
flicker, but increase the visibility of motion blur [[(Becker, 2019; J.
E. Farrell, 1986; Travis, n.d.; Y. Zhang et al.,
2007)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/CYWd%2Bjlep%2B7M0a%2BsI2C&sa=D&source=editors&ust=1738042993774274&usg=AOvVaw1FOwWptTMqS9L9L98NuPTO){.c4}]{.c5}.

[]{.c5 .c23 .c9}

[![](images/image30.png){style="width: 672.46px; height: 412.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 672.46px; height: 412.33px;"}

[]{.c5 .c23 .c9}

In addition to scanning through many rows of pixels, the electron beam
intensity modulates as the beam traverses phosphors within each row. The
electron beam modulation rate, referred to as slew rate, is not fast
enough to change perfectly as the beam moves between adjacent pixels.
Consequently, the ability to control the light from adjacent pixels
within a row is not perfectly independent [[(Lyons & Farrell,
1989)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/QEri&sa=D&source=editors&ust=1738042993774705&usg=AOvVaw0qeYE7kqwXi49E3m1ByEVD){.c4}]{.c5}.
 We will explain the consequence of this slew rate limitation on the use
of a standard display model  later in this chapter.

[]{.c0}

## [Liquid Crystal Displays]{.c20 .c9} {#h.l9k1nlecx9xp .c16}

[]{.c0}

LCD displays function as an array of light valves, with each pixel
regulating the amount of light transmitted from a constantly illuminated
backlight. Traditional LCD backlights employ either a white fluorescent
tube or a row of white LEDs positioned along the edge of the LC array,
known as edge-lit configuration. In 2013, Sony introduced the first LCD
television featuring a quantum dot (QD) backlight, a technology that has
since become prevalent in most high-end displays and some laptops. An
LCD QD backlight utilizes a row of blue LEDs that emit light through a
film containing quantum dots. As the blue light traverses this quantum
dot film, a portion is converted into red and green light, resulting in
a combination that produces a white light that reportedly increases the
color gamut of the LCD display [[(Luo et al., 2014; Xu et al.,
2025)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/BBSB%2BXFvh&sa=D&source=editors&ust=1738042993776230&usg=AOvVaw2u_90I-BeXQELAw9cf8mzw){.c4}]{.c5}.
 Regardless of the method used to create the white light, it is
uniformly distributed across the display surface using diffusing and
brightness-enhancing films, ensuring consistent illumination throughout
the screen.

[]{.c0}

[The backlight passes through a polarization filter, a layer of liquid
crystal material, a second polarization filter, and then a color filter
(Figure 4). The ability of photons to traverse this path is controlled
by the alignment of the liquid crystals which determines the
polarization of the photons and thus how much light passes through the
two polarization filters. The state of the liquid crystal in each pixel
is determined by an electric field that is controlled by digital values
in a frame-buffer, under software control. Even when the liquid crystal
is in a state that permits transmission (open), only a small fraction
(about 3 percent) of the backlight photons pass through the two
polarizers, color filter, and electronics. ]{.c0}

[![](images/image33.png){style="width: 621.50px; height: 477.41px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 621.50px; height: 477.41px;"}

[]{.c0}

The spectral radiance of an LCD pixel is determined by the SPD of the
backlight and the transmissivity of the optical elements (polarizers,
LC, and color filters).  The spatial properties of an LCD are determined
by the dimensions of a panel of thin film transistors (TFT) that
controls the voltage for each pixel component and the size and
arrangement of each individual filter in the color filter array.  The
temporal properties of an LCD are determined by the modulation rate of
the backlight and the temporal response of the liquid crystal [[(Yang &
Wu,
2014)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/XJuv&sa=D&source=editors&ust=1738042993777404&usg=AOvVaw3nCSnTZnyi5aPzf2_rG7Lx){.c4}]{.c5}.
LCDs use sample and hold circuitry that keep the liquid crystals in
their "open" or "closed" state (see Figure 4B).   This means that
flicker is not visible, but a negative consequence of the slow dynamics
is that LCDs can produce visible motion blur.  Furthermore,  liquid
crystals respond asymmetrically to an increase or decrease in voltage
(changing the alignment of the liquid crystals).  For example, it is
often the case that a change from white to black is faster than a change
from black to white.  Some LCD manufacturers have introduced circuitry
to "overdrive" and "undershoot" the voltage delivered to each pixel.
 This additional circuitry reduces the visible motion blur but makes it
difficult for the user to have precise control in the timing of visual
stimuli [[(Elze & Tanner,
2012)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/K1CN&sa=D&source=editors&ust=1738042993777717&usg=AOvVaw3jDPaQMgIRO1cXak1YjSgK){.c4}]{.c5}.
 [ ]{.c0}

[]{.c0}

[Another limitation of LCDs is that in the "off" state, photons from the
backlight still find their way through the filters to the viewer.
 Consequently,  LCDs do not achieve a complete black background which
limits their dynamic range.  Manufacturers introduced LED backlit panels
that can be locally dimmed in different regions. In this way, one
portion of the image can be much brighter than another, and a portion of
the display can be nearly black, extending the image dynamic range. Such
LCD displays are difficult to use in calibrated experiments because of
the proprietary software and control circuitry that can vary with the
displayed image.]{.c0}

## [Digital light projectors]{.c20 .c9} {#h.l9rqp3amwtfx .c16}

[]{.c0}

The digital light projector (DLP) display technology is a
micro-electro-mechanical system (MEMS) consisting of an array of
microscopically small mirrors arranged in a matrix on a semiconductor
chip- one mirror for each pixel [[(Florence & Yoder, 1996; Younse,
1993)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/9Bo1%2BabHF&sa=D&source=editors&ust=1738042993778326&usg=AOvVaw1qGJ5IZf5HCK1bydfs0s8m){.c4}]{.c5}[.
Each mirror is on the order of 15 microns in size, and the deformable
mirror arrays can have many different formats (e.g., 4K, 1080p, etc.).  
Like the LCDs, this is a light valve technology. The system includes a
constant backlight, and each mirror can be in one of two states:  it
either reflects the backlight photons towards or away from the viewer. A
typical pixel can change states at a high rate (kilohertz), though some
devices can change much faster.]{.c0}

[]{.c0}

The intensity at each pixel is controlled by varying the percentage of
time the mirror is directing light towards the viewer.  In the
single-chip DLP, color is controlled using a rapidly spinning color
wheel that interposes different color filters between the light source.
The color wheel rotation is synchronized with the control signals sent
to the chip. While most display technologies use subpixel primaries that
are adjacent in space, the DLP color primaries are adjacent in time - a
technique called field-sequential color.  Some DLP devices include only
three (red, green and blue) primaries, while others include a fourth
(white or clear) primary.  The white primary increases the maximum
display brightness, but at the highest brightness levels the display has
a vanishingly small color gamut [[(Kelley et al.,
2009)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/pjWz&sa=D&source=editors&ust=1738042993778761&usg=AOvVaw0xS1kXKD3N9l7XKABzdBOH){.c4}]{.c5}[.
]{.c0}

[]{.c0}

A problem with the single-chip DLP design is that field-sequential color
can produce visible color artifacts when the eye moves rapidly across
the image.  High speed eye movements cause the sequential red, green and
blue images to project to different retinal positions [[(X. Zhang &
Farrell,
2003)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/ayA6&sa=D&source=editors&ust=1738042993779025&usg=AOvVaw0H9tnim9NPanrEqv3MxUFy){.c4}]{.c5}[.
A more expensive three-chip DLP design is often used in home and movie
theatres.  The three-chip design simultaneously projects red, green and
blue images that are co-registered; hence, these DLPs do not produce the
sequential color artifacts.  ]{.c0}

[]{.c0}

## [Organic Light emitting diodes (OLED) ]{.c20 .c9} {#h.77t101ux8v0z .c16}

Conceptually, OLEDs are a much simpler display technology.  Rather than
being a light valve, each pixel in an OLED display is a light source,
and thus they do not require a backlight. [ The device consists of two
layers of organic molecules that are sandwiched between a cathode and an
anode (Figure 5).  OLED pixels emit light when an electric current is
applied to the electroluminescent layer of organic molecules. ]{.c0}

[]{.c0}

There are several ways to produce the different color primaries: (1)
Each diode can be made from a different substance that emits light in a
distinct wavelength band, (2) color filters  can be placed in front of a
single type of diode, or (3) a single type of OLED (usually blue) can be
use to excite different types of phosphors [[(Tsujimura,
2017)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/eUhb&sa=D&source=editors&ust=1738042993780055&usg=AOvVaw1UEszsVWwkZSpmHfTT3Wdk){.c4}]{.c5} or
quantum dots [[(Fan et al.,
2024)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/zuiR&sa=D&source=editors&ust=1738042993780261&usg=AOvVaw1i-T34yFpspek4xAmKdLFD){.c4}]{.c5}.[ 
 This is the same quantum dot technology that is used to create QD-LCD
backlights, except that in this context,  the red, green, and blue light
sources serve as emissive pixels. A significant advantage of OLED
displays is their ability to achieve a very high dynamic range, as each
OLED pixel can be completely black. This characteristic allows for
exceptional contrast and deep blacks in the displayed image.]{.c0}

[]{.c0}

The spatial properties of an OLED display are determined by the size and
 arrangement of the OLED pixels that are deposited onto glass.  Today,
OLED pixels can be as small as 10 micrometers but researchers are
experimenting with OLEDs as small as 100 nanometers [[(Marcato et al.,
2024)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/fGqn&sa=D&source=editors&ust=1738042993780776&usg=AOvVaw3NFsMVpe_bmkUH6YcaNbKs){.c4}]{.c5}. 
 The OLED pixel size varies considerably depending on the type of
display.  For example, pixels can be 100 micrometers or larger on large
format televisions.  Some types of OLEDs (polymer OLEDs or PLEDs) can be
printed onto plastic using a modified inkjet printer[ ]{.c33}[[(Bale et
al.,
2006)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/wEPT&sa=D&source=editors&ust=1738042993781319&usg=AOvVaw1qjMUEN9lddwUv5v_JbWSs){.c4}]{.c5},
or a 3D printer with a spray nozzle [[(Su et al.,
2022)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/ENGQ&sa=D&source=editors&ust=1738042993781487&usg=AOvVaw3LSO8CbJknXG1rn-IMvPKG){.c4}]{.c5}.
These advances in OLED fabrication techniques are driving progress in
display technology, paving the way for higher resolutions, larger
screens, and potentially novel form factors in future display
applications [[(Singh et al.,
2023)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/gCx2&sa=D&source=editors&ust=1738042993781700&usg=AOvVaw2FW3byxLozVknkA0oTcINH){.c4}]{.c5}.

[]{.c0}

The temporal properties of an OLED display are determined by the rate at
which the pixel intensities can be changed (update rate) and the rate at
which the screen is refreshed (refresh rate).  OLEDs can be turned on
and off extremely rapidly (update rate).  Hence, the update rate limits
the motion velocities that can be represented [[(Watson et al.,
1986)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/hv8D&sa=D&source=editors&ust=1738042993782160&usg=AOvVaw3dDjlLXcnV4O7Xdh9XvGI7){.c4}]{.c5}.
 To reduce the visibility of flicker and motion blur, OLEDs can be
refreshed at a rate that exceeds the update rate (see Figure 5B).  This
method is referred to as "pulse-width modulation" [[(Dimigen & Stein,
2024)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/BHJc&sa=D&source=editors&ust=1738042993782367&usg=AOvVaw2fvXhw2sfkQDJpaNgtwo2z){.c4}]{.c5}[.
]{.c0}

[]{.c0}

[![](images/image29.png){style="width: 591.00px; height: 398.19px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 591.00px; height: 398.19px;"}

[]{.c0}

## MicroLEDs {#h.5o5o2xbqds3 .c16}

[]{.c0}

MicroLED displays are a new generation of screen technology. The key
difference from OLED displays is that MicroLEDs use inorganic materials
like gallium nitride (GaN) rather than organic compounds. When current
 flows through these tiny LEDs[, electrons combine with \"holes\" (areas
lacking electrons) to produce light. The intensity of this light depends
on how much current is delivered; this relationship isn\'t linear.  The
current delivered to each pixel in a MicroLED display is controlled by a
thin-film transistor (TFT) in the display\'s backplane.   MicroLEDs
produce color primaries using the same methods as OLEDs - direct
emission, color filters, or color conversion using quantum dots. ]{.c0}

[]{.c0}

MicroLEDs offer several significant advantages compared to current OLED
technology. Their lifespan is remarkably long, about 10[6]{.c30} hours
compared to OLEDs\' 3 x 10[4]{.c30} hours. They\'re also approximately
1,000 times brighter and respond faster to electrical signals. Perhaps
most impressively, MicroLEDs can be made very small, around 1
micrometer [[(Hsiang et al., 2021; Smith et al.,
2020)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/tvR7%2BH7Zs&sa=D&source=editors&ust=1738042993783229&usg=AOvVaw2tGHbP5GUvOku91weM8xR8){.c4}]{.c5}. 

[]{.c0}

MicroLED technology is just appearing in consumer products, including
near-eye displays [[(Bandari & Schmidt, 2024; Huang et al.,
2020)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/bTso%2BAy2a&sa=D&source=editors&ust=1738042993783654&usg=AOvVaw0H7XeLfe4Drnu0CxCsjl8N){.c4}]{.c5}.
Manufacturers have also successfully created large displays using this
technology [[(MiniMicroLED,
2024)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/i16o&sa=D&source=editors&ust=1738042993783790&usg=AOvVaw3i5torGYMEyMSos4kerPQw){.c4}]{.c5}.
Companies are currently developing MicroLED displays for smartphones and
virtual reality headsets. The main challenge now is reducing production
costs to make these displays affordable.

# [The standard display model and stimulus characterization]{.c13 .c5 .c9} {#h.f7efpteuow7l .c16}

## [Overview]{.c20 .c9} {#h.m30buqfttvg .c16}

[]{.c0}

[Display technologies are differentiated by two main factors: the
mechanism used to generate light and the spatial configuration of pixels
and subpixels. When designing commercial displays, manufacturers
prioritize various performance metrics such as energy efficiency,
brightness, spatial resolution, contrast ratio (darkness), color gamut,
and refresh/update rates. The relative importance of these parameters
varies depending on the intended application.]{.c0}

[]{.c0}

Despite the diverse array of display architectures, it is possible to
identify a few fundamental principles that describe the relationship
between electronic control signals and the spectral radiance generated
by a display.  These widely adopted principles form the basis of a
standard display model [[(Brainard et al., 2002; Post,
1992)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/0yTJ%2BgGuZ&sa=D&source=editors&ust=1738042993785250&usg=AOvVaw1pCCIf4hxnTjTHAU5dQnhr){.c4}]{.c5}. This
model is phenomenological in nature, meaning it describes observable
relationships without necessarily explaining the underlying physical
processes. Importantly, this standard display model is applicable not
only to current popular displays but also to anticipated future
developments in display technology.

[]{.c0}

The standard display model\'s parameters can be determined through a
limited number of calibration measurements. The model, combined with the
calibration data, enables precise control over the display\'s radiance
output. A model is necessary because there are far too many images to
calibrate individually [[(Brainard,
1989)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/4u7G&sa=D&source=editors&ust=1738042993785606&usg=AOvVaw1mS5EP3rGxlU75wxZT-a4C){.c4}]{.c5}[.
To illustrate, an 8-bit display can produce 2\^24 distinct RGB
combinations for a single static image. Furthermore, a 1024x1024 pixel
display (2\^20 pixels) has the potential to render an astronomical
2\^480 different images. The standard display model efficiently
addresses this complexity by defining a compact set of calibration
measurements, which can then be used to predict the spectral radiance
for a wide array of images. ]{.c0}

[]{.c0}

Several key measurements are necessary to specify a model for
any particular [display.  First, each subpixel type has a characteristic
spectral power distribution (SPD, Figure 1). The model assumes that the
SPD is the same for all subpixels of a given type and is invariant when
normalized for intensity level.  Thus, the normalized SPD can be
measured using a spectroradiometer that averages the spectral radiance
emitted from a region of the display surface.]{.c0}

[]{.c0}

Second, the absolute level (peak radiance) of the SPD is set by the
frame buffer value. The relationship between the frame buffer value and
the SPD level is referred to as the gamma-curve. The gamma-curve is
assumed to be the same for all subpixels[ of a given type
(shift-invariant),  independent of the image content, and monotone
increasing.  ]{.c0}

[]{.c0}

[Third, the standard display model describes the spatial distribution of
light emitted by each type of subpixel, called the point spread function
(PSF).  The standard display model assumes that the PSF is the same for
subpixels of a given type (shift-invariant) and independent of the image
content. ]{.c0}

[]{.c0}

Finally, most displays refresh the image (frame) at a rate between 30
and 240 times per second. Within each frame, the subpixel  intensity can
rise and fall, and the frame repetitions and pixel dynamics influence
the visibility of motion and flicker.  The standard display model
assumes that each subpixel has a simple time-invariant impulse response
function that is independent of image content.  This assumption is
frequently violated because of the extensive engineering to control the
dynamics of displays (see previous sections on LCDs,  CRTs and OLEDs).
Characterizing the display dynamics is particularly important for
experiments involving rapidly changing high contrast targets (e.g.
random dots).

[]{.c0}

The standard display model clarifies the measurements needed to
calibrate a display. The first two are to measure (a) the normalized
spectral radiance distributions for each of the display primaries, and
(b) the gamma-curve that specifies the absolute level of the spectral
radiance given a particular frame buffer value. It is less common for
scientists to measure the subpixel PSFs.  These can be measured using a
macro-lens and the linear output of a calibrated digital camera [[(J.
Farrell et al.,
2008)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/fUuF&sa=D&source=editors&ust=1738042993786805&usg=AOvVaw1_7RxMPj7pdZIJqviY6AXV){.c4}]{.c5},
but in most cases the function is treated as a single point (impulse).
 Characterizing the PSF can be meaningful for measurements of fine
spatial resolution (e.g., quality of fonts, vernier resolution) where
there are significant effects of human optics on retinal image
formation.[ ]{.c19}In the next section, we offer specific advice about
making these calibration measurements and combining them into a
computational implementation of the standard display model.

## Spectral radiance and gamma curves  {#h.srzw2qzbbjb2 .c16}

It is common to use a spectral radiometer to measure the spectral
radiance emitted by each of the three types of primaries.  The standard
display model assumes that for each primary the spectral power
distribution takes the form ![](images/image1.png), where
![](images/image2.png)is the spectral power distribution of the display
when the frame buffer is set to its maximum value and 0 \<
![](images/image3.png)\< 1 is the relative intensity for a frame buffer
value of ![](images/image4.png)[.]{.c0}

[]{.c0}

To estimate ![](images/image5.png)and ![](images/image2.png), we measure
the spectral radiance for a series of different frame buffer levels.  An
important detail is this:  In most displays there is some stray light
present even when ![](images/image4.png)=0.  This light is usually
treated as a fixed offset, ![](images/image6.png)and subtracted from the
calibration data [[(Brainard et al.,
2002)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/gGuZ&sa=D&source=editors&ust=1738042993798589&usg=AOvVaw3QveardrwvfM0cjj3MAmBZ){.c4}]{.c5}[.
Hence, the measured spectral radiance curves have the form]{.c0}

[]{.c0}

![](images/image7.png)

[]{.c0}

The term I is the relative intensity of the primary and
![](images/image4.png) is the frame buffer value.  When
![](images/image4.png) is set to the maximum value, the value of I is
equal to 1.   If one subtracts the background spectral power
distribution, then when ![](images/image8.png) and the relative
intensity is typically modeled as a simple power law [[(Poynton,
1993)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/x1cy&sa=D&source=editors&ust=1738042993804297&usg=AOvVaw1dyyVROXpi3agEBM85KVVg){.c4}]{.c5}[ which
gives the curve its name.]{.c0}

[]{.c0}

![](images/image9.png)[ 
                                                        \[1\]]{.c0}

[]{.c0}

For most displays ![](images/image10.png)[is difficult to measure
because it is small and negligible compared to the experimental stimuli.
 In such cases, the radiance is modeled by including a small,
wavelength-independent, offset in the gamma curve]{.c0}

[]{.c0}

![](images/image11.png)[ 
                                                \[2\]]{.c0}

![](images/image12.png)[                                                        \[3\]]{.c0}

[]{.c0}

Historically, the value of ɣ in manufactured displays been between 1.8
and 2.4, which is quite significant.  If one changes the ɣ of a display
from 1.8 to 2.4, the same frame buffer values will produce very
different spectral radiance distributions.  Pixels set to [the same
frame buffer (R,G,B) produce spectral radiances that differ by as much
as 10 CIELAB ΔE units (median \~ 6 ΔE).  In recent years, manufacturers
have converged to a function that is linear at small values, close to
]{.c10}ɣ = [2.4 at high values, and overall similar to ]{.c10}ɣ = [2.2
]{.c10}[(sRGB 2015)]{.c10}^[\[c\]](#cmnt3){#cmnt_ref3}^[.]{.c5 .c22 .c9
.c14}

[]{.c5 .c22 .c9 .c14}

The analytical gamma function is an approximation to the true
![](images/image5.png). In modern computers, this approximation can be
avoided by building a lookup table that stores the nonlinear
relationship between the digital control values and the display
output, ![](images/image5.png)[.  ]{.c0}

[]{.c0}

This nonlinearity will continue across technologies because programmers
prefer that equal spacing of the digital frame buffer values correspond
to equal perceptual spacing [[(Poynton, 1993; Poynton & Funt,
2014)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/x1cy%2B8fWH&sa=D&source=editors&ust=1738042993814553&usg=AOvVaw3YJ499A2jDIMMXC-QANu18){.c4}]{.c5}.
To preserve this perceptual relationship, the display intensity must be
nonlinearly related to the frame buffer value [[(Stevens, 1957; Wandell,
1995)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/2zzl%2BL5vo&sa=D&source=editors&ust=1738042993814723&usg=AOvVaw2IYVTNJEyzpih2VF-EtCxw){.c4}]{.c5}[.
]{.c0}

[]{.c0}

## The subpixel point spread functions {#h.7y9bx8bevrl2 .c16}

The spatial distribution of light from each subpixel is described by a
point spread function, ![](images/image13.png). The spatial spread of
the light from each subpixel can be measured using a high resolution
digital camera with a close-up lens [[(J. Farrell et al.,
2008)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/fUuF&sa=D&source=editors&ust=1738042993817879&usg=AOvVaw1Nnj3QYEpfh_cfFGu9_32P){.c4}]{.c5}[.
Furthermore, the spectral and spatial parts of the point spread function
are separable.]{.c0}

[]{.c0}

![](images/image14.png)[                                        \[4\]]{.c0}

[]{.c0}

The subpixel point spread is assumed to have the same form across
display positions, that is the subpixel point spread function at pixel
(u,v) is ![](images/image15.png).  And finally, the shape scales with
intensity ![](images/image16.png)[.]{.c0}

[]{.c0}

The standard display model assumes that point spread functions from
adjacent pixels sum.  This linearity is an ideal - no display is
precisely linear.  But display designs generally aim to satisfy these
principles and implementations are close enough so that these principles
are a good basis for display characterization and simulation.  

[]{.c0}

## [Linearity]{.c20 .c9} {#h.xo7cj06snd1w .c16}

Apart from the static, nonlinear gamma curve, the standard display model
is a shift-invariant linear system.  That is, given the intensity of
each subpixel we compute the expected display spectral radiance as the
weighted sum of the subpixel point spread functions.  If the subpixel
intensities for one image are ![](images/image17.png)with corresponding
spectral radiance ![](images/image18.png), and  a second image is
![](images/image19.png)with corresponding spectral radiance
![](images/image20.png), then the radiance when the image is
![](images/image21.png) will be ![](images/image22.png).

[]{.c0}

The calibration process should test the additivity assumption. Simple
tests include checking that the light emitted from the [i]{.c19}th
subpixel does not depend on the intensity of other subpixels [[(J.
Farrell et al., 2008; Lyons & Farrell, 1989; Pelli,
1997)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/QEri%2BQfii%2BfUuF&sa=D&source=editors&ust=1738042993838441&usg=AOvVaw0N8TTq454PtRPc0c9ChZZr){.c4}]{.c5}.

[]{.c0}

## Model summary {#h.loxd10duizvo .c16}

The standard display model for a steady-state image can be expressed as
a simple formula that maps the frame buffer values,
![](images/image4.png), to the display spatial-spectral radiance
![](images/image23.png)

[]{.c0}

Suppose the gamma function, point spread function, and spectral power
distribution of the j[th]{.c30} subpixel type are
![](images/image24.png), ![](images/image25.png), and
![](images/image26.png).  Suppose the frame buffer values for the
j[th]{.c30} subpixel type is ![](images/image27.png)[. Then the display
spectral radiance across space is predicted to be]{.c0}

[]{.c0}

![](images/image28.png)                                \[5\]

[]{.c0}

# [Display calibration ]{.c13 .c5 .c9} {#h.f5sccacdd60f .c16}

[]{.c0}

If the standard display model describes the device under test, then
calibration requires a very small set of display measurements - gamma,
spd, PSF and temporal response - to fully describe the physical radiance
of displayed stimuli.  Display calibration can be conceived as (a)
measuring how well the key model assumptions hold (spectral homogeneity,
pixel independence, spatial homogeneity), and (b) using the measurements
to estimate the model parameters.

[]{.c0}

## Pixel independence {#h.7vijesqz5xc .c16}

The radiance emitted by a subpixel should depend only on the digital
frame buffer value controlling that subpixel.  Equivalently, the
radiance emitted by a collection of pixels must not change as the
digital values of other pixels change. Displays often satisfy this pixel
independence principle for a large range of stimuli [[(J. Farrell et
al.,
2008)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/fUuF&sa=D&source=editors&ust=1738042993857321&usg=AOvVaw1nBz_6JJ4oJn0AkAw8f-Yy){.c4}]{.c5},
but there are displays and certain types of stimuli that fail this test
[[(Elze & Tanner, 2012; Lyons & Farrell,
1989)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/QEri%2BK1CN&sa=D&source=editors&ust=1738042993857482&usg=AOvVaw1TvWuvvf6ZY8A-jDsVI1Wo){.c4}]{.c5}[.
 ]{.c0}

[]{.c0}

For example, CRTs  must sweep the intensity of the electron beam very
rapidly across each row of pixels.  There are limits to how rapidly the
beam intensity can change (a maximum "slew rate"). If a very different
intensity is required for a pair of adjacent row pixels, the beam may
not be able to adjust in time and independence is violated, and the
standard display model will not be useful for characterizing the
spatial-spectral radiance of such stimuli [[(Lyons & Farrell, 1989;
Naiman & Makous,
1993)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/QEri%2BOZwX&sa=D&source=editors&ust=1738042993857850&usg=AOvVaw28gDhIPUr8iiegRIZp-VGR){.c4}]{.c5}[.
 ]{.c0}

[]{.c0}

LCDs are limited by the rate at which liquid crystals can change their
state in response to a change in voltage polarity, as well as the
asymmetry in their response to  the "on" or "off" states. LCDs typically
combine sample and hold circuitry to switch between different LC states
and a flickering backlight to minimize the visibility of both motion
blur.   LCDs with these features (sample and hold circuitry with
flickering LED or fluorescent backlights) can be modeled as a linear
system  [[(J. Farrell et al.,
2008)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/fUuF&sa=D&source=editors&ust=1738042993858198&usg=AOvVaw03glLzOES9loZf7UB07-Wq){.c4}]{.c5}.
   Departure from display linearity occurs, however,  when LCD
manufacturers introduce "overdrive" and  "undershoot" circuitry to
minimize the visibility of motion blur or when they locally dim LED
backlight panels to increase dynamic range.  These new features make it
very difficult to control and calibrate visual stimuli, particularly for
studies that require precise control of timing  [[(Elze & Tanner,
2012)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/K1CN&sa=D&source=editors&ust=1738042993858387&usg=AOvVaw0-gliYTghrgp5Zg4pvDapB){.c4}]{.c5}.
[ ]{.c0}

[]{.c0}

There are several ways to test pixel independence [[(J. Farrell et al.,
2008; Lyons & Farrell, 1989; Pelli,
1997)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/QEri%2BQfii%2BfUuF&sa=D&source=editors&ust=1738042993858681&usg=AOvVaw1y3S9Rsn0SYFbDqNhnaXEp){.c4}]{.c5}[,
but the general principle is simple. Separately measure the radiance
from the middle of a large patch of pixels.  Make the measurement with a
few different digital values. Then create spatial patterns that are made
up with half the pixels at one digital value and half at the other.  The
radiance from these mixed patches should be the average of the radiance
from the large patches, measured individually.  ]{.c0}

[]{.c0}

A key assessment is to evaluate how well independence is satisfied for
the planned experimental stimuli.  For example, CRTs often fail pixel
independence for high spatial frequency stimuli because of the finite
slew rate of the electron beam.  Nonetheless, CRTs are very useful for
visual experiments that use low frequency stimuli, such as studies of
human color vision. The standard display model, like any useful model,
will have some compliance range, and the practical question is whether
the model can be used given a specific experimental plan.

[]{.c0}

OLEDs are excellent devices for vision research because they can meet
the requirements of the standard display model [[(Cooper et al.,
2013)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/SSHP&sa=D&source=editors&ust=1738042993859296&usg=AOvVaw3hj0Ley0pWi37IWUFlhG3b){.c4}]{.c5}[.
 Display electronics control the rate at which the pixel intensities can
be changed (the update rate), but OLED pixels can be rapidly turned on
and off.   Thus while the update rate limits  the motion velocities that
can be represented,  the higher refresh rates minimize the visibility of
motion blur and flicker.  And, unlike the LCDs that modulate the
intensity of a backlight, OLED pixels can be turned off, creating a very
dark background.  ]{.c0}

[]{.c0}

[Given these benefits, and the fact that the cost of manufacturing OLED
displays is decreasing, one ]{.c0}

might consider these displays to be ideal devices for vision research.
There are, however, potential challenges to consider.   OLED display
manufacturers are experimenting with different types of color pixel
patterns and developing proprietary methods for rendering images on
these new displays. For instance, one manufacturer incorporated a
hardware-based edge enhancement algorithm, though fortunately, this
feature can be disabled to maintain pixel independence [[(Cooper et al.,
2013)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/SSHP&sa=D&source=editors&ust=1738042993859690&usg=AOvVaw3Xah1z1wEzt8jP6zfGbDJs){.c4}]{.c5}[.
 Unless it is possible to turn off  or at least control the proprietary
display rendering, which may vary depending on the presented image, it
may be difficult to know the spatial distribution of the spectral energy
in displayed stimuli. ]{.c0}

## [Spectral homogeneity]{.c9 .c20} {#h.rfxzwqimec99 .c16}

The relative spectral radiance from a subpixel should be the same as its
intensity is varied.  Any change in the relative spectral radiance will
be manifest as an unwanted color shift, and the display will be
difficult to calibrate.  Recall that the intensity of the light from an
LC display depends on the rotation of the polarization angle caused by
the birefringent liquid crystal.  In some displays, the polarization
effect is wavelength dependent and this violates the spectral
homogeneity assumption  [[(Wandell & Silverstein,
2003)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/PVJo&sa=D&source=editors&ust=1738042993860430&usg=AOvVaw2K41-1WOMhnvRcCJOgMxBe){.c4}]{.c5}[.
 These failure occurs because the LC polarization is not precisely]{.c0}

[the same for all wavelengths and also as a result of spectral
variations in polarizer extinction.]{.c0}

[]{.c0}

A second deviation from the standard display model occurs when the
display emission is angle-dependent.  In fact, the first-generation of
LCDs had a very large angle-dependence so that even small changes in the
viewing position had a large impact on the spectral radiance at the
cornea. The reason for this strong dependence is that the path followed
by a ray through the LC and the polarizers has an influence on the
likelihood of transmission, and this function is wavelength dependent
[[(Silverstein, L.D., Fiske, T.G.,
1993)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/bmaJ&sa=D&source=editors&ust=1738042993860849&usg=AOvVaw0bPM9jZQcFGIsD_jOvOfEA){.c4}]{.c5}.
Manufacturers have reduced these viewing angle dependencies by placing
retardation films in the optical path [[(Yakovlev et al.,
2015)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/R0sH&sa=D&source=editors&ust=1738042993861053&usg=AOvVaw0X67fFrL73nlPBzpQRCdQI){.c4}]{.c5}[.
 ]{.c0}

[]{.c0}

[For visual psychophysics experiments, it is typical to fix the
subject's head position relative to the screen, typically by using a
chin-rest or a bite bar placed on-axis facing the middle of the display.
Instruments used for  display calibration should be placed at this
position.  If the spectrophotometer and the eye are located at any other
angle, the spectral radiance from the display may different. ]{.c0}

[]{.c0}

## Spatial homogeneity (shift invariance) {#h.v300qmaaced1 .c16}

[]{.c0}

When a subject is close to the display surface, the angle-dependence of
the spectral radiance appears as a spatial inhomogeneity[:  the spectral
radiance at the cornea differs between on-axis (center) and off-axis
(edge) pixels.  At further distances, say 1m away, the angle between the
center and edge is smaller and the spatial homogeneity is better. ]{.c0}

[]{.c0}

[A second source of spatial inhomogeneity arises from the fact that it
is difficult to maintain perfect uniformity of the pixels across the
relatively large display surfaces.  Such non-uniformities are referred
to as "mura", which is a Japanese word for "unevenness".  For LCDs,
there are several sources of mura, including non-uniformity in the  TFT
thickness,  LC material density, color filter variations, backlight
illumination, and variations in the optical filters.  Additional
possible sources are impurities in the LC material, non-uniform gaps
between substrates and warped light guides. ]{.c0}

[]{.c0}

On LCDs, mura appears as blemishes and dark spots; manufacturers attempt
to eliminate these sources during the manufacturing process. For OLEDs,
 mura is mainly due to non-uniformity in the currents in spatially
adjacent diodes that appear as black lines, blotches, dots, and faint
stains that are more visible in the dark areas of an image. This can be
mitigated during the manufacturing process by introducing feedback
circuitry that adjusts the pixel transistor current during a calibration
procedure [[(McCreary,
2014)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/J0ki&sa=D&source=editors&ust=1738042993862818&usg=AOvVaw0M_Ba53Au6jAPkWyo42C5Z){.c4}]{.c5}[.
 ]{.c0}

[]{.c0}

# [Applications of the standard display model]{.c13 .c5 .c9} {#h.411bpyqpgmqu .c16}

[]{.c0}

The standard display model is a versatile tool in the fields of vision
science and display engineering. Its primary functions can be summarized
in three key areas. First, it serves as a guide for calibrating visual
stimuli, which is essential for scientists to accurately characterize
and share experimental stimuli, thereby facilitating the replication of
scientific studies [[(Brainard, 1989; Brainard et al.,
2002)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/4u7G%2BgGuZ&sa=D&source=editors&ust=1738042993863373&usg=AOvVaw3kxneBMJ-Ay5xpXV2n5CK-){.c4}]{.c5}.
Second, the model supports the advancement of computational models for
human vision by enabling researchers to calculate the irradiance
incident at the eye, a critical factor in understanding visual
perception [[(Cottaris et al., 2019, 2020; X. Ding et al., 2019; J. E.
Farrell et al.,
2014)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/q9T7%2BcFeb%2B29lo%2BjeJF&sa=D&source=editors&ust=1738042993863554&usg=AOvVaw3yMGLc7SpCGOQ9Vb5XnhfU){.c4}]{.c5}.
Third, it is valuable in the engineering design process, allowing for
the simulation and evaluation of different display types and rendering
algorithms [[(J. Farrell et al.,
2008)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/fUuF&sa=D&source=editors&ust=1738042993863674&usg=AOvVaw3YPY3-bLEyRTeI_cv2PNfk){.c4}]{.c5}.[ ]{.c0}

[]{.c0}

[Key assumptions of the standard display model is that the light
]{.c10}generated by each display subpixel is additive, independent and
[shift invariant. ]{.c10}  These assumptions, referred to as spectral
homogeneity, pixel independence and spatial homogeneity, can be tested
in the calibration process.   [A particular display may not meet these
conditions for all stimuli, yet the model may still be used to predict
the spatial-spectral radiance of a restricted class of visual stimuli.
 As an example, the standard display model does not predict the spectral
radiance of high frequency gratings presented on a CRT ]{.c10}[[(J.
Farrell et al., 2008; Lyons & Farrell, 1989; Pelli,
1997)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/QEri%2BQfii%2BfUuF&sa=D&source=editors&ust=1738042993864202&usg=AOvVaw083hK5RbwdCO12lVv2qMjh){.c4}]{.c5
.c14}[, but the model does predict the spectral-spectral radiance of
large uniform colors ]{.c10}[[(Brainard et al., 2002; Post,
1992)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/gGuZ%2B0yTJ&sa=D&source=editors&ust=1738042993864385&usg=AOvVaw0ahcJ4JG9ZHeqapDGxOeFu){.c4}]{.c5
.c14}[.  The standard display model can predict the steady-state
spatial-spectral radiance of high frequency gratings and text rendered
on many LCD displays ]{.c10}[[(J. Farrell et al.,
2008)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/fUuF&sa=D&source=editors&ust=1738042993864536&usg=AOvVaw3HQJy5hmm7Hx6rQVsZBFyK){.c4}]{.c5
.c14}[, particularly in the absence of  complex circuitry to overdrive
or undershoot pixel intensity ]{.c10}[[(B.-W. Lee et al., 2001; S.-W.
Lee et al.,
2006)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/Zk9Z%2BwoLm&sa=D&source=editors&ust=1738042993864663&usg=AOvVaw1gvmEPJ7rXSro5YfFlr6FN){.c4}]{.c5
.c14}[  and  locally dim LED backlights ]{.c10}[[(Seetzen et al.,
2004)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/Vla5&sa=D&source=editors&ust=1738042993864801&usg=AOvVaw3c3WG1FHsvTD6gcPa2bNcv){.c4}]{.c5
.c14}[.  The standard display can predict the spatial-spectral radiance
of many visual stimuli rendered on OLED displays when image-adaptive
edge enhancement algorithms that are typically implemented in hardware
are disabled ]{.c10}[[(Cooper et al.,
2013)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/SSHP&sa=D&source=editors&ust=1738042993864982&usg=AOvVaw12KkweKvhO1lFvjgMrdksK){.c4}]{.c5
.c14}[. ]{.c10}[Even head-mounted displays (HMDs) which present unique
challenges for calibration due to their proprietary rendering and
updating software, can be modified so that spectral homogeneity and
pixel independence are achievable ]{.c10}[[(Gil Rodríguez et al., 2022;
Toscani et al., 2019; Zaman et al.,
2023)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/Ids2%2Bw7FM%2BRZzA&sa=D&source=editors&ust=1738042993865224&usg=AOvVaw2np9jFY7rNLo9nBjZ4i7IS){.c4}]{.c5
.c14}[.]{.c10}

[]{.c5 .c22 .c9 .c14}

[In the following sections,  we present two  examples that  illustrate
how the standard model, coupled with color discrimination metrics, can
analyze display capabilities. The first demonstrates the necessity of
10-bit intensity resolution for measuring psychophysical discrimination
functions. The second analyzes the impact of different subpixel PSFs on
font discriminations. These examples illustrate how the standard display
model can be applied to analyze display capabilities under specific
experimental conditions, highlighting its versatility and practical
applications in display technology research and development.]{.c5 .c9
.c14 .c22}

[]{.c5 .c22 .c9 .c14}

## [Color discriminations: the impact of bit-depth]{.c20 .c9} {#h.nimnvxz63i8p .c16}

[First, we consider how the number of digital steps (frame buffer
levels) limits the ability to make threshold color and luminance
discrimination measurements. We calculated the CIE XYZ values for each
of 27 different RGB levels, and we then calculated the CIELAB ΔE  value
between each of these 27 points and all of its neighbors within 2
digital steps.  We repeated this calculation simulation assuming a frame
buffer with 10-bits (1024 levels), the actual display resolution, and a
coarser step size of 8-bits (256 levels) but equivalent gamma.]{.c5 .c22
.c9 .c14}

[]{.c5 .c22 .c9 .c14}

[The distributions of CIELAB ΔE differences for the 10-bit and 8-bit
displays are shown in the upper and lower histograms of Figure 6,
respectively.  For a 10-bit display, the signals within two digital
steps are below ΔE=1.  In this case, the visual discriminability is
small enough  to measure a psychophysical discrimination curve.  If the
display has only 8-bits of intensity resolution, the two digital steps
frequently exceed ΔE=1.  This explains why threshold measurements are
impractical on 8-bit displays.  For commercial purposes, however, one
step is about ΔE=1, which explains why 8-bits renders a reasonable
reproduction.  ]{.c10}

[]{.c0}

[![](images/image35.png){style="width: 487.50px; height: 669.82px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 487.50px; height: 669.82px;"}

[]{.c5 .c9 .c25}

## Spatial-spectral discriminations {#h.q4zjwfhtxquy .c16}

[]{.c0}

Next, we analyzed the visual impact of changing the subpixel point
spread function (see Figure 2). In this example, we compared two
displays with the same primaries and spatial resolution (96 dots per
inch), but with different pixel point spread functions.  In one case,
the point spread function is the conventional set of three parallel
stripes (Dell LCD Display Model 1905FP), while in the second case the
point spread is three adjacent chevrons (Dell LCD Display Model
1907FPc).  We used the standard display model to calculate the
spatial-spectral radiance of the 52 upper and lower case letters on both
displays.  The spatial-spectral radiance image data are represented as
[3D matrices or hypercubes where each plane in the hypercube contains
the stimulus intensity for points sampled across the display (x,y) for
each of the sampled wavelengths (ƛ).  To visualize the data, we map the
vector describing the spectral radiance for each pixel into CIE XYZ
values and convert these into sRGB display values ]{.c10}[(see inset in
Figure 7). ]{.c10}

[]{.c5 .c22 .c9 .c14}

We used the spatial-spectral radiance data to calculate the Spatial
CIELAB (S-[CIELAB) ΔE difference ]{.c10}[[(X. Zhang & Wandell,
1997)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/zQ8e&sa=D&source=editors&ust=1738042993867409&usg=AOvVaw3xNgKnEFH440TrXybw5XI8){.c4}]{.c5
.c14} [between each letter simulated on the two displays and viewed from
different distances.  Figure 7  plots the ]{.c10}median S-[CIELAB
ΔE]{.c10} value as a function of viewing distance.  The analysis
predicts no visible differences between pairs of letters rendered on the
two displays at any of the viewing distances.  And indeed, we did not
find significant differences between subject's judgments about the
quality of letters rendered on the two different displays  [[(J. Farrell
et al.,
2009)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/ZbJD&sa=D&source=editors&ust=1738042993867738&usg=AOvVaw2AZjmzpF-gaKmT9s-NhuGZ){.c4}]{.c5}[.]{.c0}

[]{.c0}

[![](images/image34.png){style="width: 664.00px; height: 510.85px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"}]{style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 664.00px; height: 510.85px;"}

[]{.c0}

# [The future: Display systems and simulation]{.c13 .c5 .c9} {#h.4t9ec3mvtmse .c16}

[]{.c0}

The  standard display model is used in vision science in two important
ways.  First, it is used to control and characterize the stimuli used in
visual psychophysical experiments.  Second, it is used to calculate the
irradiance at the eye and integrated into computational models of human
vision^[\[1\]](#ftnt1){#ftnt_ref1}^[. ]{.c0}

[]{.c0}

A third use of the standard display model, which is important for
industry, is its use in simulation to soft prototype displays and
quantify their performance. Simulation is a powerful tool in the imaging
industry and an important part of our own
research^[\[2\]](#ftnt2){#ftnt_ref2}^[.   Many research groups and
companies are developing simulation software to support the design of
imaging components including lenses, sensors and light-emitting devices.
 Soft prototyping is used to evaluate the integration of those
components into imaging systems. Similarly, the standard display model
will need to evolve and be integrated into image systems simulation
software as displays become an integral part of more complex imaging
systems. ]{.c0}

[]{.c0}

[To understand the evolution of display imaging systems, it\'s helpful
to consider the concept of the environmental light field---a complete
radiometric description of light rays within a three-dimensional scene.
Recreating this full light field is a significant challenge, currently
beyond our technological capabilities. An ideal system would emit light
rays with precise intensity, direction, and wavelength from every point
within a large volume, effectively replicating how light propagates from
a real 3D scene. This approach promises accurate depth cues---including
focus, parallax, and occlusion---allowing viewers to perceive lifelike
3D images without special glasses or head tracking, a key objective for
many display technology researchers and engineers.]{.c0}

[]{.c0}

Free-standing displays approximate portions of the environmental light
field. Early systems, primarily for teleconferencing, were expensive and
complex. Commercial examples included life-size displays with ultra-high
definition (e.g., Cisco TelePresence, Poly RealPresence, Google's
Project Starline), designed to present remote participants at their
actual size. Some used curved or wrap-around displays for greater
immersion, attempting a better approximation of the light field. More
recent displays offer a closer approximation of the light field [[(Wang
et al.,
2024)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/CnGQ&sa=D&source=editors&ust=1738042993869445&usg=AOvVaw23jxbvXrtTb60RCa8wN_dg){.c4}]{.c5} [within
a volume of space (e.g., Holografika, Light Field Lab, Leia). These
systems integrate optics with light generation to control the intensity,
color, and direction of emitted rays. The light field itself can be
generated using computer graphics or captured with a light field camera
(e.g., Raytrix). These are often referred to as \"far-field\"
displays.]{.c0}

[]{.c0}

An alternative approach uses simpler displays but dynamically updates
the image based on the viewer\'s head and eye position. The development
of small displays like OLEDs and microLEDs has enabled compact, wearable
\"near-field\" displays in the form of glasses or goggles. These systems
use information about both the environmental light field and the
viewer\'s head and eye position. A computer then calculates and renders
the appropriate display image. This approach was pioneered in virtual
reality (VR) devices and is now being developed for augmented reality
(AR) and mixed reality (MR) (e.g., Apple's Vision Pro, Meta's Quest
Pro). The near-field devices involve integration between many different
sensors and extensive computation, along with highly specialized optics
[[(Y. Ding et al., 2023; Rolland & Goodsell,
2024)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/WUgk%2BICdX&sa=D&source=editors&ust=1738042993869930&usg=AOvVaw2cY3elkygIS8jpSYKqx61K){.c4}]{.c5} to
enable viewing the image on the small, near display.  For example, the
Apple Vision Pro includes twenty different sensors, a micro-OLED display
with 23 million pixels and custom optics, and an M2
processor^[\[3\]](#ftnt3){#ftnt_ref3}^[ .]{.c0}

[]{.c0}

Future display development will likely explore both far-field devices,
aiming to present a larger portion of the environmental light field, and
near-field devices, focusing on dynamically updating the incident light
field. However, the near-field devices must address two key human
factors challenges: the vergence-accommodation conflict (VAC) and
latency [[(Bhowmik, 2024; Jerald, 2015; Kramida,
2016)](https://www.google.com/url?q=https://paperpile.com/c/rDmune/ylUK%2BySCm%2BipUJ&sa=D&source=editors&ust=1738042993870429&usg=AOvVaw3Lr7yEo3_Ji62sDbqY3vDO){.c4}]{.c5}[.]{.c0}

[]{.c0}

The VAC arises from a mismatch between vergence and accommodation, two
normally coupled eye responses. In natural vision, our eyes converge (or
diverge) to fixate on an object, and simultaneously adjust focus
(accommodate) to maintain a sharp image. In most stereoscopic displays,
however, the eyes are always focused on the fixed display plane,
regardless of the virtual object\'s apparent distance. This creates a
conflict: while the eyes verge to align with virtual objects at varying
depths, accommodation remains fixed at the screen distance. This
unnatural decoupling can lead to visual discomfort, eye strain, and
difficulty fusing stereoscopic images, especially for near objects.
Latency, the delay between user head/eye movements and corresponding
display updates, can disrupt presence and induce motion sickness.

[]{.c0}

[Addressing the vergence-accommodation conflict (VAC) and latency
requires close collaboration between engineering and vision science
researchers. Implementing and evaluating both far- and near-field
displays necessitates new approaches to device calibration,
characterization, and understanding the impact of engineering design
choices on the appearance. The standard display model will likely be
replaced by sophisticated simulation software capable of modeling each
system component, including light-emitting elements, light guides, and
various optical components. Increased emphasis will be placed on precise
timing to understand latency requirements. This will enable prediction
of the dynamic light field generated by these displays and,
consequently, the irradiance at the viewer's retinas. This shift from a
standard display model to comprehensive system simulation demands new
ideas in both vision science and display technology. We are confident
that scientists and engineers will develop robust calibration and
simulation methodologies, enabling researchers to effectively integrate
these new technologies into scientific practice and generate novel
insights into vision and cognition.]{.c0}

[]{.c5 .c22 .c9 .c43}

# [References]{.c13 .c5 .c9} {#h.h568vcenhz7h .c35}

[[Bale, M., Carter, J. C., Creighton, C. J., Gregory, H. J., Lyon, P.
H., Ng, P., Webb, L., & Wehrum, A. (2006). Ink‐jet printing: The route
to production of full‐color P‐OLED
displays.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/wEPT&sa=D&source=editors&ust=1738042993871363&usg=AOvVaw2Lbyy4_Pz0yqIT29rhj-hc){.c4}
]{.c3}[[Journal of the Society for Information
Display](https://www.google.com/url?q=http://paperpile.com/b/rDmune/wEPT&sa=D&source=editors&ust=1738042993871495&usg=AOvVaw0-yFEfo3lCqWUFS51R20aq){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/wEPT&sa=D&source=editors&ust=1738042993871581&usg=AOvVaw2kUVR7EhWkgcbhsfeo9MRc){.c4}
]{.c3}[[14](https://www.google.com/url?q=http://paperpile.com/b/rDmune/wEPT&sa=D&source=editors&ust=1738042993871658&usg=AOvVaw0A9SUuyqLNW7J2SoO0uiOG){.c4}]{.c5
.c6}[[(5),
453--459.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/wEPT&sa=D&source=editors&ust=1738042993871733&usg=AOvVaw3JSQJ-p_vIeis8az4B1Bt3){.c4}]{.c3}

[[Bandari, V. K., & Schmidt, O. G. (2024). A bright future for micro-LED
displays.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/bTso&sa=D&source=editors&ust=1738042993871912&usg=AOvVaw0YMMKYOzJA4nO4UD2CqTHm){.c4}
]{.c3}[[Light, Science &
Applications](https://www.google.com/url?q=http://paperpile.com/b/rDmune/bTso&sa=D&source=editors&ust=1738042993872040&usg=AOvVaw0eaabxcNDFUo7tuMkX8Xnt){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/bTso&sa=D&source=editors&ust=1738042993872152&usg=AOvVaw1KY5TZ7kVIXVkSbpqzpG7O){.c4}
]{.c3}[[13](https://www.google.com/url?q=http://paperpile.com/b/rDmune/bTso&sa=D&source=editors&ust=1738042993872268&usg=AOvVaw0K_HBSKZzT_PONXkT_R7DS){.c4}]{.c5
.c6}[[(1),
317.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/bTso&sa=D&source=editors&ust=1738042993872384&usg=AOvVaw1tMe0_5-t645quitW5-RPE){.c4}]{.c3}

[[Becker, M. E. (2019). 50‐1: Flicker from electronic displays ‐
reconsidering the
confusion.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/7M0a&sa=D&source=editors&ust=1738042993872635&usg=AOvVaw2saLkQY_EtRmrt6jfq26gr){.c4}
]{.c3}[[Digest of Technical Papers. SID International
Symposium](https://www.google.com/url?q=http://paperpile.com/b/rDmune/7M0a&sa=D&source=editors&ust=1738042993872779&usg=AOvVaw3LApXXgw83QJQYCiOX00y-){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/7M0a&sa=D&source=editors&ust=1738042993872896&usg=AOvVaw3DoRa4nCrOd4uT9OQxQzVk){.c4}
]{.c3}[[50](https://www.google.com/url?q=http://paperpile.com/b/rDmune/7M0a&sa=D&source=editors&ust=1738042993873011&usg=AOvVaw1qiN3DD7zjaK7_BSrRJo9-){.c4}]{.c5
.c6}[[(1),
687--690.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/7M0a&sa=D&source=editors&ust=1738042993873135&usg=AOvVaw0bpembha4LV1Fp-3EhQgz2){.c4}]{.c3}

[[Bhowmik, A. K. (2024). Virtual and augmented reality: Human
sensory‐perceptual requirements and trends for immersive spatial
computing
experiences.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ySCm&sa=D&source=editors&ust=1738042993873324&usg=AOvVaw1GTafPpOic_btFt5JiPDc4){.c4}
]{.c3}[[Journal of the Society for Information
Display](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ySCm&sa=D&source=editors&ust=1738042993873413&usg=AOvVaw2C8QgLjn16OnffbtFv66jA){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ySCm&sa=D&source=editors&ust=1738042993873483&usg=AOvVaw3uRdEOu9PoPJVXloZCzHSR){.c4}
]{.c3}[[32](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ySCm&sa=D&source=editors&ust=1738042993873552&usg=AOvVaw3KbvcslrXz6Fiiv0hfNSOb){.c4}]{.c5
.c6}[[(8),
605--646.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ySCm&sa=D&source=editors&ust=1738042993873657&usg=AOvVaw2fZYc8PR4eOffi-Rj6LsGX){.c4}]{.c3}

[[Brainard, D. H. (1989). Calibration of a computer controlled color
monitor.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/4u7G&sa=D&source=editors&ust=1738042993873888&usg=AOvVaw18K4zk1OqjomZHnlI8kXXZ){.c4}
]{.c3}[[Color Research and
Application](https://www.google.com/url?q=http://paperpile.com/b/rDmune/4u7G&sa=D&source=editors&ust=1738042993874033&usg=AOvVaw0n6j0_NaNIZ5cA6fe91us8){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/4u7G&sa=D&source=editors&ust=1738042993874151&usg=AOvVaw0hFEb8GVzirkZCArmv8RPZ){.c4}
]{.c3}[[14](https://www.google.com/url?q=http://paperpile.com/b/rDmune/4u7G&sa=D&source=editors&ust=1738042993874246&usg=AOvVaw2DY0KgcYzSIIosrhCvqKPq){.c4}]{.c5
.c6}[[(1),
23--34.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/4u7G&sa=D&source=editors&ust=1738042993874336&usg=AOvVaw1QOhq0gMik_Ec3UgNZ-5he){.c4}]{.c3}

[[Brainard, D. H. (1998). Color constancy in the nearly natural image.
2. Achromatic
loci.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/g9Yn&sa=D&source=editors&ust=1738042993874537&usg=AOvVaw1BXrssJGVBdepgIMQ7X5vc){.c4}
]{.c3}[[Journal of The Optical Society of America A-Optics Image Science
and
Vision](https://www.google.com/url?q=http://paperpile.com/b/rDmune/g9Yn&sa=D&source=editors&ust=1738042993874674&usg=AOvVaw0letNMF3iXsRZd0o16S5ur){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/g9Yn&sa=D&source=editors&ust=1738042993874817&usg=AOvVaw16ZQM0jhgFkvJlUR7dc_Xc){.c4}
]{.c3}[[15](https://www.google.com/url?q=http://paperpile.com/b/rDmune/g9Yn&sa=D&source=editors&ust=1738042993874918&usg=AOvVaw2b2XmIUXKLKDHE6SeEaXG1){.c4}]{.c5
.c6}[[(2),
307--325.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/g9Yn&sa=D&source=editors&ust=1738042993875043&usg=AOvVaw1JancYb_LW2EuR60rB_uqH){.c4}]{.c3}

[[Brainard, D. H., Brunt, W. A., & Speigle, J. M. (1997). Color
constancy in the nearly natural image. 1. Asymmetric
matches.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/VIgL&sa=D&source=editors&ust=1738042993875232&usg=AOvVaw1bR4gQN5mcZVcuJzCI9wsi){.c4}
]{.c3}[[JOSA
A](https://www.google.com/url?q=http://paperpile.com/b/rDmune/VIgL&sa=D&source=editors&ust=1738042993875315&usg=AOvVaw1WsEQCklezmzBWUboqNr44){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/VIgL&sa=D&source=editors&ust=1738042993875386&usg=AOvVaw3coTi_jqmAp5XtwwdH8ykn){.c4}
]{.c3}[[14](https://www.google.com/url?q=http://paperpile.com/b/rDmune/VIgL&sa=D&source=editors&ust=1738042993875456&usg=AOvVaw2NhBXQaCwqR6S1rl-ftiCS){.c4}]{.c5
.c6}[[(9),
2091--2110.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/VIgL&sa=D&source=editors&ust=1738042993875531&usg=AOvVaw0utaGOFZF2s7Yn7RqxT7gb){.c4}]{.c3}

[[Brainard, D. H., Pelli, D. G., & Robson, T. (2002). Display
characterization.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/gGuZ&sa=D&source=editors&ust=1738042993875703&usg=AOvVaw1I-LVY_qo-j6ARAMZGWcPy){.c4}
]{.c3}[[Signal Processing Algorithms, Architectures, Arrangements, and
Applications Conference
Proceedings](https://www.google.com/url?q=http://paperpile.com/b/rDmune/gGuZ&sa=D&source=editors&ust=1738042993875811&usg=AOvVaw3AsNSmZ7vE0W-L6S7D4NCo){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/gGuZ&sa=D&source=editors&ust=1738042993875903&usg=AOvVaw16_yrGNTekyFdLWSjlmA8F){.c4}
]{.c3}[[80](https://www.google.com/url?q=http://paperpile.com/b/rDmune/gGuZ&sa=D&source=editors&ust=1738042993876005&usg=AOvVaw0c0VLosha-qz1fnZMwJO98){.c4}]{.c5
.c6}[[,
2--067.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/gGuZ&sa=D&source=editors&ust=1738042993876114&usg=AOvVaw0Ez-A-YKOvDQyX-ZMIr2jk){.c4}]{.c3}

[[Castellano, J. A.
(1992).](https://www.google.com/url?q=http://paperpile.com/b/rDmune/RRqX&sa=D&source=editors&ust=1738042993876301&usg=AOvVaw3hWkb6mETOI3p4EZXDUmwe){.c4}
]{.c3}[[Handbook of display
technology](https://www.google.com/url?q=http://paperpile.com/b/rDmune/RRqX&sa=D&source=editors&ust=1738042993876410&usg=AOvVaw3HYtLIyLRvEpEeO21tQm4V){.c4}]{.c5
.c6}[[.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/RRqX&sa=D&source=editors&ust=1738042993876488&usg=AOvVaw0l226LWuIW8eCTnIttgBX1){.c4}
]{.c3}[[https://books.google.com/books?hl=en&lr=&id=p68XfA0MHpoC&oi=fnd&pg=PR13&dq=+Handbook+Of+Display+Technology+Castellano&ots=yt-mSACsLQ&sig=pQWBgKMXlbNGo-Z6iZwydyCAkJY](https://www.google.com/url?q=https://books.google.com/books?hl%3Den%26lr%3D%26id%3Dp68XfA0MHpoC%26oi%3Dfnd%26pg%3DPR13%26dq%3D%2BHandbook%2BOf%2BDisplay%2BTechnology%2BCastellano%26ots%3Dyt-mSACsLQ%26sig%3DpQWBgKMXlbNGo-Z6iZwydyCAkJY&sa=D&source=editors&ust=1738042993876688&usg=AOvVaw07h3uNatTxaRMB_anJY-wi){.c4}]{.c3}

[[Cooper, E. A., Jiang, H., Vildavski, V., Farrell, J. E., & Norcia, A.
M. (2013). Assessment of OLED displays for vision
research.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/SSHP&sa=D&source=editors&ust=1738042993876876&usg=AOvVaw3314FGFLZoxnXCQGSQcKLq){.c4}
]{.c3}[[Journal of
Vision](https://www.google.com/url?q=http://paperpile.com/b/rDmune/SSHP&sa=D&source=editors&ust=1738042993876965&usg=AOvVaw3c87bwD5ssmt1UK-15vaDD){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/SSHP&sa=D&source=editors&ust=1738042993877055&usg=AOvVaw0GWkJQ5q28hh31ABVciuLw){.c4}
]{.c3}[[13](https://www.google.com/url?q=http://paperpile.com/b/rDmune/SSHP&sa=D&source=editors&ust=1738042993877133&usg=AOvVaw1Dll_cM5jgOT6GXMyIs8MS){.c4}]{.c5
.c6}[[(12),
16.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/SSHP&sa=D&source=editors&ust=1738042993877207&usg=AOvVaw3ONYKMLZsgVpoAl9kANg0k){.c4}]{.c3}

[[Cottaris, N. P., Jiang, H., Ding, X., Wandell, B. A., & Brainard, D.
H. (2019). A computational-observer model of spatial contrast
sensitivity: Effects of wave-front-based optics, cone-mosaic structure,
and inference
engine.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/cFeb&sa=D&source=editors&ust=1738042993877370&usg=AOvVaw26jpc7-QygX2FsmRRzB3Dq){.c4}
]{.c3}[[Journal of
Vision](https://www.google.com/url?q=http://paperpile.com/b/rDmune/cFeb&sa=D&source=editors&ust=1738042993877446&usg=AOvVaw2etA5WNxmYlXSTctrp9A2y){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/cFeb&sa=D&source=editors&ust=1738042993877518&usg=AOvVaw3fjNJJGlz9WCFP8Bpbms-h){.c4}
]{.c3}[[19](https://www.google.com/url?q=http://paperpile.com/b/rDmune/cFeb&sa=D&source=editors&ust=1738042993877587&usg=AOvVaw3lnfBjZCuI1dLQSwXe7ykc){.c4}]{.c5
.c6}[[(4),
8.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/cFeb&sa=D&source=editors&ust=1738042993877660&usg=AOvVaw2sS4VnqF52fjXw4c9ljNB9){.c4}]{.c3}

[[Cottaris, N. P., Wandell, B. A., Rieke, F., & Brainard, D. H. (2020).
A computational observer model of spatial contrast sensitivity: Effects
of photocurrent encoding, fixational eye movements, and inference
engine.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/jeJF&sa=D&source=editors&ust=1738042993877838&usg=AOvVaw3hj4dv9iasIbFu-uUXJG_i){.c4}
]{.c3}[[Journal of
Vision](https://www.google.com/url?q=http://paperpile.com/b/rDmune/jeJF&sa=D&source=editors&ust=1738042993877917&usg=AOvVaw2K1PfVwC20Ry5yPu2Bi2VB){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/jeJF&sa=D&source=editors&ust=1738042993877987&usg=AOvVaw3v22eY3Ra66qYed-Ti49Id){.c4}
]{.c3}[[20](https://www.google.com/url?q=http://paperpile.com/b/rDmune/jeJF&sa=D&source=editors&ust=1738042993878059&usg=AOvVaw2U7ah6hqbzccKnG7cCaz3m){.c4}]{.c5
.c6}[[(7),
17.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/jeJF&sa=D&source=editors&ust=1738042993878130&usg=AOvVaw3R4fgPSygofw9sobfzLdXt){.c4}]{.c3}

[[Dimigen, O., & Stein, A. (2024). A high-speed OLED monitor for precise
stimulation in vision, eye-tracking, and EEG research.
In](https://www.google.com/url?q=http://paperpile.com/b/rDmune/BHJc&sa=D&source=editors&ust=1738042993878325&usg=AOvVaw282GYZdika4p0t54CDV34A){.c4}
]{.c3}[[bioRxiv](https://www.google.com/url?q=http://paperpile.com/b/rDmune/BHJc&sa=D&source=editors&ust=1738042993878411&usg=AOvVaw37rBWMCX6bBRpe0XavO5fD){.c4}]{.c5
.c6}[[.
https://doi.org/](https://www.google.com/url?q=http://paperpile.com/b/rDmune/BHJc&sa=D&source=editors&ust=1738042993878490&usg=AOvVaw0Wjc4XjFRiKHAWLSIVwaZA){.c4}]{.c3}[[10.1101/2024.09.13.612866](https://www.google.com/url?q=http://dx.doi.org/10.1101/2024.09.13.612866&sa=D&source=editors&ust=1738042993878575&usg=AOvVaw1b-FkfotlqRFho_PR_OkwG){.c4}]{.c3}

[[Ding, X., Radonjic, A., Cottaris, N. P., Jiang, H., Wandell, B. A., &
Brainard, D. H. (2019). Computational-observer analysis of illumination
discrimination.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/29lo&sa=D&source=editors&ust=1738042993878747&usg=AOvVaw3i7fSrwUBNMSFHmLVviqO7){.c4}
]{.c3}[[Journal of
Vision](https://www.google.com/url?q=http://paperpile.com/b/rDmune/29lo&sa=D&source=editors&ust=1738042993878840&usg=AOvVaw2n43LjATOieLJX6TxCqj1F){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/29lo&sa=D&source=editors&ust=1738042993878919&usg=AOvVaw1ZzgA-P6icJkrXiP5ucF9z){.c4}
]{.c3}[[19](https://www.google.com/url?q=http://paperpile.com/b/rDmune/29lo&sa=D&source=editors&ust=1738042993879060&usg=AOvVaw22EPE-jIrwTmqnDH5GKf3P){.c4}]{.c5
.c6}[[(7),
11.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/29lo&sa=D&source=editors&ust=1738042993879140&usg=AOvVaw2YKkUWa6Qv6t73kNgax4rB){.c4}]{.c3}

[[Ding, Y., Yang, Q., Li, Y., Yang, Z., Wang, Z., Liang, H., & Wu, S.-T.
(2023). Waveguide-based augmented reality displays: perspectives and
challenges.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ICdX&sa=D&source=editors&ust=1738042993879309&usg=AOvVaw1pfyeXevTnj8wIyIn4pFFb){.c4}
]{.c3}[[eLight](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ICdX&sa=D&source=editors&ust=1738042993879392&usg=AOvVaw3O4huDOVNqlrincoWPY7te){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ICdX&sa=D&source=editors&ust=1738042993879467&usg=AOvVaw23zKDFkPBsZPQLy2Xnmwey){.c4}
]{.c3}[[3](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ICdX&sa=D&source=editors&ust=1738042993879541&usg=AOvVaw1Ypd7-9eIgA3zOt-w50sWl){.c4}]{.c5
.c6}[[(1),
1--34.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ICdX&sa=D&source=editors&ust=1738042993879623&usg=AOvVaw3rtIuJdDZ2c-CfFw9NU4es){.c4}]{.c3}

[[Elze, T., & Tanner, T. G. (2012). Temporal properties of liquid
crystal displays: implications for vision science
experiments.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/K1CN&sa=D&source=editors&ust=1738042993879787&usg=AOvVaw0QxQ2IOdMxf09n1HcJ829t){.c4}
]{.c3}[[PloS
One](https://www.google.com/url?q=http://paperpile.com/b/rDmune/K1CN&sa=D&source=editors&ust=1738042993879874&usg=AOvVaw0ueBIcbIjLqMKBexSfEc-e){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/K1CN&sa=D&source=editors&ust=1738042993879951&usg=AOvVaw21rrPQNv0mfokZFTSxmZX8){.c4}
]{.c3}[[7](https://www.google.com/url?q=http://paperpile.com/b/rDmune/K1CN&sa=D&source=editors&ust=1738042993880028&usg=AOvVaw1TqLTFNd5D7ppKGXTb3_H4){.c4}]{.c5
.c6}[[(9),
e44048.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/K1CN&sa=D&source=editors&ust=1738042993880102&usg=AOvVaw2ChFyLm7Mz6QzAE93sODjz){.c4}]{.c3}

[[Engel, S. A., Glover, G. H., & Wandell, B. A. (1997). Retinotopic
organization in human visual cortex and the spatial precision of
functional
MRI.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Ie9F&sa=D&source=editors&ust=1738042993880251&usg=AOvVaw3BIDjJiFEpohjFwK1KDXDN){.c4}
]{.c3}[[Cerebral Cortex (New York, N.Y.:
1991)](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Ie9F&sa=D&source=editors&ust=1738042993880336&usg=AOvVaw0Bmv4dYra7kcmUsSPCj-5U){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Ie9F&sa=D&source=editors&ust=1738042993880407&usg=AOvVaw2M5AbTrZkbvzF55AnXsi4l){.c4}
]{.c3}[[7](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Ie9F&sa=D&source=editors&ust=1738042993880478&usg=AOvVaw3aVD3ug4tzIM_lwT0IPhSf){.c4}]{.c5
.c6}[[(2),
181--192.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Ie9F&sa=D&source=editors&ust=1738042993880556&usg=AOvVaw0OEkDnjjjR-Er0-IplGhGH){.c4}]{.c3}

[[Fan, J., Han, C., Yang, G., Song, B., Xu, R., Xiang, C., Zhang, T., &
Qian, L. (2024). Recent progress of quantum dots light-emitting diodes:
Materials, device structures, and display
applications.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/zuiR&sa=D&source=editors&ust=1738042993880772&usg=AOvVaw1XJOc8RIcbuDkcpCOko9UG){.c4}
]{.c3}[[Advanced Materials (Deerfield Beach,
Fla.)](https://www.google.com/url?q=http://paperpile.com/b/rDmune/zuiR&sa=D&source=editors&ust=1738042993880854&usg=AOvVaw2BuaaKYXzYZFIwfyKfHYR_){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/zuiR&sa=D&source=editors&ust=1738042993880933&usg=AOvVaw3jZWcaCxMxebeI2nQglkab){.c4}
]{.c3}[[36](https://www.google.com/url?q=http://paperpile.com/b/rDmune/zuiR&sa=D&source=editors&ust=1738042993881030&usg=AOvVaw1_fWdylOjUCqTUtdbRUYZE){.c4}]{.c5
.c6}[[(37),
e2312948.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/zuiR&sa=D&source=editors&ust=1738042993881139&usg=AOvVaw1ixgIRHKvLs7fv7TTSKbs-){.c4}]{.c3}

[[Farrell, J. E. (1986). An analytical method for predicting perceived
flicker.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/CYWd&sa=D&source=editors&ust=1738042993881351&usg=AOvVaw1OsPnChNfWsRZtvDzlKxdu){.c4}
]{.c3}[[Behaviour & Information
Technology](https://www.google.com/url?q=http://paperpile.com/b/rDmune/CYWd&sa=D&source=editors&ust=1738042993881490&usg=AOvVaw0JFicYPlSw7VYv21VgWTk6){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/CYWd&sa=D&source=editors&ust=1738042993881616&usg=AOvVaw0vegJ6K3t1OZUMkXuc_1rU){.c4}
]{.c3}[[5](https://www.google.com/url?q=http://paperpile.com/b/rDmune/CYWd&sa=D&source=editors&ust=1738042993881740&usg=AOvVaw35iMKZO-Z90Ef3CSn2KUHQ){.c4}]{.c5
.c6}[[(4),
349--358.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/CYWd&sa=D&source=editors&ust=1738042993881875&usg=AOvVaw24J79TgHNDlmisgnkJRJjx){.c4}]{.c3}

[[Farrell, J. E., Jiang, H., Winawer, J., Brainard, D. H., & Wandell, B.
A. (2014).
27.2:](https://www.google.com/url?q=http://paperpile.com/b/rDmune/q9T7&sa=D&source=editors&ust=1738042993882056&usg=AOvVaw14o3NmZtzcsIF6MZR-gD3m){.c4}
]{.c3}[[distinguished
paper](https://www.google.com/url?q=http://paperpile.com/b/rDmune/q9T7&sa=D&source=editors&ust=1738042993882162&usg=AOvVaw1ovyRlskeSSPdQ-bDLJW7t){.c4}]{.c5
.c6}[[: Modeling visible differences: The computational observer
model.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/q9T7&sa=D&source=editors&ust=1738042993882268&usg=AOvVaw1TG2BWIbABZg16vj7Fft1C){.c4}
]{.c3}[[Digest of Technical Papers. SID International
Symposium](https://www.google.com/url?q=http://paperpile.com/b/rDmune/q9T7&sa=D&source=editors&ust=1738042993882367&usg=AOvVaw3_eSaKfSqyOrbroR_FZ7LC){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/q9T7&sa=D&source=editors&ust=1738042993882479&usg=AOvVaw3xGvW2_LciyM28X5DiY2Hr){.c4}
]{.c3}[[45](https://www.google.com/url?q=http://paperpile.com/b/rDmune/q9T7&sa=D&source=editors&ust=1738042993882574&usg=AOvVaw2T2YThqA22_Nqws9h_NRs5){.c4}]{.c5
.c6}[[(1),
352--356.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/q9T7&sa=D&source=editors&ust=1738042993882683&usg=AOvVaw0ESTumsAmDKHYbTYlBsufC){.c4}]{.c3}

[[Farrell, J., Ng, G., Ding, X., Larson, K., & Wandell, B. (2008). A
display simulation toolbox for image quality
evaluation.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/fUuF&sa=D&source=editors&ust=1738042993882886&usg=AOvVaw1VPfUxVtp3ssHXcKrRA2Wn){.c4}
]{.c3}[[Journal of Display
Technology](https://www.google.com/url?q=http://paperpile.com/b/rDmune/fUuF&sa=D&source=editors&ust=1738042993882972&usg=AOvVaw25VpGEaErU1USFMziTpaGB){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/fUuF&sa=D&source=editors&ust=1738042993883060&usg=AOvVaw1nNITa7WVlrCWp08MOYyo7){.c4}
]{.c3}[[4](https://www.google.com/url?q=http://paperpile.com/b/rDmune/fUuF&sa=D&source=editors&ust=1738042993883154&usg=AOvVaw1Gsw3z8C5m2nc7GnsQmWIW){.c4}]{.c5
.c6}[[(2),
262--270.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/fUuF&sa=D&source=editors&ust=1738042993883240&usg=AOvVaw2gGraYTuFDvHdNyAyu4xXF){.c4}]{.c3}

[[Farrell, J., Xu, J., Larson, K., & Wandell, B. (2009). 47.2: Visual
preference for ClearType
technology.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ZbJD&sa=D&source=editors&ust=1738042993883434&usg=AOvVaw3EIYMH9IDkFAvt0xa7izYX){.c4}
]{.c3}[[Digest of Technical Papers. SID International
Symposium](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ZbJD&sa=D&source=editors&ust=1738042993883532&usg=AOvVaw0zfcuO6ZI4Tc2gdeWQ0ysm){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ZbJD&sa=D&source=editors&ust=1738042993883608&usg=AOvVaw0iExW0jlGIgrLTiw7L09_R){.c4}
]{.c3}[[40](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ZbJD&sa=D&source=editors&ust=1738042993883699&usg=AOvVaw0BHPp3WV8DGQN3CcR5VLe2){.c4}]{.c5
.c6}[[(1),
702--705.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ZbJD&sa=D&source=editors&ust=1738042993883785&usg=AOvVaw1p8qSyeYK2DVr0FufT4l06){.c4}]{.c3}

[[Florence, J. M., & Yoder, L. A. (1996). Display system architectures
for digital micromirror device (DMD)-based projectors. In M. H. Wu
(Ed.),](https://www.google.com/url?q=http://paperpile.com/b/rDmune/abHF&sa=D&source=editors&ust=1738042993883985&usg=AOvVaw3wXIP8ZP2HgAnrbLBu89qe){.c4}
]{.c3}[[Projection Displays
II](https://www.google.com/url?q=http://paperpile.com/b/rDmune/abHF&sa=D&source=editors&ust=1738042993884072&usg=AOvVaw1pUjF06r44H5HDd7TyB--1){.c4}]{.c5
.c6}[[. SPIE.
https://doi.org/](https://www.google.com/url?q=http://paperpile.com/b/rDmune/abHF&sa=D&source=editors&ust=1738042993884147&usg=AOvVaw0UT9SwFywsbKPAszvA5eP3){.c4}]{.c3}[[10.1117/12.237004](https://www.google.com/url?q=http://dx.doi.org/10.1117/12.237004&sa=D&source=editors&ust=1738042993884229&usg=AOvVaw2OVC3e3gy1U9cJQi1kA4MY){.c4}]{.c3}

[[Gershun, A. (1939). The Light
Field.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/yLhf&sa=D&source=editors&ust=1738042993884400&usg=AOvVaw14a2gSZ2aHXqdDiO9SLvmB){.c4}
]{.c3}[[Journal of Mathematics and
Physics](https://www.google.com/url?q=http://paperpile.com/b/rDmune/yLhf&sa=D&source=editors&ust=1738042993884504&usg=AOvVaw0TjwZ60YLQ_OYgEmIo2lBN){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/yLhf&sa=D&source=editors&ust=1738042993884578&usg=AOvVaw1DQNujGVG26UkgFRrP2M1g){.c4}
]{.c3}[[18](https://www.google.com/url?q=http://paperpile.com/b/rDmune/yLhf&sa=D&source=editors&ust=1738042993884650&usg=AOvVaw16oIBHKHoGFTKSeLpY4eld){.c4}]{.c5
.c6}[[(1-4),
51--151.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/yLhf&sa=D&source=editors&ust=1738042993884739&usg=AOvVaw1UjfP67m8XKCsuLZYNS6c-){.c4}]{.c3}

[[Ghodrati, M., Morris, A. P., & Price, N. S. C. (2015). The
(un)suitability of modern liquid crystal displays (LCDs) for vision
research.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/fO5b&sa=D&source=editors&ust=1738042993884937&usg=AOvVaw3jsYAzXHT2fjM-9-IaOpj4){.c4}
]{.c3}[[Frontiers in
Psychology](https://www.google.com/url?q=http://paperpile.com/b/rDmune/fO5b&sa=D&source=editors&ust=1738042993885026&usg=AOvVaw3VG7jHSH5KX1_lLPsAWrlN){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/fO5b&sa=D&source=editors&ust=1738042993885099&usg=AOvVaw3utGr2dL14xS4zjWMo09at){.c4}
]{.c3}[[6](https://www.google.com/url?q=http://paperpile.com/b/rDmune/fO5b&sa=D&source=editors&ust=1738042993885170&usg=AOvVaw0YJAXrEh8UN3EGfbVqxEw-){.c4}]{.c5
.c6}[[,
303.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/fO5b&sa=D&source=editors&ust=1738042993885257&usg=AOvVaw1HnAmybbJSdCJc2JBVap5C){.c4}]{.c3}

[[Gil Rodríguez, R., Bayer, F., Toscani, M., Guarnera, D. 'ya, Guarnera,
G. C., & Gegenfurtner, K. R. (2022). Colour Calibration of a Head
Mounted Display for Colour Vision Research Using Virtual
Reality.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/RZzA&sa=D&source=editors&ust=1738042993885474&usg=AOvVaw01j-xd029Hai0EcUXfVsDV){.c4}
]{.c3}[[SN Computer
Science](https://www.google.com/url?q=http://paperpile.com/b/rDmune/RZzA&sa=D&source=editors&ust=1738042993885599&usg=AOvVaw3AA-b6Iy3PkcQP5rVNt8wE){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/RZzA&sa=D&source=editors&ust=1738042993885683&usg=AOvVaw3ffWPCnKVu-Ev2wXtD_DAI){.c4}
]{.c3}[[3](https://www.google.com/url?q=http://paperpile.com/b/rDmune/RZzA&sa=D&source=editors&ust=1738042993885764&usg=AOvVaw1XPl9TG6yvfEcEmjF7Tj5n){.c4}]{.c5
.c6}[[(1),
22.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/RZzA&sa=D&source=editors&ust=1738042993885841&usg=AOvVaw3ter2e9DRN5qiJ5YKLQ8if){.c4}]{.c3}

[[Hornbeck, L. J. (1991). Spatial light modulator and method (USPTO
Patent No. 5061049).
In](https://www.google.com/url?q=http://paperpile.com/b/rDmune/zQ5t&sa=D&source=editors&ust=1738042993886010&usg=AOvVaw3FhrLApIMJTbq3bmrlDLSC){.c4}
]{.c3}[[US
Patent](https://www.google.com/url?q=http://paperpile.com/b/rDmune/zQ5t&sa=D&source=editors&ust=1738042993886088&usg=AOvVaw0Fi4_mSjZ6Yw6T65lvDn74){.c4}]{.c5
.c6}[[ (No.
5061049).](https://www.google.com/url?q=http://paperpile.com/b/rDmune/zQ5t&sa=D&source=editors&ust=1738042993886162&usg=AOvVaw3W43qUbt8UiP3uRRudW4RN){.c4}
]{.c3}[[https://patents.google.com/patent/US5061049A/en](https://www.google.com/url?q=https://patents.google.com/patent/US5061049A/en&sa=D&source=editors&ust=1738042993886252&usg=AOvVaw19mPrQ0G-AXlDIv_QYYGX1){.c4}]{.c3}

[[Hsiang, E.-L., Yang, Z., Yang, Q., Lan, Y.-F., & Wu, S.-T. (2021).
Prospects and challenges of mini‐LED, OLED, and micro‐LED
displays.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/H7Zs&sa=D&source=editors&ust=1738042993886410&usg=AOvVaw2AINtxVGKZF7h1TsarHwIM){.c4}
]{.c3}[[Journal of the Society for Information
Display](https://www.google.com/url?q=http://paperpile.com/b/rDmune/H7Zs&sa=D&source=editors&ust=1738042993886511&usg=AOvVaw3tXMYLXCl0jtV2gcIe7HG-){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/H7Zs&sa=D&source=editors&ust=1738042993886605&usg=AOvVaw3l8CVmj85w9W6SRuGbxJwv){.c4}
]{.c3}[[29](https://www.google.com/url?q=http://paperpile.com/b/rDmune/H7Zs&sa=D&source=editors&ust=1738042993886693&usg=AOvVaw1a8oA5S6_O1X95BTIZrxhl){.c4}]{.c5
.c6}[[(6),
446--465.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/H7Zs&sa=D&source=editors&ust=1738042993886809&usg=AOvVaw2fVdN2NOKO17yWDV7MotQ4){.c4}]{.c3}

[[Huang, Y., Hsiang, E.-L., Deng, M.-Y., & Wu, S.-T. (2020). Mini-LED,
Micro-LED and OLED displays: present status and future
perspectives.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Ay2a&sa=D&source=editors&ust=1738042993886991&usg=AOvVaw1AA_jdaZWEnWSxLBTv-Mov){.c4}
]{.c3}[[Light, Science &
Applications](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Ay2a&sa=D&source=editors&ust=1738042993887114&usg=AOvVaw3BhxyVXCnaLAOSCCiaAqZ3){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Ay2a&sa=D&source=editors&ust=1738042993887188&usg=AOvVaw2enAEu_tqOamG5_dUyROEC){.c4}
]{.c3}[[9](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Ay2a&sa=D&source=editors&ust=1738042993887255&usg=AOvVaw06th5TfoFneHatoEbmOx1X){.c4}]{.c5
.c6}[[(1),
105.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Ay2a&sa=D&source=editors&ust=1738042993887324&usg=AOvVaw0bNtFz5BrZ1ImZ0JdEerU2){.c4}]{.c3}

[[Jerald, J.
(2015).](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ipUJ&sa=D&source=editors&ust=1738042993887450&usg=AOvVaw3kBcUdYd6vi7K0TFDXYHF2){.c4}
]{.c3}[[The VR book: Human-centered design for virtual
reality](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ipUJ&sa=D&source=editors&ust=1738042993887526&usg=AOvVaw3fiFPZmN3f_kOx2YTKzhbp){.c4}]{.c5
.c6}[[. ACM
Books.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ipUJ&sa=D&source=editors&ust=1738042993887599&usg=AOvVaw2IZYl6CmIb22pKx8138dvV){.c4}
]{.c3}[[https://www.google.com/books/edition/The_VR_Book/ZEBiDwAAQBAJ?hl=en&gbpv=1&dq=Jason+Jerald&pg=PR11&printsec=frontcover](https://www.google.com/url?q=https://www.google.com/books/edition/The_VR_Book/ZEBiDwAAQBAJ?hl%3Den%26gbpv%3D1%26dq%3DJason%2BJerald%26pg%3DPR11%26printsec%3Dfrontcover&sa=D&source=editors&ust=1738042993887761&usg=AOvVaw0JW7OsmbQ6QpiofTSWx772){.c4}]{.c3}

[[Jiang, H., Lin, J., Jin, S., & Li, J. (2002). Micro-size LED and
detector arrays for minidisplay, hyper-bright light emitting diodes,
lighting, and UV detector and imaging sensor applications (USPTO Patent
No. 6410940).
In](https://www.google.com/url?q=http://paperpile.com/b/rDmune/K9T7&sa=D&source=editors&ust=1738042993887936&usg=AOvVaw0HNNUMLZovN8IWXjCAFnjy){.c4}
]{.c3}[[US
Patent](https://www.google.com/url?q=http://paperpile.com/b/rDmune/K9T7&sa=D&source=editors&ust=1738042993888014&usg=AOvVaw1DLxYl8GIve8UqA50PkaPx){.c4}]{.c5
.c6}[[ (No.
6410940).](https://www.google.com/url?q=http://paperpile.com/b/rDmune/K9T7&sa=D&source=editors&ust=1738042993888103&usg=AOvVaw2Mlog7Ef96NgH1mc7pDqkR){.c4}
]{.c3}[[https://patents.google.com/patent/US6410940B1/en](https://www.google.com/url?q=https://patents.google.com/patent/US6410940B1/en&sa=D&source=editors&ust=1738042993888207&usg=AOvVaw3ffAtZaH2QTYaYHV9lLdpd){.c4}]{.c3}

[[Kawamoto, H. (2002). The history of liquid-crystal
displays.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Fz8U&sa=D&source=editors&ust=1738042993888383&usg=AOvVaw3655HsYL_-q0yZntrcR7ZD){.c4}
]{.c3}[[Proceedings of the IEEE. Institute of Electrical and Electronics
Engineers](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Fz8U&sa=D&source=editors&ust=1738042993888467&usg=AOvVaw0Nh_sy03iAqNMiNVi05igc){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Fz8U&sa=D&source=editors&ust=1738042993888534&usg=AOvVaw1eMenulHMqNUMW3YsIFSEo){.c4}
]{.c3}[[90](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Fz8U&sa=D&source=editors&ust=1738042993888608&usg=AOvVaw0QEKIWAMOzvJNsjoGhGMd3){.c4}]{.c5
.c6}[[(4),
460--500.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Fz8U&sa=D&source=editors&ust=1738042993888682&usg=AOvVaw2GIk8MCmfkFOCpfJPtt8Vp){.c4}]{.c3}

[[Kelley, E. F., Lang, K., Silverstein, L. D., & Brill, M. H.
(2009).](https://www.google.com/url?q=http://paperpile.com/b/rDmune/pjWz&sa=D&source=editors&ust=1738042993888821&usg=AOvVaw2WEZ27VpOVGawVmGDlQDoW){.c4}
]{.c3}[[17.5: Projector Flux from Color
Primaries](https://www.google.com/url?q=http://paperpile.com/b/rDmune/pjWz&sa=D&source=editors&ust=1738042993888898&usg=AOvVaw3VyriVhVjEU7ZrAHNlH7kl){.c4}]{.c5
.c6}[[.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/pjWz&sa=D&source=editors&ust=1738042993888966&usg=AOvVaw3HleiYifDOId60xE2452SD){.c4}
]{.c3}[[https://www.nist.gov/publications/projector-flux-color-primaries](https://www.google.com/url?q=https://www.nist.gov/publications/projector-flux-color-primaries&sa=D&source=editors&ust=1738042993889096&usg=AOvVaw3UE6YQKGbAm8CI2Xg1o2dJ){.c4}]{.c3}

[[Kramida, G. (2016). Resolving the vergence-accommodation conflict in
head-mounted
displays.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ylUK&sa=D&source=editors&ust=1738042993889273&usg=AOvVaw1Ao645D0IUme7Y_1Njc7uj){.c4}
]{.c3}[[IEEE Transactions on Visualization and Computer
Graphics](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ylUK&sa=D&source=editors&ust=1738042993889385&usg=AOvVaw3dlBO4ophsR7N75mPYcj_X){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ylUK&sa=D&source=editors&ust=1738042993889482&usg=AOvVaw0F_YnsUaOWF1anGPdxNIZQ){.c4}
]{.c3}[[22](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ylUK&sa=D&source=editors&ust=1738042993889572&usg=AOvVaw02yVJ1npgSPrELFGpCuUrz){.c4}]{.c5
.c6}[[,
1912--1931.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ylUK&sa=D&source=editors&ust=1738042993889662&usg=AOvVaw2kgzIR9Q31AyvCFN4Scztf){.c4}]{.c3}

[[Law, H. B. (1976). The shadow mask color picture tube: How it
began---An eyewitness account of its early
history.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Cc3X&sa=D&source=editors&ust=1738042993889824&usg=AOvVaw2Sn4Lgd6-LJODevpUFmroQ){.c4}
]{.c3}[[IEEE Transactions on Electron
Devices](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Cc3X&sa=D&source=editors&ust=1738042993889899&usg=AOvVaw3Q-1qZWzRBcZLe_URXn63l){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Cc3X&sa=D&source=editors&ust=1738042993889968&usg=AOvVaw3ZyGaypC0Lh5JfqVh2Q3jz){.c4}
]{.c3}[[23](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Cc3X&sa=D&source=editors&ust=1738042993890043&usg=AOvVaw0CvYn8nW0pnVJAKt6GoGs3){.c4}]{.c5
.c6}[[(7),
752--759.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Cc3X&sa=D&source=editors&ust=1738042993890115&usg=AOvVaw0ftfmFOtQlsLZv2HsS0LXf){.c4}]{.c3}

[[Lee, B.-W., Park, C., Kim, S., Jeon, M., Heo, J., Sagong, D., Kim, J.,
& Souk, J. (2001). 51.2: Reducing gray‐level response to one frame:
Dynamic Capacitance
Compensation.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Zk9Z&sa=D&source=editors&ust=1738042993890290&usg=AOvVaw1Y9C5JfwmT9lGIdEAU70ul){.c4}
]{.c3}[[Digest of Technical Papers. SID International
Symposium](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Zk9Z&sa=D&source=editors&ust=1738042993890372&usg=AOvVaw0APuj9lh5giYrSgi2Ybkk6){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Zk9Z&sa=D&source=editors&ust=1738042993890442&usg=AOvVaw2cR3S2W9NwwQk3pff5bpdO){.c4}
]{.c3}[[32](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Zk9Z&sa=D&source=editors&ust=1738042993890510&usg=AOvVaw24pAL-taIItApb8XziahwP){.c4}]{.c5
.c6}[[(1),
1260--1263.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Zk9Z&sa=D&source=editors&ust=1738042993890581&usg=AOvVaw2xHXKxw3bgI3bxi6kugjYb){.c4}]{.c3}

[[Lee, S.-W., Kim, M., Souk, J. H., & Kim, S. S. (2006). Motion artifact
elimination technology for liquid‐crystal‐display monitors: Advanced
dynamic capacitance compensation
method.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/woLm&sa=D&source=editors&ust=1738042993890732&usg=AOvVaw2Yn_PuYWA_Hk_aL6A-U9R6){.c4}
]{.c3}[[Journal of the Society for Information
Display](https://www.google.com/url?q=http://paperpile.com/b/rDmune/woLm&sa=D&source=editors&ust=1738042993890817&usg=AOvVaw0DZd018U3eu8mHL67N_ndI){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/woLm&sa=D&source=editors&ust=1738042993890924&usg=AOvVaw2B-U649nktM-e8mC0x8KyL){.c4}
]{.c3}[[14](https://www.google.com/url?q=http://paperpile.com/b/rDmune/woLm&sa=D&source=editors&ust=1738042993891004&usg=AOvVaw0gIAIFjgtrdVJq_-mYEQzh){.c4}]{.c5
.c6}[[(4),
387--394.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/woLm&sa=D&source=editors&ust=1738042993891089&usg=AOvVaw00kuL9J-mqfTeZlEwkrKF4){.c4}]{.c3}

[[Luo, Z., Xu, D., & Wu, S.-T. (2014). Emerging Quantum-Dots-Enhanced
LCDs.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/XFvh&sa=D&source=editors&ust=1738042993891233&usg=AOvVaw2C1trCQBsRYhHx-ZeuP8JN){.c4}
]{.c3}[[Journal of Display
Technology](https://www.google.com/url?q=http://paperpile.com/b/rDmune/XFvh&sa=D&source=editors&ust=1738042993891315&usg=AOvVaw2Ak4CjgzQ3uBNfP4KcJxs4){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/XFvh&sa=D&source=editors&ust=1738042993891386&usg=AOvVaw1_IaqCeqv_ypP0vbbsmQh_){.c4}
]{.c3}[[10](https://www.google.com/url?q=http://paperpile.com/b/rDmune/XFvh&sa=D&source=editors&ust=1738042993891456&usg=AOvVaw3TupvAEPk4eqTl6tEdRode){.c4}]{.c5
.c6}[[(7),
526--539.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/XFvh&sa=D&source=editors&ust=1738042993891559&usg=AOvVaw0WzLPt0bvQ6UD6IG1TV0zI){.c4}]{.c3}

[[Lyons, N. P., & Farrell, J. E. (1989). Linear systems analysis of CRT
displays.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/QEri&sa=D&source=editors&ust=1738042993891739&usg=AOvVaw2-J7dTaTae4Fo8pPGvqqSO){.c4}
]{.c3}[[SID
Digest](https://www.google.com/url?q=http://paperpile.com/b/rDmune/QEri&sa=D&source=editors&ust=1738042993891822&usg=AOvVaw3YBPNudzLf06_6JssZGoQi){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/QEri&sa=D&source=editors&ust=1738042993891895&usg=AOvVaw0363hOx_fqW79Aiuxb9jtN){.c4}
]{.c3}[[10](https://www.google.com/url?q=http://paperpile.com/b/rDmune/QEri&sa=D&source=editors&ust=1738042993891963&usg=AOvVaw3ik1nER1ng9QkpQAKaf3Mg){.c4}]{.c5
.c6}[[,
220--223.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/QEri&sa=D&source=editors&ust=1738042993892057&usg=AOvVaw10fUVfTLnosRTs6hCuubnD){.c4}]{.c3}

[[Marcato, T., Oh, J., Lin, Z.-H., Shivarudraiah, S. B., Kumar, S.,
Zeng, S., & Shih, C.-J. (2024). Nanomolecular OLED Pixelization Enabling
Electroluminescent Metasurfaces.
In](https://www.google.com/url?q=http://paperpile.com/b/rDmune/fGqn&sa=D&source=editors&ust=1738042993892269&usg=AOvVaw0oagFCYBrMJD23DOB8PNqn){.c4}
]{.c3}[[arXiv
\[physics.optics\]](https://www.google.com/url?q=http://paperpile.com/b/rDmune/fGqn&sa=D&source=editors&ust=1738042993892351&usg=AOvVaw1JLeQEIPN7HrAfuB3S6ne3){.c4}]{.c5
.c6}[[.
arXiv.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/fGqn&sa=D&source=editors&ust=1738042993892424&usg=AOvVaw15Qn7vQp3SzDkZxxdDRtS0){.c4}
]{.c3}[[http://arxiv.org/abs/2404.05336](https://www.google.com/url?q=http://arxiv.org/abs/2404.05336&sa=D&source=editors&ust=1738042993892499&usg=AOvVaw2wdjUH_-EeBPqRw7CUk_a-){.c4}]{.c3}

[[Maxwell, J. C. (1860). IV. On the theory of compound colours, and the
relations of the colours of the
spectrum.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/b1Ta&sa=D&source=editors&ust=1738042993892643&usg=AOvVaw2KbWrwPUGYo38_AA9toGyt){.c4}
]{.c3}[[Philosophical Transactions of the Royal Society of
London](https://www.google.com/url?q=http://paperpile.com/b/rDmune/b1Ta&sa=D&source=editors&ust=1738042993892720&usg=AOvVaw3i6kZSeLU7EccjSg28O2Hj){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/b1Ta&sa=D&source=editors&ust=1738042993892798&usg=AOvVaw3vJicn1lmYZnCdtsJfra4U){.c4}
]{.c3}[[150](https://www.google.com/url?q=http://paperpile.com/b/rDmune/b1Ta&sa=D&source=editors&ust=1738042993892868&usg=AOvVaw0r2t274X0QZxMuMYgMSqbg){.c4}]{.c5
.c6}[[(0),
57--84.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/b1Ta&sa=D&source=editors&ust=1738042993892952&usg=AOvVaw3GG7F09FLniTBZ-5YWCCdZ){.c4}]{.c3}

[[McCreary, J. L. (2014). Correction of TFT non-uniformity in AMOLED
display (USPTO Patent No. 8624805).
In](https://www.google.com/url?q=http://paperpile.com/b/rDmune/J0ki&sa=D&source=editors&ust=1738042993893128&usg=AOvVaw10HlMRdoOxgeS1VhfpGrzS){.c4}
]{.c3}[[US
Patent](https://www.google.com/url?q=http://paperpile.com/b/rDmune/J0ki&sa=D&source=editors&ust=1738042993893245&usg=AOvVaw3gZvzKFZwkOd4lTxT218Tl){.c4}]{.c5
.c6}[[ (No.
8624805).](https://www.google.com/url?q=http://paperpile.com/b/rDmune/J0ki&sa=D&source=editors&ust=1738042993893334&usg=AOvVaw2847SimoqmqKYNBB018n2e){.c4}
]{.c3}[[https://patents.google.com/patent/US8624805B2/en](https://www.google.com/url?q=https://patents.google.com/patent/US8624805B2/en&sa=D&source=editors&ust=1738042993893426&usg=AOvVaw1knoR8wBpj7EkGXh1RHR3S){.c4}]{.c3}

[[MiniMicroLED, D. (2024, May 15). Highlights Of Micro LED Innovations
At 2024 SID Display
Week.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/i16o&sa=D&source=editors&ust=1738042993893580&usg=AOvVaw1uL-SWx6dsu3gpSh0Vbpjj){.c4}
]{.c3}[[Mini/MicroLED Insights \| Shaping the Future of Mini & Micro LED
Displays](https://www.google.com/url?q=http://paperpile.com/b/rDmune/i16o&sa=D&source=editors&ust=1738042993893671&usg=AOvVaw2agN0EJzAIDtf_l3cHEV4M){.c4}]{.c5
.c6}[[.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/i16o&sa=D&source=editors&ust=1738042993893741&usg=AOvVaw3CYoik3nrRtU_7gExjA_Zp){.c4}
]{.c3}[[https://www.minimicroled.com/2024-sid-display-week-highlights-of-micro-led-innovations-from-12-companies/](https://www.google.com/url?q=https://www.minimicroled.com/2024-sid-display-week-highlights-of-micro-led-innovations-from-12-companies/&sa=D&source=editors&ust=1738042993893925&usg=AOvVaw2y3XnrkG2ud4ScC2ZFuZrA){.c4}]{.c3}

[[Naiman, A. C., & Makous, W. (1993). Undetected gray strips displace
perceived edges
nonlinearly.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/OZwX&sa=D&source=editors&ust=1738042993894079&usg=AOvVaw0gvq5dFbZ_BFB7Nyi68dIs){.c4}
]{.c3}[[Journal of the Optical Society of America. A, Optics and Image
Science](https://www.google.com/url?q=http://paperpile.com/b/rDmune/OZwX&sa=D&source=editors&ust=1738042993894163&usg=AOvVaw0MvL9esbKxtPyebhGhsKZe){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/OZwX&sa=D&source=editors&ust=1738042993894264&usg=AOvVaw1erf6yTaDq2Aa9txVaWo_I){.c4}
]{.c3}[[10](https://www.google.com/url?q=http://paperpile.com/b/rDmune/OZwX&sa=D&source=editors&ust=1738042993894421&usg=AOvVaw0cR5FpZ_f97AYHV5SVBdpi){.c4}]{.c5
.c6}[[(5),
794--803.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/OZwX&sa=D&source=editors&ust=1738042993894499&usg=AOvVaw0JLbdrh9YjZstF3b_Une-6){.c4}]{.c3}

[[Packer, O., Diller, L. C., Verweij, J., Lee, B. B., Pokorny, J.,
Williams, D. R., Dacey, D. M., & Brainard, D. H. (2001).
Characterization and use of a digital light projector for vision
research.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/sh8P&sa=D&source=editors&ust=1738042993894667&usg=AOvVaw3gYwMEgYTB3wh7SpPAZH0C){.c4}
]{.c3}[[Vision
Research](https://www.google.com/url?q=http://paperpile.com/b/rDmune/sh8P&sa=D&source=editors&ust=1738042993894743&usg=AOvVaw0Kc_bU3_zE2lF4fmWOP0TX){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/sh8P&sa=D&source=editors&ust=1738042993894843&usg=AOvVaw2fPFyoJWOJqNVYsDS6QKHB){.c4}
]{.c3}[[41](https://www.google.com/url?q=http://paperpile.com/b/rDmune/sh8P&sa=D&source=editors&ust=1738042993894917&usg=AOvVaw06r7_HySRM4Lrm7c2fn4J2){.c4}]{.c5
.c6}[[(4),
427--439.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/sh8P&sa=D&source=editors&ust=1738042993894990&usg=AOvVaw08un1yO38KABInJoD5VVKg){.c4}]{.c3}

[[Pelli, D. G. (1997). Pixel independence: measuring spatial
interactions on a CRT
display.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Qfii&sa=D&source=editors&ust=1738042993895156&usg=AOvVaw2E5ZYxc8sN-Xhdy4AIdaCw){.c4}
]{.c3}[[Spatial
Vision](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Qfii&sa=D&source=editors&ust=1738042993895229&usg=AOvVaw1mc7hZyNTmvfrElvXO2Y7z){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Qfii&sa=D&source=editors&ust=1738042993895298&usg=AOvVaw0kyzo9mcbxqFDhHZ2_esCe){.c4}
]{.c3}[[10](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Qfii&sa=D&source=editors&ust=1738042993895372&usg=AOvVaw21Ef2BvtuP5mIGYUSPqgDp){.c4}]{.c5
.c6}[[(4),
443--446.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Qfii&sa=D&source=editors&ust=1738042993895444&usg=AOvVaw1E27S2zRv691CsHEn4S2V7){.c4}]{.c3}

[[Post, D. L. (1992). Colorimetric measurement, calibration, and
characterization of self-luminous displays.
In](https://www.google.com/url?q=http://paperpile.com/b/rDmune/0yTJ&sa=D&source=editors&ust=1738042993895644&usg=AOvVaw2PNJEMMUIABa18_E2w8EU4){.c4}
]{.c3}[[Color in Electronic
Displays](https://www.google.com/url?q=http://paperpile.com/b/rDmune/0yTJ&sa=D&source=editors&ust=1738042993895723&usg=AOvVaw0YApgmAK1oJyEcaiA3QouE){.c4}]{.c5
.c6}[[ (pp. 299--312). Springer
US.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/0yTJ&sa=D&source=editors&ust=1738042993895807&usg=AOvVaw0gd7Mzk6pJTn6ulreKTwA5){.c4}]{.c3}

[[Poynton, C. (1993). Gamma and its disguises : The nonlinear mappings
of intensity in perception, CRTs, film, and
video.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/x1cy&sa=D&source=editors&ust=1738042993895946&usg=AOvVaw3oXwnoOE9vDr_f4k3ZqxYX){.c4}
]{.c3}[[Smpte
Journal](https://www.google.com/url?q=http://paperpile.com/b/rDmune/x1cy&sa=D&source=editors&ust=1738042993896023&usg=AOvVaw3xXJgbT9O7o0brP_0DU_pf){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/x1cy&sa=D&source=editors&ust=1738042993896094&usg=AOvVaw1H9k1Dh6gxy8AL_9rWdj_V){.c4}
]{.c3}[[102](https://www.google.com/url?q=http://paperpile.com/b/rDmune/x1cy&sa=D&source=editors&ust=1738042993896164&usg=AOvVaw06-BBMyzzEj1lBZ_FBFq10){.c4}]{.c5
.c6}[[,
1099--1108.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/x1cy&sa=D&source=editors&ust=1738042993896234&usg=AOvVaw3mLx7v-xY-jVtdEkzXCz21){.c4}]{.c3}

[[Poynton, C., & Funt, B. (2014). Perceptual uniformity in digital image
representation and
display.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/8fWH&sa=D&source=editors&ust=1738042993896364&usg=AOvVaw1obOYiUbjxQ8us4Fpn1GfW){.c4}
]{.c3}[[Color Research and
Application](https://www.google.com/url?q=http://paperpile.com/b/rDmune/8fWH&sa=D&source=editors&ust=1738042993896440&usg=AOvVaw1wW989NJ2-xxg1e7OdKW3H){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/8fWH&sa=D&source=editors&ust=1738042993896507&usg=AOvVaw1EtsZnqU0BesDZTfBVfs4g){.c4}
]{.c3}[[39](https://www.google.com/url?q=http://paperpile.com/b/rDmune/8fWH&sa=D&source=editors&ust=1738042993896574&usg=AOvVaw03cj-q6IrlZUJEbIMEzLax){.c4}]{.c5
.c6}[[(1),
6--15.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/8fWH&sa=D&source=editors&ust=1738042993896643&usg=AOvVaw1PiRRpPytPsQmPWzv3A_2V){.c4}]{.c3}

[[Rolland, J. P., & Goodsell, J. (2024). Waveguide-based augmented
reality displays: a
highlight.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/WUgk&sa=D&source=editors&ust=1738042993896790&usg=AOvVaw09-1-9a5vESXkrUI4XiUWc){.c4}
]{.c3}[[Light, Science &
Applications](https://www.google.com/url?q=http://paperpile.com/b/rDmune/WUgk&sa=D&source=editors&ust=1738042993896868&usg=AOvVaw0qZGPj2ixiocm-VfJbadi5){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/WUgk&sa=D&source=editors&ust=1738042993896937&usg=AOvVaw2_yCy-rKPOMYwfQho2peIQ){.c4}
]{.c3}[[13](https://www.google.com/url?q=http://paperpile.com/b/rDmune/WUgk&sa=D&source=editors&ust=1738042993897015&usg=AOvVaw3KPUnyA4n8V57gUpd1KFxr){.c4}]{.c5
.c6}[[(1),
22.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/WUgk&sa=D&source=editors&ust=1738042993897092&usg=AOvVaw3npF9cVX7XYvMa1wFuB14l){.c4}]{.c3}

[[Seetzen, H., Heidrich, W., Stuerzlinger, W., Ward, G., Whitehead, L.,
Trentacoste, M., Ghosh, A., & Vorozcovs, A. (2004). High dynamic range
display
systems.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Vla5&sa=D&source=editors&ust=1738042993897239&usg=AOvVaw2KRWy2QsEzyX0RpEEcRSTp){.c4}
]{.c3}[[ACM Transactions on
Graphics](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Vla5&sa=D&source=editors&ust=1738042993897318&usg=AOvVaw004fU6C9pnCuWaSIz4gEVk){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Vla5&sa=D&source=editors&ust=1738042993897387&usg=AOvVaw0SasH3TSsMF9PEnKxFMxVO){.c4}
]{.c3}[[23](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Vla5&sa=D&source=editors&ust=1738042993897456&usg=AOvVaw3vFlk8fGT1NwtuUUOxnV0b){.c4}]{.c5
.c6}[[(3),
760--768.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Vla5&sa=D&source=editors&ust=1738042993897527&usg=AOvVaw3KkohmbjvYwYA4EpvcYBhd){.c4}]{.c3}

[[Silverstein, L.D., Fiske, T.G. (1993). Colorimetric and photometric
modeling of liquid crystal
displays.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/bmaJ&sa=D&source=editors&ust=1738042993897665&usg=AOvVaw1tjyn23cC3zASmlIGDEbmC){.c4}
]{.c3}[[Color and Imaging Conference. Vol. 1993. No.
1](https://www.google.com/url?q=http://paperpile.com/b/rDmune/bmaJ&sa=D&source=editors&ust=1738042993897743&usg=AOvVaw01VHWhwWRVfzuGpqdBjYvx){.c4}]{.c5
.c6}[[. Color and Imaging Conference., Scottsdale,
AZ.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/bmaJ&sa=D&source=editors&ust=1738042993897826&usg=AOvVaw1aCny5yzo6tpWeH1fA2ZZe){.c4}
]{.c3}[[https://library.imaging.org/admin/apis/public/api/ist/website/downloadArticle/cic/1/1/art00038](https://www.google.com/url?q=https://library.imaging.org/admin/apis/public/api/ist/website/downloadArticle/cic/1/1/art00038&sa=D&source=editors&ust=1738042993897965&usg=AOvVaw2a_iU9qmYmty1oKyAKvF-K){.c4}]{.c3}

[[Singh, L., Dubey, R., & Rai, R. N.
(2023).](https://www.google.com/url?q=http://paperpile.com/b/rDmune/gCx2&sa=D&source=editors&ust=1738042993898108&usg=AOvVaw2uQb80ZzdgpHTQjVJbvJt3){.c4}
]{.c3}[[Organic light emitting diode (OLED) toward smart lighting and
displays technologies: Material design strategies, challenges and future
perspectives](https://www.google.com/url?q=http://paperpile.com/b/rDmune/gCx2&sa=D&source=editors&ust=1738042993898197&usg=AOvVaw3HAXUA93pr1WPvU8MogXaH){.c4}]{.c5
.c6}[[ (L. Singh, R. Dubey, & R. N. Rai (eds.)). CRC
Press.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/gCx2&sa=D&source=editors&ust=1738042993898279&usg=AOvVaw3nq_swjzltecJYqVy4GJGl){.c4}
]{.c3}[[https://books.google.com/books?hl=en&lr=&id=TqMIEQAAQBAJ&oi=fnd&pg=PP1&dq=Organic+Light+Emitting+Diode+(OLED)+Toward+Smart+Lighting+and+Displays+Technologies&ots=44pGRTvA2V&sig=80HUNiFW_xl0giEpVt2YdscHB30](https://www.google.com/url?q=https://books.google.com/books?hl%3Den%26lr%3D%26id%3DTqMIEQAAQBAJ%26oi%3Dfnd%26pg%3DPP1%26dq%3DOrganic%2BLight%2BEmitting%2BDiode%2B(OLED)%2BToward%2BSmart%2BLighting%2Band%2BDisplays%2BTechnologies%26ots%3D44pGRTvA2V%26sig%3D80HUNiFW_xl0giEpVt2YdscHB30&sa=D&source=editors&ust=1738042993898502&usg=AOvVaw39yW4jNGAPhIv-QN4CevcV){.c4}]{.c3}

[[Smith, J. M., Ley, R., Wong, M. S., Baek, Y. H., Kang, J. H., Kim, C.
H., Gordon, M. J., Nakamura, S., Speck, J. S., & DenBaars, S. P. (2020).
Comparison of size-dependent characteristics of blue and green InGaN
microLEDs down to
1](https://www.google.com/url?q=http://paperpile.com/b/rDmune/tvR7&sa=D&source=editors&ust=1738042993898684&usg=AOvVaw26dSHAAeZMmU08I46xqrlW){.c4}
]{.c3}[[μ](https://www.google.com/url?q=http://paperpile.com/b/rDmune/tvR7&sa=D&source=editors&ust=1738042993898764&usg=AOvVaw1LjqGYKRnmAVr6sOjcww9C){.c4}]{.c5
.c6}[[ m in
diameter.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/tvR7&sa=D&source=editors&ust=1738042993898841&usg=AOvVaw0y6xQ0w_atqH8PSXtzEIYn){.c4}
]{.c3}[[Applied Physics
Letters](https://www.google.com/url?q=http://paperpile.com/b/rDmune/tvR7&sa=D&source=editors&ust=1738042993898915&usg=AOvVaw2oj5mcvkI7UL0eNgHfXLM_){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/tvR7&sa=D&source=editors&ust=1738042993898984&usg=AOvVaw3FE4w2clWZ0mWo0PvjpQSs){.c4}
]{.c3}[[116](https://www.google.com/url?q=http://paperpile.com/b/rDmune/tvR7&sa=D&source=editors&ust=1738042993899084&usg=AOvVaw1c_3cDRvQMhEpLr4NNIMQs){.c4}]{.c5
.c6}[[(7),
071102.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/tvR7&sa=D&source=editors&ust=1738042993899218&usg=AOvVaw0yLR27SiHrveYFkCw3GTYW){.c4}]{.c3}

[[Stevens, S. S. (1957). On the psychophysical
law.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/L5vo&sa=D&source=editors&ust=1738042993899486&usg=AOvVaw0pTjXQIz3v3mjmKz58SXW7){.c4}
]{.c3}[[Psychology
Review](https://www.google.com/url?q=http://paperpile.com/b/rDmune/L5vo&sa=D&source=editors&ust=1738042993899624&usg=AOvVaw1utl1bCXP24O2cRaTHrwy0){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/L5vo&sa=D&source=editors&ust=1738042993899761&usg=AOvVaw3PGtSAquNVNryz24ZDGe2S){.c4}
]{.c3}[[64](https://www.google.com/url?q=http://paperpile.com/b/rDmune/L5vo&sa=D&source=editors&ust=1738042993899851&usg=AOvVaw0vFEMVfptVTkwSL1u1zpaA){.c4}]{.c5
.c6}[[(3),
153--181.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/L5vo&sa=D&source=editors&ust=1738042993899941&usg=AOvVaw1iqBtmqh-OVqmK6pOtiFAn){.c4}]{.c3}

[[Su, R., Park, S. H., Ouyang, X., Ahn, S. I., & McAlpine, M. C. (2022).
3D-printed flexible organic light-emitting diode
displays.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ENGQ&sa=D&source=editors&ust=1738042993900102&usg=AOvVaw2heu_cVhAhBhF2RqC3_JKn){.c4}
]{.c3}[[Science
Advances](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ENGQ&sa=D&source=editors&ust=1738042993900197&usg=AOvVaw3lnRGIgO61c0DYc3tMtA5M){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ENGQ&sa=D&source=editors&ust=1738042993900327&usg=AOvVaw2erjnfxhMVtjU2RBbGWEJz){.c4}
]{.c3}[[8](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ENGQ&sa=D&source=editors&ust=1738042993900451&usg=AOvVaw0DrQ-c_9H_agCdIa3boWq8){.c4}]{.c5
.c6}[[(1),
eabl8798.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ENGQ&sa=D&source=editors&ust=1738042993900598&usg=AOvVaw3CaSdbmXZuz_c3PONZcpQo){.c4}]{.c3}

[[Tang, C., & Vanslyke, S. (1987). Organic Electroluminescent
Diodes.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Vf1l&sa=D&source=editors&ust=1738042993900885&usg=AOvVaw1op_Zu9gdoLj6di3JVG7M0){.c4}
]{.c3}[[Applied Physics
Letters](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Vf1l&sa=D&source=editors&ust=1738042993901052&usg=AOvVaw3oU2xr8GTokqkd_sKDeO0B){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Vf1l&sa=D&source=editors&ust=1738042993901189&usg=AOvVaw09zxAglo5JYp1u_3UjFU79){.c4}
]{.c3}[[51](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Vf1l&sa=D&source=editors&ust=1738042993901319&usg=AOvVaw3TU8PkkWa277KICdyRI20-){.c4}]{.c5
.c6}[[,
913--915.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Vf1l&sa=D&source=editors&ust=1738042993901454&usg=AOvVaw2mYSThNfqmGLCfJPkZiXqh){.c4}]{.c3}

[[Toscani, M., Gil, R., Guarnera, D., Guarnera, G., Kalouaz, A., &
Gegenfurtner, K. R. (2019). Assessment of OLED head mounted display for
vision research with virtual
reality.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/w7FM&sa=D&source=editors&ust=1738042993901729&usg=AOvVaw31wbhsJUHUNdXlNrwuU7Nx){.c4}
]{.c3}[[2019 15th International Conference on Signal-Image Technology &
Internet-Based Systems
(SITIS)](https://www.google.com/url?q=http://paperpile.com/b/rDmune/w7FM&sa=D&source=editors&ust=1738042993901848&usg=AOvVaw3NlApeMKWhFrQ-s8nXaPqV){.c4}]{.c5
.c6}[[,
738--745.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/w7FM&sa=D&source=editors&ust=1738042993901926&usg=AOvVaw0KX5qnO0gg5gieEAnWsjAb){.c4}]{.c3}

[[Travis, D.
(n.d.).](https://www.google.com/url?q=http://paperpile.com/b/rDmune/sI2C&sa=D&source=editors&ust=1738042993902088&usg=AOvVaw1NkiJ-nFlrbvUHHxjqcFB_){.c4}
]{.c3}[[ISO 9241: Part
3](https://www.google.com/url?q=http://paperpile.com/b/rDmune/sI2C&sa=D&source=editors&ust=1738042993902217&usg=AOvVaw32xG4x2nN7Ls62I_Jx_byG){.c4}]{.c5
.c6}[[. Retrieved December 30, 2024,
from](https://www.google.com/url?q=http://paperpile.com/b/rDmune/sI2C&sa=D&source=editors&ust=1738042993902347&usg=AOvVaw2IRAk2dNwZzD7545KCtpZq){.c4}
]{.c3}[[https://www.userfocus.co.uk/resources/iso9241/part3.html?t](https://www.google.com/url?q=https://www.userfocus.co.uk/resources/iso9241/part3.html?t&sa=D&source=editors&ust=1738042993902540&usg=AOvVaw1cJJRLaNiJcv3qL-OHolta){.c4}]{.c3}

[[Tsujimura, T.
(2017).](https://www.google.com/url?q=http://paperpile.com/b/rDmune/eUhb&sa=D&source=editors&ust=1738042993902821&usg=AOvVaw2JLCWR_xqwx-l0cl1nkdaI){.c4}
]{.c3}[[OLED Display Fundamentals and
Applications](https://www.google.com/url?q=http://paperpile.com/b/rDmune/eUhb&sa=D&source=editors&ust=1738042993902976&usg=AOvVaw1AQ77CZqzq3vYjjztFLcmK){.c4}]{.c5
.c6}[[ (2nd ed.) \[PDF\]. John Wiley &
Sons.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/eUhb&sa=D&source=editors&ust=1738042993903115&usg=AOvVaw3AXwsdzbsMtqlv5AKLpxQ1){.c4}]{.c3}

[[Wandell, B. A.
(1995).](https://www.google.com/url?q=http://paperpile.com/b/rDmune/2zzl&sa=D&source=editors&ust=1738042993903300&usg=AOvVaw0kv2ae81aiZkuV1ApEi_8d){.c4}
]{.c3}[[Foundations of vision: Behaviour, neuroscience, and
computation](https://www.google.com/url?q=http://paperpile.com/b/rDmune/2zzl&sa=D&source=editors&ust=1738042993903386&usg=AOvVaw3uLJiRIBzKQpeuR7g_CPx5){.c4}]{.c5
.c6}[[. Sinauer
Associates.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/2zzl&sa=D&source=editors&ust=1738042993903460&usg=AOvVaw2djfgHoWbKvgg0brq6sNSZ){.c4}]{.c3}

[[Wandell, B. A., & Silverstein, L. D. (2003). Digital Color
Reproduction.
In](https://www.google.com/url?q=http://paperpile.com/b/rDmune/PVJo&sa=D&source=editors&ust=1738042993903591&usg=AOvVaw3fyOk0wF67-SLIsRo7KmfX){.c4}
]{.c3}[[The Science of
Color](https://www.google.com/url?q=http://paperpile.com/b/rDmune/PVJo&sa=D&source=editors&ust=1738042993903679&usg=AOvVaw0qO7dwc0-5cbCKN98Kma43){.c4}]{.c5
.c6}[[ (Vol. 2, pp. 281--316).
Elsevier.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/PVJo&sa=D&source=editors&ust=1738042993903818&usg=AOvVaw2kJbwYPZBrjpZ5-WSv4PP9){.c4}]{.c3}

[[Wang, T., Yang, C., Chen, J., Zhao, Y., & Zong, J. (2024). Naked-eye
light field display technology based on mini/micro light emitting diode
panels: a systematic review and
meta-analysis.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/CnGQ&sa=D&source=editors&ust=1738042993904084&usg=AOvVaw0jKvmRTNQAZcZHcv_-ej14){.c4}
]{.c3}[[Scientific
Reports](https://www.google.com/url?q=http://paperpile.com/b/rDmune/CnGQ&sa=D&source=editors&ust=1738042993904234&usg=AOvVaw2kE6Ttr0454e2uiJNwNqWp){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/CnGQ&sa=D&source=editors&ust=1738042993904354&usg=AOvVaw0tvBuqO6FSTTb7CdMa_ly8){.c4}
]{.c3}[[14](https://www.google.com/url?q=http://paperpile.com/b/rDmune/CnGQ&sa=D&source=editors&ust=1738042993904542&usg=AOvVaw0Rzvl2C-ZJXf9JGWqrT6fF){.c4}]{.c5
.c6}[[(1),
24381.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/CnGQ&sa=D&source=editors&ust=1738042993904632&usg=AOvVaw2Hw4gWEstqeHH5BQdxNhzN){.c4}]{.c3}

[[Watson, A. B., J., A. J. A., & Farrell, J. E. (1986). Window of
visibility: a psychophysical theory of fidelity in time-sampled visual
motion
displays.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/hv8D&sa=D&source=editors&ust=1738042993904818&usg=AOvVaw39fg_88zXYoKsuY-ZuOV8G){.c4}
]{.c3}[[Journal of the Optical Society of America
A](https://www.google.com/url?q=http://paperpile.com/b/rDmune/hv8D&sa=D&source=editors&ust=1738042993904952&usg=AOvVaw3wkNQPa24ha05PRgUSUUEc){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/hv8D&sa=D&source=editors&ust=1738042993905074&usg=AOvVaw1yEjrxdjMPfSbq7QTdE6mp){.c4}
]{.c3}[[3](https://www.google.com/url?q=http://paperpile.com/b/rDmune/hv8D&sa=D&source=editors&ust=1738042993905193&usg=AOvVaw2TVFYHQhN5gKwIOjCwVp9S){.c4}]{.c5
.c6}[[(3),
300--307.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/hv8D&sa=D&source=editors&ust=1738042993905336&usg=AOvVaw0dRvSqvriEJ_zJQ0_-B7GC){.c4}]{.c3}

[[Wyszecki, G., & Stiles, W. S.
(1982).](https://www.google.com/url?q=http://paperpile.com/b/rDmune/E40X&sa=D&source=editors&ust=1738042993905607&usg=AOvVaw0PyTbqLfQTsczfLoxT9OFw){.c4}
]{.c3}[[Color
science](https://www.google.com/url?q=http://paperpile.com/b/rDmune/E40X&sa=D&source=editors&ust=1738042993905766&usg=AOvVaw2dcMOT52Brb6ORaYtD9OA0){.c4}]{.c5
.c6}[[ (Vol. 8). Wiley New
York.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/E40X&sa=D&source=editors&ust=1738042993905909&usg=AOvVaw2eCZ0yidGAwyQK-0TSM8wK){.c4}]{.c3}

[[Xu, B., Zhou, J., Zhang, C., Chang, Y., & Deng, Z. (2025). Research
progress on quantum dot-embedded polymer films and plates for LCD
backlight
display.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/BBSB&sa=D&source=editors&ust=1738042993906160&usg=AOvVaw1X_dtYBT9Bhiag_ldNd-V-){.c4}
]{.c3}[[Polymers](https://www.google.com/url?q=http://paperpile.com/b/rDmune/BBSB&sa=D&source=editors&ust=1738042993906303&usg=AOvVaw2TOs-zgySvD6xzowtrgUzz){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/BBSB&sa=D&source=editors&ust=1738042993906389&usg=AOvVaw2E838f0iezAL91KsMX78EW){.c4}
]{.c3}[[17](https://www.google.com/url?q=http://paperpile.com/b/rDmune/BBSB&sa=D&source=editors&ust=1738042993906458&usg=AOvVaw3-m-iOGrWjlxXESXEDTNhS){.c4}]{.c5
.c6}[[(2),
233.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/BBSB&sa=D&source=editors&ust=1738042993906527&usg=AOvVaw10pvum7VnJbEIPgvnDyhKN){.c4}]{.c3}

[[Yakovlev, D. A., Chigrinov, V. G., & Kwok, H.-S.
(2015).](https://www.google.com/url?q=http://paperpile.com/b/rDmune/R0sH&sa=D&source=editors&ust=1738042993906681&usg=AOvVaw1pINr9RGx4eGt3WnE7YK9m){.c4}
]{.c3}[[Modeling and optimization of LCD optical performance:
Yakovlev/modeling](https://www.google.com/url?q=http://paperpile.com/b/rDmune/R0sH&sa=D&source=editors&ust=1738042993906828&usg=AOvVaw2UdT2wDjdD_fBj5UPsFcbU){.c4}]{.c5
.c6}[[ (D. A. Yakovlev, V. G. Chigrinov, & H.-S. Kwok (eds.); 1st ed.)
\[PDF\].
Wiley-Blackwell.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/R0sH&sa=D&source=editors&ust=1738042993906973&usg=AOvVaw2sp6g39MCI6nN2-m9-qPU1){.c4}]{.c3}

[[Yang, D.-K., & Wu, S.-T.
(2014).](https://www.google.com/url?q=http://paperpile.com/b/rDmune/XJuv&sa=D&source=editors&ust=1738042993907210&usg=AOvVaw1e7mL8mcnE2X5Ci_brS-eM){.c4}
]{.c3}[[Fundamentals of liquid crystal
devices](https://www.google.com/url?q=http://paperpile.com/b/rDmune/XJuv&sa=D&source=editors&ust=1738042993907330&usg=AOvVaw0tFixq32lgcQKoCXclagBf){.c4}]{.c5
.c6}[[ (2nd ed.) \[EPUB\].
Wiley-Blackwell.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/XJuv&sa=D&source=editors&ust=1738042993907414&usg=AOvVaw28fgrlTue_Q4KQnGtLx3ft){.c4}]{.c3}

[[Younse, J. (1993). Mirrors on a
chip.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/9Bo1&sa=D&source=editors&ust=1738042993907615&usg=AOvVaw26CVarmJ8Qo6hODxbVn2Ba){.c4}
]{.c3}[[IEEE
Spectrum](https://www.google.com/url?q=http://paperpile.com/b/rDmune/9Bo1&sa=D&source=editors&ust=1738042993907746&usg=AOvVaw1OqXl8SzssDAMqbSptFUII){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/9Bo1&sa=D&source=editors&ust=1738042993907882&usg=AOvVaw1J__9kjk82luBSxo2lQ30P){.c4}
]{.c3}[[30](https://www.google.com/url?q=http://paperpile.com/b/rDmune/9Bo1&sa=D&source=editors&ust=1738042993908031&usg=AOvVaw3zL-hke1pjzPTgo0a7baRO){.c4}]{.c5
.c6}[[,
27--31.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/9Bo1&sa=D&source=editors&ust=1738042993908195&usg=AOvVaw3tWkeCvaGIW6K2XFoQTlWs){.c4}]{.c3}

[[Zaman, N., Sarker, P., & Tavakkoli, A. (2023). Calibration of head
mounted displays for vision research with virtual
reality.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Ids2&sa=D&source=editors&ust=1738042993908475&usg=AOvVaw15bHm5nRaMq_X7RSUHCip9){.c4}
]{.c3}[[Journal of
Vision](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Ids2&sa=D&source=editors&ust=1738042993908627&usg=AOvVaw0Yv4Df2bkebMLmrluB0hE_){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Ids2&sa=D&source=editors&ust=1738042993908773&usg=AOvVaw3YdUcB8WGxQuE_0zHmjY7U){.c4}
]{.c3}[[23](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Ids2&sa=D&source=editors&ust=1738042993908901&usg=AOvVaw0pQKrPQP1UKt-And3pmgT_){.c4}]{.c5
.c6}[[.
https://doi.org/](https://www.google.com/url?q=http://paperpile.com/b/rDmune/Ids2&sa=D&source=editors&ust=1738042993909025&usg=AOvVaw0WKYVC3s7UK_Ja7q1y4_Ho){.c4}]{.c3}[[10.1167/jov.23.6.7](https://www.google.com/url?q=http://dx.doi.org/10.1167/jov.23.6.7&sa=D&source=editors&ust=1738042993909131&usg=AOvVaw2zMj2h56hE3w32WNAbA9Lu){.c4}]{.c3}

[[Zhang, X., & Farrell, J. E. (2003). Sequential color breakup measured
with induced saccades. In B. E. Rogowitz & T. N. Pappas
(Eds.),](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ayA6&sa=D&source=editors&ust=1738042993909306&usg=AOvVaw3FY5SjrPz1yulRmhuYm-T_){.c4}
]{.c3}[[Human Vision and Electronic Imaging
VIII](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ayA6&sa=D&source=editors&ust=1738042993909397&usg=AOvVaw1s_EVa1N_dbd95rm4Itgry){.c4}]{.c5
.c6}[[. SPIE.
https://doi.org/](https://www.google.com/url?q=http://paperpile.com/b/rDmune/ayA6&sa=D&source=editors&ust=1738042993909527&usg=AOvVaw2-72YqXrTLssbXFr_EyQ87){.c4}]{.c3}[[10.1117/12.497843](https://www.google.com/url?q=http://dx.doi.org/10.1117/12.497843&sa=D&source=editors&ust=1738042993909658&usg=AOvVaw0IBVwMaGoZuP8EN9-zKUVf){.c4}]{.c3}

[[Zhang, X., & Wandell, B. A. (1997). A spatial extension of CIELAB for
digital color‐image
reproduction.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/zQ8e&sa=D&source=editors&ust=1738042993909962&usg=AOvVaw2g3XUVjtT4l8Q9E8F8t522){.c4}
]{.c3}[[Journal of the Society for Information
Display](https://www.google.com/url?q=http://paperpile.com/b/rDmune/zQ8e&sa=D&source=editors&ust=1738042993910118&usg=AOvVaw3VMoW5KZOQA8cktKWNIPLX){.c4}]{.c5
.c6}[[,](https://www.google.com/url?q=http://paperpile.com/b/rDmune/zQ8e&sa=D&source=editors&ust=1738042993910257&usg=AOvVaw0OZp5I3AqodKQPXNLcX02W){.c4}
]{.c3}[[5](https://www.google.com/url?q=http://paperpile.com/b/rDmune/zQ8e&sa=D&source=editors&ust=1738042993910374&usg=AOvVaw060Teb1f1U3FKWsvUjytn4){.c4}]{.c5
.c6}[[(1),
61--63.](https://www.google.com/url?q=http://paperpile.com/b/rDmune/zQ8e&sa=D&source=editors&ust=1738042993910513&usg=AOvVaw0-GqZpggZ_qqEou2DsKm3S){.c4}]{.c3}

[[Zhang, Y., Song, W., & Teunissen, K. (2007). A tradeoff between motion
blur and flicker visibility of electronic display devices. In L. Zhou
(Ed.),](https://www.google.com/url?q=http://paperpile.com/b/rDmune/jlep&sa=D&source=editors&ust=1738042993910705&usg=AOvVaw02rdwaGJ98l3Gqd7xgcbxN){.c4}
]{.c3}[[International Symposium on Photoelectronic Detection and Imaging
2007: Related Technologies and
Applications](https://www.google.com/url?q=http://paperpile.com/b/rDmune/jlep&sa=D&source=editors&ust=1738042993910806&usg=AOvVaw2LE6sjzeVFba-ZbY9awQwA){.c4}]{.c5
.c6}[[. SPIE.
https://doi.org/](https://www.google.com/url?q=http://paperpile.com/b/rDmune/jlep&sa=D&source=editors&ust=1738042993910885&usg=AOvVaw1Ot8GSdfYMmzV8pVk5lBFK){.c4}]{.c3}[[10.1117/12.790748](https://www.google.com/url?q=http://dx.doi.org/10.1117/12.790748&sa=D&source=editors&ust=1738042993911008&usg=AOvVaw1G2Jd5IrkR5KDdvIHw5jxZ){.c4}]{.c3}

[]{.c5 .c22 .c9 .c14}

------------------------------------------------------------------------

<div>

[\[1\]](#ftnt_ref1){#ftnt1}[ https://github.com/isetbio/isetbio/wiki]{.c5
.c23 .c9}

</div>

<div>

[\[2\]](#ftnt_ref2){#ftnt2}[ https://github.com/iset/isetcam/wiki]{.c5
.c23 .c9}

</div>

<div>

[\[3\]](#ftnt_ref3){#ftnt3}[ https://www.apple.com/apple-vision-pro/specs/]{.c5
.c23 .c9}

</div>

::: c24
[\[a\]](#cmnt_ref1){#cmnt1}[Edited.]{.c5 .c9 .c32}
:::

::: c24
[\[b\]](#cmnt_ref2){#cmnt2}[Edited.]{.c5 .c32 .c9}
:::

::: c24
[\[c\]](#cmnt_ref3){#cmnt3}[To check.]{.c5 .c32 .c9}
:::
