# Geometric optics {#sec-geometric-optics}

## Geometric optics overview 
Modeling light as rays is a useful approximation for many calculations. This method of enables us to use simple geometric calculations, such as the extensive use of similar triangles, to derive many properties of simple lenses. For this reason this approach is also called **geometric optics**. In this chapter we describe the simplest image forming optics, a **pinhole**. After understanding the logic of modeling using rays and pinholes, I explain the limitations of the ray model and why we will also model light as waves. Finally, I discuss the key concept of the **point spread function**, which plays a role in all the different modeling approaches. We will extend the geometric optics calculations in the next few chapters, before we turn to linear systems theory and wavefronts (Fourier optics).

## Pinhole optics
If we model light as a collection of rays, it is easy to understand why imaging through a pinhole produces an image (@fig-pinhole-image). The figure shows a set of *objects* on the left.  The camera is a dark chamber with only a pinhole opening. The *image* is formed on the planar surface, at the right.  The light rays travel in a straight line, so only a small subset of the rays from each object passing through the pinhole.  We can trace the light path by starting at a point on the image and drawing a straight line into the object space. The geometry illustrates how the rays from adjacent objects arrive at adjacent positions in the image plane, forming a reversed and inverted image.

![A pinhole makes an image.](images/optics/06-geometric/pinhole-image.png){#fig-pinhole-image width=60%}

If the pinhole is small, each image point receives rays from a small region in object space (@fig-pinhole-blur). As we increase the pinhole diameter, each image point receives rays from larger regions on the objects. If multiple objects contribute rays to an image point, the image will be blurry. Conversely, according to the ray model, reducing the pinhole size should sharpen the image.

![Why enlarging the pinhole increases the blur.](images/optics/06-geometric/pinhole-blur.png){#fig-pinhole-blur width=60%}

### Parallel (collimated) rays
The rays from a point on an object often radiate in a wide range of directions. A special case -that is important in many practical applications- are the rays from distant points (@fig-pinhole-distant). When the point is far, only a small angular bundle of rays arrives at the pinhole. When the angle is very small, the rays are nearly parallel. In that case we say the beam of light is **collimated**.  

![Pinhole camera geometry. The rays from a distant objects arrive in parallel (collaimated) at the pinhole. If rays travel in straight lines, they would continue to form an image the size of the pinhole (short dashed black lines). Hence, the size of the point image would be the same for on-axis (A) and off-axis (B) points. However, you can see that although I drew the same pattern of rays for the two points, we expect fewer rays from the off-axis point (B) to pass through the aperture. Its image will be dimmer. ](images/optics/06-geometric/pinholePSF.png){#fig-pinhole-distant fig-align="center" width="60%"}

For an object point, **A** that is aligned with the pinhole (on-axis), the ray model of light predicts that the rays will continue straight through the pinhole aperture and form an image that is very close to the same size as the pinhole itself. Consider a distant off-axis point, **B**. Its rays, too, will start in many directions and only a narrow, collimated subset of rays will arrive at the pinhole aperture. Because of the angle between the collimated rays and the pinhole, a smaller fraction of the rays will pass through the pinhole aperture. There will be less light from **B** than from **A**. The relative amount of light that makes it through the pinhole depends on the cosine of the angle between the pinhole and the rays. But the shape of the image from the two points does not differ. If the pinhole is circular, on- and off-axis points will produce a circular image with the same diameter as the pinhole.

@fig-ayscough by Ayscough illustrates an image formed by a complex scene, with many points. Each point in the scene is blurred and rendered at a unique position. Also, the intensity at each point will be impacted by its relative angle to the pinhole and image surface. If the image intensity through the pinhole is adequate, and we do not mind the blurring, we will have a satisfactory image.

### Pinhole: Computer graphics
Pinhole cameras are often used in computer graphics calculations. They are simple to compute, tracing light from the recording surface (film or sensor) through the pinhole back into object space. In computer graphics it is fairly common to aim to render a nice looking image, rather than a physically accurate image. The pinhole approximation to optics provides a sharp image with large depth of field that is suitable for many applications.

It is also possible to use pinhole computations to illustrate the limitations of this model in real image systems. In @fig-pinhole-chessset I rendered a chess set scene with the pieces, each a few cm tall, positioned about 0.5 meters from the pinhole camera. The four pictures were rendered using different pinhole diameters. The upper left allows only one ray through from each location in the scene. The aperture diameters for the next three pictures are for three different pinhole sizes. The images are brighter as the pinhole size increases. For this example, the image at the two smaller pinhole sizes are tolerable. Depending on your viewing distance from the screen or page, the third pinhole image might be usable. But the largest pinhole, which lets in the most light, loses so much spatial information that the individual pieces blur together in the image (@sec-airy-pattern).

![A simulated scene rendered through a pinhole camera, using only ray tracing. The size of the pinhole diameter increases from the upper left to the lower right. The relative intensity is preserved in the renderings so that the scene becomes brighter as the pinhole diameter increases. Rendered with [@pharrPBRTVersion4] and [@iset3d2022].](images/optics/06-geometric/01-pinhole-chessset.png){#fig-pinhole-chessset width="80%" fig-align="center"}

### Pinholes: real life
The basic idea of the pinhole camera (also called the **camera obscura**) has been known for thousands of years.  Surely, many people noticed the phenomenon in different times and places. We have a record that the Chinese philosopher Mozi (c. 470–391 BC) wrote that an inverted image is formed through a pinhole, and moreover he explained the phenomenon by positing that light travels in straight lines! The Chinese scientist Shen Kuo (1031–1095) described the process explicitly in his book Dream Pool Essays, also noting that the image is inverted because light rays travel in a straight line from the source to the pinhole and then continue straight to form the image.  

The most significant Islamic figure is Ibn al-Haytham (c. 965–1040), also known as Alhazen. His influential work, the Book of Optics, provides a comprehensive analysis of the camera obscura phenomenon. He used the term al-bayt al-muthlim ("the dark room") to describe the pinhole camera, and he conducted experiments to demonstrate that a small hole could project an image of an external scene onto the opposite wall. Al-Haytham correctly reasoned that the pinhole created a clear image because it isolates and channels individual light rays from different points of the object, preventing them from mixing. His work included many other observations that laid the groundwork for modern optics.

::: {.callout-note collapse="false" title="Natural pinholes"}
From time-to-time people report on interesting examples of naturally occurring pinhole cameras.  This video shows how the holes at the top of a curtain produce a series of overlaping images of the street below.


::: {.content-visible when-format="html"}
![Video of a natural set of pinholes at the upper part of the curtain.](images/optics/06-geometric/pinholes-video-rainmaker.mp4){#fig-pinholes-rainmaker width="40%" fig-align="center"}
:::


::: {.content-visible when-format="pdf"}
![Video of a natural set of pinholes at the upper part of the curtain. (https://x.com/Rainmaker1973/status/1830854129155031206){target=_blank}](images/optics/06-geometric/pinholes-video-twitter-still.png){#fig-pinholes-rainmaker width="40%" fig-align="center"}
:::

([See the original source](https://x.com/Rainmaker1973/status/1830854129155031206){target=_blank})

Antonio Torralba and Bill Freeman and @torralba2012-pinhole described examples of naturally occurring pinhole cameras, and how to create a pinhole image computationally even when a window is too big to produce a useful image.  They say you can take record the very blurry image from a large window opening, and then you can put a small occluder into the window (maybe stand sidewise in the middle of the window) and take a second image. Then, subtract the two images. By the Principle of Superposition, the difference image corresponds to the image when the aperture was the same size as the occluder. This method is more complex to implement because it involves acquiring two (linear) images and then subtracting them. And the world might have changed between the time you took the two image. But it's a good trick for spies who are desperate to learn where they are being held hostage.

![A pinhole camera image formed by substracting an image with an occluder (left) from an image without the occluder (middle). If the two captured images are linear measures of the photons, then Principle of Superposition implies we can subtract them and be left with a computed image that we would have obtained with through the occluded region. The result is a (noisy) image that Torralba and Freeman call 'inverse' inphole camera.](images/optics/06-geometric/torralba.png){#fig-torralba width="80%"}
:::

## Diffraction {#sec-lightfields-diffraction}
Useful as the ray model has been, for more than 300 years scientists have known that geometric optics, describing light as rays, is not completely accurate. Consider the simple prediction of the ray model in @fig-ray-wave. The parallel rays from the point source **A** should pass through the pinhole and continue in a straight line. An image cast on a surface behind the pinhole should have the diameter of the pinhole; a person to the side of the pinhole would see it as dark because no rays are heading to his/her eyes. Try the experiment, and you will be able to see the pinhole. So did the Jesuit scientist, Grimaldi, who worked in the time of Newton. He described this experiment and others in a manuscript [@Grimaldi1665-physico], and he called the phenomenon **diffraction**.

![@Grimaldi1665-physico introduced a pencil of light into a dark room through a hole. According to the ray theory of light, the image on the wall should be the same size as the pinhole, and the rays should not be visible to an observer looking from the side. Grimaldi found that under some conditions the image on the image plane was larger than the pinhole itself, inconsistent with the ray theory of light. Newton confirmed the experiment but continued to use the ray theory because it remained useful for many purposes (A History of Physics, Cajori, p. 88-89). In modern times, we accept the wave theory but often use the ray theory because it works well in many circumstances.](images/optics/06-geometric/ray-wave.png){#fig-ray-wave width="80%" fig-align="center"}

## Huygens wave model {#sec-huygens-wave}

The Dutch scientist Christiaan Huygens, also working at the same time as Newton, suggested an alternative to the ray model: he proposed modeling light as waves that expand to fill space. On Huygen's theory, the light emitted from a point expands as a spherical wave in all directions. At each moment in time the expansion, called the wavefront, can be considered as an array of points that each emits a secondary wave. This model leads to many quantitative predictions, including how light will be reflected from a mirror and how the light direction will change as the wave passes from one medium (air) into a second medium (glass) (@fig-huygens-waves).

![Light modeled as a wavefront. (A) A point source is shown emitting a circular (or 3D, spherical) wave. Each point on the expanding wavefront emits a new spherical wave. The leading edge of these waves reinforce one another to form the expanding wavefront. (B) At a large distance from the source, the small part of the wavefront appears to be a plane wave. Again, each point on the plane emits a spherical wavefront. These are aligned and the wavefront remains planar. (C) When the wavefront arrives at a small aperture only a small part of the wave passes through. This is like the original source, revealing the spherical wavefront from that point.](images/optics/06-geometric/huygens-wave.png){#fig-huygens-waves fig-cap-location="bottom" width="80%" fig-align="center"}

A consequence of the wave theory is that as light passes through a pinhole, or near an edge, the spherical waves from each point on the wavefront are revealed. This is because the aperture limits the region of the plane wave that continues on. If there is a small number of points passing through the aperture, each emitting a spherical wave, the result will be closer to spherical but certainly no longer planar. Instead, the sum of the spherical waves from the few points will sum to a new wavefront that spreads in multiple directions. When the pinhole diameter is small, and only a small portion of the plane wave compared to the wavelength of light enters the pinhole, the spherical wavefront becomes quite large and this blurs the image (@fig-huygens-waves). Were there only a single point, a spherical wave would be revealed. 

::: {.callout-note collapse="false" title="Rays and waves and hypotheses"}

<!-- History.  https://chatgpt.com/c/67098b1d-ae24-8002-be3d-d55f2bc87045 -->

Although the ray and wave theories were proposed at about the same time, Newton's 1704 framing of light as rays was widely accepted for roughly a century. Widespread recognition of the accuracy of Huygen's wave theory was delayed until Thomas Young's 1804 demonstration of the interference pattern created by light from two coherent, nearby sources. I find it interesting to learn about the [the history of these ideas.](../resources/optics-diffraction.html).

I have worked in fields where scientists rely mainly on hypothesis testing: they perform experiments to see if a theory is provably wrong. Surely Newton's theory of light as a ray is provably wrong, and it was so proved nearly 400 years ago! And yet, we use rays to describe light routinely. This is because in many cases the ray theory is an excellent approximation, and we use it as a simple way to reason about radiation - approximately.

This is a very pragmatic approach, which is deeply embedded in the mind of many scientists engineers: Use the tool that is accurate enough for the problem at hand. Approach your problem with a toolbox of methods, and choose the one that gets the job done. In this spirit, the phrase 'all models are wrong, some are useful', @box-science-1976 is widely quoted in many engineering disciplines. In these fields hypotheses that are useful are included in the toolbox. It is essential to understand the scope over which the tool can be reasonably relied upon. 

<!-- Gemini link
Some scientific fields rely strongly on hypothesis testing - asking whether a theory can be proven wrong by experiment.  Other fields accept that theories are largely wrong, but they can still be useful as tools to compute approximations and make devices or products.  Can you describe which fields rely more on the hypothesis testing approach and which rely more on theories as useful tools and approximations? 

Gemini puts basic sciences into hypothesis and engineering into tools.
https://g.co/gemini/share/9013b83cc4f6 -->

:::

## Pinhole size or diffraction: which blurs more? {#sec-airy-pattern}
From these simple considerations, we have seen that the image is blurred by two effects: the pinhole size and diffraction. Increasing the pinhole would create a larger spot on the wall, but decreasing the pinhole size reveals the spherical nature of the wavefront and also increases the size of the spot on the wall.  We can compare the size of these two effects numerically.

![The Airy pattern of a pinhole camera.](images/optics/06-geometric/blur-comparison.png){#fig-blur-comparison fig-cap-location="margin" width="80%"}

First, consider what we expect from the ray model. If the pinhole diameter is $D$, a far-away point on the main axis will produce a blurred spot in the image of size $D$. Also, the pinhole-blur predicted by the ray model is the same no matter how far the image plane is from the pinhole.

Second, consider the light pattern we expect for a plane wave passing through a pinhole aperture. This pattern can be calculated using a formula derived by the astronomer, George B. Airy [@airy-1835-diffraction] and is shown in @fig-blur-comparison. The Airy pattern has a central bright spot (the Airy disk), which is surrounded by a series of concentric rings. The size of the pattern depends on the wavelength of the light $\lambda$, the diameter of the pinhole $D$.  Unlike the ray model, for the diffraction case the rays are expanding so that the distance $L$ from the pinhole to the image plane matters. The image is radially symmetric with a bright spot in the center, surrounded by a set of concentric rings of decreasing intensity. The Airy disk contains about 85% of the total energy. The mathematical notation for the Airy pattern is a bit complex, but the diameter of the Airy disk, $d$, has a simple formula

$$
d = 2.44~L~(\lambda / D)
$$ {#eq-airy1}

Suppose we calculate the size of the diffraction diameter when the image plane is 1 m away, so $L=1$, and for a wavelength of light is 550 nm. Suppose the pinhole diameter is $D = 10^{-4} m$. The diameter of the Airy disk, $d$, will be

$$
d = 2.44 \times (1 m) (550 \times 10^{-9} m )/ 1 \times 10^{-4}m) = 0.0134 m
$$ {#eq-airydisk1}

```{=html}
<!-- 
The diffraction spread is larger than the pinhole spread when $d$ exceeds $D$. We do the calculation in the scripts in this [ISETCam script](https://htmlpreview.github.io/?https://github.com/wandell/FISE-git/blob/main/code/fise_diffraction.html).  For $L = 1m$ the pinhole blur is larger than the diffraction blur for a diameter of about $1 mm$.  When $L$ is much closer, say $10 mm$, the pinhole blur exceeds the diffraction blur when the diameter is $100 \mu$.
-->
```

The diffraction spread exceeds the pinhole spread when $d$ exceeds $D$. We do the calculation for different assumptions about the distance to the image plane [ISETCam script](/code/fise_diffraction.html). As an example, we find that when the distance to the image plane is $L = 1m$, the pinhole blur is larger than the diffraction blur for a pinhole diameter of about $1 mm$. When the image plane distance, $L$, is closer, say $10 mm$, the pinhole blur exceeds the diffraction blur when the diameter is $100 \mu$.

::: {.callout-note collapse="false" title="The diameter of the diffraction point spread"}

In a paper entitled "On the Diffraction of an Object-glass with Circular Aperture", George Airy provided the mathematical description of the diffraction pattern [@airy-1835-diffraction]. A modern derivation of the full point spread function for both the circular aperture and other shapes is in @goodman2022 (pages 88-94). The computation is implemented and frequently used in ISETCam. It is explained [in this tutorial](https://htmlpreview.github.io/?https://github.com/ISET/isetcam/blob/main/tutorials/optics/t_opticsAiryDisk.html).

In the main text, we expressed the formula for a particular distance from the pinhole to an image plane. For a pinhole, the formula is usually given in terms of the angle of the bundle of rays emerging from the pinhole.

$$sin(\theta) = 1.22 \lambda / D$$

When the angle is small, $\theta < 10 \deg$, the formula is very accurately approximated as

$$
\theta = 1.22 \lambda / D
$$

The size of the spot on the image plane depends on the distance how far away the pinhole is from the pinhole, as you can see in [@eq-airy2]. In @sec-optics-thinlens we provide a formula for the Airy disk size for ideal lenses.
:::

## Point spread functions {#sec-pointspread}
Throughout this section, we have discussed how a single point of light is imaged by an optical system. The resulting image is called the **point spread function (PSF)**, and it is a fundamental measure of optical performance. The Airy pattern, for example, is the PSF produced by a circular aperture due to diffraction. We will encounter other types of PSFs when we analyze optical systems using linear systems theory (@sec-optics-linear-space).

It is important to note that most optical systems, including lenses, do not have a single, fixed PSF. The PSF can vary depending on the distance to the point source and its position in the field of view. For systems with circular symmetry, the position is often described by the **field height**, which is the angle between the optical axis and the point's location.

Even in pinhole imaging, the PSF is not unique. There are two main diffraction regimes to consider. When the point source is far from the pinhole, the incoming wavefront is essentially planar, and the resulting diffraction pattern is described by **Fraunhofer diffraction** (or [far-field diffraction](https://en.wikipedia.org/wiki/Fraunhofer_diffraction)). In this case, the Airy pattern accurately describes the PSF.

When the point source is close to the pinhole, the wavefront is curved (spherical), and the diffraction pattern changes. This situation is described by **Fresnel diffraction** (or [near-field diffraction](https://en.wikipedia.org/wiki/Fresnel_diffraction)). Here, the PSF depends on the distance from the source to the aperture.

We will explore the role of the PSF in lens simulation, characterization, and computational imaging methods in  @sec-optics-linear-space and the following chapters.

## Pinhole shapes and PSFs
To this point we have only considered circular pinholes. These are important because the human pupil is close to circular, and we often have camera systems with approximately circular apertures. With a circular aperture and **circularly symmetric** lenses, we can rotate the camera (or our head) and the image will not change much.  The point spread function will also be circularly symmetric and thus we can describe its shape using only the radial distance from the PSF center.

There are cases in nature -and industry- of non-circular apertures, and these point spread functions must be described as two-dimensional images. In the next two sections I show examples and provide an ISETCam script that calculates the diffraction-limited PSF for some examples.

Biological optics -inluding the optics of most people- are often imperfect and deviate from circular symmety. I use ISETCam to plot typical, on-axis PSFs measured made by opthalmologists (@thibos2002-statisticalvariationaberration). 

### Rectangular pinholes 
Towards the end of the optics section, I will describe how to use wavefront methods to calculate different apertures and lens aberrations.  The code in the script [fise_oiAperture](../code/02Optics/fise_oiAperturemlx.html) calculates the PSF for a rectangular aperture (3 times as high as wide).  When diffraction is the only limitation, being high makes the image sharper, so in this case, the horizontal patterns are higher contrast the than vertical patterns.

![Images and PSF from a rectangular, diffraction limited, aperture.](images/optics/06-geometric/pinhole-shape-rectangle.png){#fig-pinhole-rectangle width="60%""}

### Regular polygons
<!--
This is a mechanical shutter.  This is a leaf
https://www.photoreview.com.au/tips/shooting/mechanical-vs-electronic-shutters/

% This is a polygon
https://stackoverflow.com/questions/56467558/trying-to-create-a-camera-shutter-effect-with-divs
-->
![Images and PSF from a rectangular, diffraction limited, aperture.](images/optics/06-geometric/polygon-shutter.png){#fig-pinhole-polygon width="60%""}

Rectangular pinhole

![Images and PSF from a rectangular, diffraction limited, aperture.](images/optics/06-geometric/pinhole-shape-rectangle.png){#fig-pinhole-polygon width="60%""}

HDR images

![Images and PSF from a rectangular, diffraction limited, aperture.](images/optics/06-geometric/pinhole-shape-hdr.png){#fig-pinhole-polygon width="60%""}


### Human PSF

Human eyes have approximately circular pupils.  When the pupils are closed down, the PSF is roughly circularly symmetric.  But when the pupil widens, and the imperfections of the human optics (cornea, lens) have a large impact, the PSF is no longer circularly symmetric.  @thibos2020-arvs @thibos2002-statisticalvariationaberration

When the human eye has non-circular PSF, we say the person is **astigmatic**.  We create glasses or contact lenses to counter this astigmatism. Isn't there some notion that the astigmatism can be well-modeled as two types (horizontal and vertical)?  Is that true, or just old fashioned stuff.

::: {.callout-note collapse=false title="Animal pupil shapes."}
I like these images from the web - there are many of the cat's eye - and from Marty Banks' article of different animal eyes.  @banks2015-animaleyes
![Animal pupils.  Left is cat from reddit.  Right are examples from Banks Science article.](images/optics/06-geometric/catpupil.png){#fig-cat-pupil width=60%}
:::

Your own PSF.  Try taking off your glasses or contact lenses and look at a small bright light in the dark. Maybe a night light from across the room, or one of the LED lights on electronic gear.  The image you see is the PSF of your own visual system, and if you are looking in the dark, your pupil is probably wide open. By squinting, you reduce the size of your eye's aperture which probably sharpens the image by reducing how much of the lens is contributing to the image formation, getting closer to diffraction.

Example of a human PSF, from ISETBio.

![Illustration of astigmatism.  s_wvfAstigmatism.  Top row of the plot.](images/optics/06-geometric/astigmatism-defocus.png){#fig-astigmatism width=100%}

This is astigmatism caused by the optics and wavefront aberration


