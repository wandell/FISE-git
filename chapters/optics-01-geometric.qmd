# Geometric optics {#sec-geometric-optics}

## Geometric optics overview 
Modeling light as rays is a useful approximation for many calculations. This method of enables us to use simple geometric calculations, such as the extensive use of similar triangles, to derive many properties of simple lenses. For this reason this approach is also called **geometric optics**. In this chapter we describe the simplest image forming optics, a **pinhole**. After understanding the logic of modeling using rays and pinholes, I explain the limitations of the ray model and why we will also model light as waves. Finally, I discuss the key concept of the **point spread function**, which plays a role in all the different modeling approaches. We will extend the geometric optics calculations in the next few chapters, before we turn to linear systems theory and wavefronts (Fourier optics).

## Pinhole optics
If we model light as a collection of rays, it is easy to understand why imaging through a pinhole produces an image (@fig-pinhole-image). The figure shows a set of *objects* on the left.  The camera is a dark chamber with only a pinhole opening. The *image* is formed on the planar surface, at the right.  The light rays travel in a straight line, so only a small subset of the rays from each object passing through the pinhole.  We can trace the light path by starting at a point on the image and drawing a straight line into the object space. The geometry illustrates how the rays from adjacent objects arrive at adjacent positions in the image plane, forming a reversed and inverted image.

![A pinhole makes an image.](images/optics/06-geometric/pinhole-image.png){#fig-pinhole-image width=60%}

If the pinhole is small, each image point receives rays from a small region in object space (@fig-pinhole-blur). As we increase the pinhole diameter, each image point receives rays from larger regions on the objects. If multiple objects contribute rays to an image point, the image will be blurry. Conversely, according to the ray model, reducing the pinhole size should sharpen the image.

![Why enlarging the pinhole increases the blur.](images/optics/06-geometric/pinhole-blur.png){#fig-pinhole-blur width=60%}

### Parallel (collimated) rays
The rays from a point on an object often radiate in a wide range of directions. A special case -that is important in many practical applications- are the rays from distant points (@fig-pinhole-distant). When the point is far, only a small angular bundle of rays arrives at the pinhole. When the angle is very small, the rays are nearly parallel. In that case we say the beam of light is **collimated**.  

![Pinhole camera geometry. The rays from a distant objects arrive in parallel (collaimated) at the pinhole. If rays travel in straight lines, they would continue to form an image the size of the pinhole (short dashed black lines). Hence, the size of the point image would be the same for on-axis (A) and off-axis (B) points. However, you can see that although I drew the same pattern of rays for the two points, we expect fewer rays from the off-axis point (B) to pass through the aperture. Its image will be dimmer. ](images/optics/06-geometric/pinholePSF.png){#fig-pinhole-distant fig-align="center" width="60%"}

For an object point, **A** that is aligned with the pinhole (on-axis), the ray model of light predicts that the rays will continue straight through the pinhole aperture and form an image that is very close to the same size as the pinhole itself. Consider a distant off-axis point, **B**. Its rays, too, will start in many directions and only a narrow, collimated subset of rays will arrive at the pinhole aperture. Because of the angle between the collimated rays and the pinhole, a smaller fraction of the rays will pass through the pinhole aperture. There will be less light from **B** than from **A**. The relative amount of light that makes it through the pinhole depends on the cosine of the angle between the pinhole and the rays. But the shape of the image from the two points does not differ. If the pinhole is circular, on- and off-axis points will produce a circular image with the same diameter as the pinhole.

@fig-ayscough by Ayscough illustrates an image formed by a complex scene, with many points. Each point in the scene is blurred and rendered at a unique position. Also, the intensity at each point will be impacted by its relative angle to the pinhole and image surface. If the image intensity through the pinhole is adequate, and we do not mind the blurring, we will have a satisfactory image.

### Pinhole: Computer graphics
Pinhole cameras are often used in computer graphics calculations. They are simple to compute, tracing light from the recording surface (film or sensor) through the pinhole back into object space. In computer graphics it is fairly common to aim to render a nice looking image, rather than a physically accurate image. The pinhole approximation to optics provides a sharp image with large depth of field that is suitable for many applications.

It is also possible to use pinhole computations to illustrate the limitations of this model in real image systems. In @fig-pinhole-chessset I rendered a chess set scene with the pieces, each a few cm tall, positioned about 0.5 meters from the pinhole camera. The four pictures were rendered using different pinhole diameters. The upper left allows only one ray through from each location in the scene. The aperture diameters for the next three pictures are for three different pinhole sizes. The images are brighter as the pinhole size increases. For this example, the image at the two smaller pinhole sizes are tolerable. Depending on your viewing distance from the screen or page, the third pinhole image might be usable. But the largest pinhole, which lets in the most light, loses so much spatial information that the individual pieces blur together in the image (@sec-airy-pattern).

![A simulated scene rendered through a pinhole camera, using only ray tracing. The size of the pinhole diameter increases from the upper left to the lower right. The relative intensity is preserved in the renderings so that the scene becomes brighter as the pinhole diameter increases. Rendered with [@pharrPBRTVersion4] and [@iset3d2022].](images/optics/06-geometric/01-pinhole-chessset.png){#fig-pinhole-chessset width="80%" fig-align="center"}

### Pinholes: real life
The basic idea of the pinhole camera (also called the **camera obscura**) has been known for thousands of years.  Surely, many people noticed the phenomenon in different times and places. We have a record that the Chinese philosopher Mozi (c. 470–391 BC) wrote that an inverted image is formed through a pinhole, and moreover he explained the phenomenon by positing that light travels in straight lines! The Chinese scientist Shen Kuo (1031–1095) described the process explicitly in his book Dream Pool Essays, also noting that the image is inverted because light rays travel in a straight line from the source to the pinhole and then continue straight to form the image.  

The most significant Islamic figure is Ibn al-Haytham (c. 965–1040), also known as Alhazen. His influential work, the Book of Optics, provides a comprehensive analysis of the camera obscura phenomenon. He used the term al-bayt al-muthlim ("the dark room") to describe the pinhole camera, and he conducted experiments to demonstrate that a small hole could project an image of an external scene onto the opposite wall. Al-Haytham correctly reasoned that the pinhole created a clear image because it isolates and channels individual light rays from different points of the object, preventing them from mixing. His work included many other observations that laid the groundwork for modern optics.

::: {.callout-note collapse="false" title="Natural pinholes"}
From time-to-time people report on interesting examples of naturally occurring pinhole cameras.  This video shows how the holes at the top of a curtain produce a series of overlaping images of the street below.


::: {.content-visible when-format="html"}
![Video of a natural set of pinholes at the upper part of the curtain.](images/optics/06-geometric/pinholes-video-rainmaker.mp4){#fig-pinholes-rainmaker width="40%" fig-align="center"}
:::


::: {.content-visible when-format="pdf"}
![Video of a natural set of pinholes at the upper part of the curtain. (https://x.com/Rainmaker1973/status/1830854129155031206){target=_blank}](images/optics/06-geometric/pinholes-video-twitter-still.png){#fig-pinholes-rainmaker width="40%" fig-align="center"}
:::

([See the original source](https://x.com/Rainmaker1973/status/1830854129155031206){target=_blank})

Antonio Torralba and Bill Freeman and @torralba2012-pinhole described examples of naturally occurring pinhole cameras, and how to create a pinhole image computationally even when a window is too big to produce a useful image.  They say you can take record the very blurry image from a large window opening, and then you can put a small occluder into the window (maybe stand sidewise in the middle of the window) and take a second image. Then, subtract the two images. By the Principle of Superposition, the difference image corresponds to the image when the aperture was the same size as the occluder. This method is more complex to implement because it involves acquiring two (linear) images and then subtracting them. And the world might have changed between the time you took the two image. But it's a good trick for spies who are desperate to learn where they are being held hostage.

![A pinhole camera image formed by substracting an image with an occluder (left) from an image without the occluder (middle). If the two captured images are linear measures of the photons, then Principle of Superposition implies we can subtract them and be left with a computed image that we would have obtained with through the occluded region. The result is a (noisy) image that Torralba and Freeman call 'inverse' inphole camera.](images/optics/06-geometric/torralba.png){#fig-torralba width="80%"}
:::

## Diffraction {#sec-lightfields-diffraction}
Useful as the ray model has been, for more than 300 years scientists have known that geometric optics, describing light as rays, is not completely accurate. Consider the simple prediction of the ray model in @fig-ray-wave. The parallel rays from the point source **A** should pass through the pinhole and continue in a straight line. An image cast on a surface behind the pinhole should have the diameter of the pinhole; a person to the side of the pinhole would see it as dark because no rays are heading to his/her eyes. Try the experiment, and you will be able to see the pinhole. So did the Jesuit scientist, Grimaldi, who worked in the time of Newton. He described this experiment and others in a manuscript [@Grimaldi1665-physico], and he called the phenomenon **diffraction**.

![@Grimaldi1665-physico introduced a pencil of light into a dark room through a hole. According to the ray theory of light, the image on the wall should be the same size as the pinhole, and the rays should not be visible to an observer looking from the side. Grimaldi found that under some conditions the image on the image plane was larger than the pinhole itself, inconsistent with the ray theory of light. Newton confirmed the experiment but continued to use the ray theory because it remained useful for many purposes (A History of Physics, Cajori, p. 88-89). In modern times, we accept the wave theory but often use the ray theory because it works well in many circumstances.](images/optics/06-geometric/ray-wave.png){#fig-ray-wave width="80%" fig-align="center"}

## Huygens wave model {#sec-huygens-wave}

The Dutch scientist Christiaan Huygens, also working at the same time as Newton, suggested an alternative to the ray model: he proposed modeling light as waves that expand to fill space. On Huygen's theory, the light emitted from a point expands as a spherical wave in all directions. At each moment in time the expansion, called the wavefront, can be considered as an array of points that each emits a secondary wave. This model leads to many quantitative predictions, including how light will be reflected from a mirror and how the light direction will change as the wave passes from one medium (air) into a second medium (glass) (@fig-huygens-waves).

![Light modeled as a wavefront. (A) A point source is shown emitting a circular (or 3D, spherical) wave. Each point on the expanding wavefront emits a new spherical wave. The leading edge of these waves reinforce one another to form the expanding wavefront. (B) At a large distance from the source, the small part of the wavefront appears to be a plane wave. Again, each point on the plane emits a spherical wavefront. These are aligned and the wavefront remains planar. (C) When the wavefront arrives at a small aperture only a small part of the wave passes through. This is like the original source, revealing the spherical wavefront from that point.](images/optics/06-geometric/huygens-wave.png){#fig-huygens-waves fig-cap-location="bottom" width="80%" fig-align="center"}

A consequence of the wave theory is that as light passes through a pinhole, or near an edge, the spherical waves from each point on the wavefront are revealed. This is because the aperture limits the region of the plane wave that continues on. If there is a small number of points passing through the aperture, each emitting a spherical wave, the result will be closer to spherical but certainly no longer planar. Instead, the sum of the spherical waves from the few points will sum to a new wavefront that spreads in multiple directions. When the pinhole diameter is small, and only a small portion of the plane wave compared to the wavelength of light enters the pinhole, the spherical wavefront becomes quite large and this blurs the image (@fig-huygens-waves). Were there only a single point, a spherical wave would be revealed. 

::: {.callout-note collapse="false" title="Rays and waves and hypotheses"}

<!-- History.  https://chatgpt.com/c/67098b1d-ae24-8002-be3d-d55f2bc87045 -->

Although the ray and wave theories were proposed at about the same time, Newton's 1704 framing of light as rays was widely accepted for roughly a century. Widespread recognition of the accuracy of Huygen's wave theory was delayed until Thomas Young's 1804 demonstration of the interference pattern created by light from two coherent, nearby sources. I find it interesting to learn about the [the history of these ideas.](../resources/optics-diffraction.html).

I have worked in fields where scientists rely mainly on hypothesis testing: they perform experiments to see if a theory is provably wrong. Surely Newton's theory of light as a ray is provably wrong, and it was so proved nearly 400 years ago! And yet, we use rays to describe light routinely. This is because in many cases the ray theory is an excellent approximation, and we use it as a simple way to reason about radiation - approximately.

This is a very pragmatic approach, which is deeply embedded in the mind of many scientists engineers: Use the tool that is accurate enough for the problem at hand. Approach your problem with a toolbox of methods, and choose the one that gets the job done. In this spirit, the phrase 'all models are wrong, some are useful', @box-science-1976 is widely quoted in many engineering disciplines. In these fields hypotheses that are useful are included in the toolbox. It is essential to understand the scope over which the tool can be reasonably relied upon. 

<!-- Gemini link
Some scientific fields rely strongly on hypothesis testing - asking whether a theory can be proven wrong by experiment.  Other fields accept that theories are largely wrong, but they can still be useful as tools to compute approximations and make devices or products.  Can you describe which fields rely more on the hypothesis testing approach and which rely more on theories as useful tools and approximations? 

Gemini puts basic sciences into hypothesis and engineering into tools.
https://g.co/gemini/share/9013b83cc4f6 -->

:::

## Double slit experiments

<!--
https://physicsworld.com/a/famous-double-slit-experiment-gets-its-cleanest-test-yet/?utm_source=Live+Audience&utm_campaign=01bdf7753f-nature-briefing-daily-20250827&utm_medium=email&utm_term=0_b27a691814-01bdf7753f-49658492
Experiment schematic: Two single atoms floating in a vacuum chamber are illuminated by a laser beam and act as the two slits. The interference of the scattered light is recorded with a highly sensitive camera depicted as a screen. Incoherent light appears as background and implies that the photon has acted as a particle passing only through one slit. (Courtesy: Wolfgang Ketterle, Vitaly Fedoseev, Hanzhen Lin, Yu-Kun Lu, Yoo Kyung Lee and Jiahao Lyu)
Image is in:  double-slit-atoms.png

A bit about the history.
https://chatgpt.com/s/t_68af573578f08191a975ae4de6749069
-->

The development of the wave theory of light spanned more than a century.  Grimaldi’s observations were very important, and he coined the term diffraction. He documented how light spreads out after passing the edge of an obstacle or through a narrow slit, easily reproducible and imortant phenomena. But perhaps because he did not provide a theory. Huygens (1690) did put forward a genuine wave theory of light. His principle of secondary wavelets elegantly explained reflection and refraction, and even hinted at diffraction. It is surprising to me that Newton felt he could promote a ray theory of light despite these prior observations and theory. Perhaps because Newton was remarkable in many other ways, his voice dominated the scientific scene.

Huygens theory did account for many important phenomena; to me, the simple observation in @fig-ray-wave is decisive. But one phenomenon Huygens did not describe was interference — the phenomenon where waves from two sources combine to produce bright and dark fringes. Apparently, some scientists thought the wave theory was incomplete, and Newton’s particle theory retained the upper hand throughout the 18th century.

Thomas Young presented his famous double-slit experiments to the Royal Society in 1801–1803. The ability to see the interference fringes provided quantitative, unmistakable proof of the value of the wave theory. Only waves, not particles, could add and cancel in this way and made the phenomenon hard to ignore.  

![Thomas Young's double slit experiment](images/optics/06-geometric/double-slit.png){#fig-double-slit width="80%"}

It is worth remembering that even after his presentations to the Royal Society, the wave theory met resistance.  The loudest was from Henry Brougham who made personal attacks on Young[^Brougham]. But serious thinkers also wondered whether a wave theory could be right.  What was the medium that supported the waves?  The so-called 'ether' had not been measured.  And if the waves were propagating through a medium, wouldn't inhomogeneities cause them to deviate from straight lines?  

[^Brougham]: Henry Brougham was a particularly fierce critique of Young's entire research program, and an ardent defender of Newton's work. His strongest attacks were against Young's important -and accurate!- observations about human color vision.  More on that in @sec-human.

A particularly important event that turned the tide occurred a decade later, when Augustin-Jean Fresnel supplied the mathematics of diffraction and interference. This was a famous event in the history of physics. In 1818, Fresnel submitted his wave theory to a competition sponsored by the French Academy of Sciences. One of the judges, Siméon-Denis Poisson, was a staunch supporter of Newton's particle theory and sought to disprove Fresnel's work. Using Fresnel's own equations, Poisson calculated that if a circular obstacle were illuminated by a point source of light, a bright spot should appear in the very center of the shadow. Poisson presented this as a *reductio ad absurdum*—an absurd conclusion that surely proved the wave theory was wrong.

However, the head of the committee, François Arago, decided to perform the experiment. To the astonishment of many, Arago observed the bright spot exactly as predicted. This dramatic confirmation of a counter-intuitive prediction was a decisive victory for the wave theory. The spot is now ironically known as **Poisson's spot** (or sometimes Arago's spot). This work ended the dominance of the corpuscular theory for some time. It was to return with Einstein's work, which I explain in @sec-sensors-photons-electrons.


## Pinhole size or diffraction: which blurs more? {#sec-airy-pattern}
From these simple considerations, we have seen that the image is blurred by two effects: the pinhole size and diffraction. Increasing the pinhole would create a larger spot on the wall, but decreasing the pinhole size reveals the spherical nature of the wavefront and also increases the size of the spot on the wall.  We can compare the size of these two effects numerically.

![The Airy pattern of a pinhole camera.](images/optics/06-geometric/blur-comparison.png){#fig-blur-comparison fig-cap-location="margin" width="80%"}

First, consider what we expect from the ray model. If the pinhole diameter is $D$, a far-away point on the main axis will produce a blurred spot in the image of size $D$. Also, the pinhole-blur predicted by the ray model is the same no matter how far the image plane is from the pinhole.

Second, consider the light pattern we expect for a plane wave passing through a pinhole aperture. This pattern can be calculated using a formula derived by the astronomer, George B. Airy [@airy-1835-diffraction] and is shown in @fig-blur-comparison. The Airy pattern has a central bright spot (the Airy disk), which is surrounded by a series of concentric rings. The size of the pattern depends on the wavelength of the light $\lambda$, the diameter of the pinhole $D$.  Unlike the ray model, for the diffraction case the rays are expanding so that the distance $L$ from the pinhole to the image plane matters. The image is radially symmetric with a bright spot in the center, surrounded by a set of concentric rings of decreasing intensity. The Airy disk contains about 85% of the total energy. The mathematical notation for the Airy pattern is a bit complex, but the diameter of the Airy disk, $d$, has a simple formula

$$
d = 2.44~L~(\lambda / D)
$$ {#eq-airy1}

Suppose we calculate the size of the diffraction diameter when the image plane is 1 m away, so $L=1$, and for a wavelength of light is 550 nm. Suppose the pinhole diameter is $D = 10^{-4} m$. The diameter of the Airy disk, $d$, will be

$$
d = 2.44 \times (1 m) (550 \times 10^{-9} m )/ 1 \times 10^{-4}m) = 0.0134 m
$$ {#eq-airydisk1}

```{=html}
<!-- 
The diffraction spread is larger than the pinhole spread when $d$ exceeds $D$. We do the calculation in the scripts in this [ISETCam script](https://htmlpreview.github.io/?https://github.com/wandell/FISE-git/blob/main/code/fise_diffraction.html).  For $L = 1m$ the pinhole blur is larger than the diffraction blur for a diameter of about $1 mm$.  When $L$ is much closer, say $10 mm$, the pinhole blur exceeds the diffraction blur when the diameter is $100 \mu$.
-->
```

The diffraction spread exceeds the pinhole spread when $d$ exceeds $D$. We do the calculation for different assumptions about the distance to the image plane [ISETCam script](/code/fise_diffraction.html). As an example, we find that when the distance to the image plane is $L = 1m$, the pinhole blur is larger than the diffraction blur for a pinhole diameter of about $1 mm$. When the image plane distance, $L$, is closer, say $10 mm$, the pinhole blur exceeds the diffraction blur when the diameter is $100 \mu$.

::: {.callout-note collapse="false" title="The diameter of the diffraction point spread"}

In a paper entitled "On the Diffraction of an Object-glass with Circular Aperture", George Airy provided the mathematical description of the diffraction pattern [@airy-1835-diffraction]. A modern derivation of the full point spread function for both the circular aperture and other shapes is in @goodman2022 (pages 88-94). The computation is implemented and frequently used in ISETCam. It is explained [in this tutorial](https://htmlpreview.github.io/?https://github.com/ISET/isetcam/blob/main/tutorials/optics/t_opticsAiryDisk.html).

In the main text, we expressed the formula for a particular distance from the pinhole to an image plane. For a pinhole, the formula is usually given in terms of the angle of the bundle of rays emerging from the pinhole.

$$sin(\theta) = 1.22 \lambda / D$$

When the angle is small, $\theta < 10 \deg$, the formula is very accurately approximated as

$$
\theta = 1.22 \lambda / D
$$

The size of the spot on the image plane depends on the distance how far away the pinhole is from the pinhole, as you can see in [@eq-airy2]. In @sec-optics-thinlens we provide a formula for the Airy disk size for ideal lenses.
:::

## Point spread functions {#sec-pointspread}
Throughout this section, we have discussed how a single point of light is imaged by an optical system. The resulting image is called the **point spread function (PSF)**, and it is a fundamental measure of optical performance. The Airy pattern, for example, is the PSF produced by a circular aperture due to diffraction. We will encounter other types of PSFs when we analyze optical systems using linear systems theory (@sec-optics-linear-space).

It is important to note that most optical systems, including lenses, do not have a single, fixed PSF. The PSF can vary depending on the distance to the point source and its position in the field of view. For systems with circular symmetry, the position is often described by the **field height**, which is the angle between the optical axis and the point's location.

Even in pinhole imaging, the PSF is not unique. There are two main diffraction regimes to consider. When the point source is far from the pinhole, the incoming wavefront is essentially planar, and the resulting diffraction pattern is described by **Fraunhofer diffraction** (or [far-field diffraction](https://en.wikipedia.org/wiki/Fraunhofer_diffraction)). In this case, the Airy pattern accurately describes the PSF.

When the point source is close to the pinhole, the wavefront is curved (spherical), and the diffraction pattern changes. This situation is described by **Fresnel diffraction** (or [near-field diffraction](https://en.wikipedia.org/wiki/Fresnel_diffraction)). Here, the PSF depends on the distance from the source to the aperture.

We will explore the role of the PSF in lens simulation, characterization, and computational imaging methods in  @sec-optics-linear-space and the following chapters.

## Pinhole shapes and PSFs
To this point we have only considered circular pinholes. These are important because many apertures, including the human pupil, are close to circular. Also, many camera systems use approximately circular apertures. The nice feature of circular apertures is that rotating the camera (or our head) leaves the optical impact of the aperture unchanged. When the point spread function is circularly symmetric, as for the Airy pattern, we can describe it using only the radial distance from the PSF center.

There are cases in nature -and industry- of non-circular apertures, and these point spread functions must be described as two-dimensional images. In the following sections I introduce an ISETCam script that calculates the diffraction-limited PSF for some non-circular diffraction-limited apertures. 

### Rectangular pinholes 
The script [fise_oiAperture](../code/02Optics/fise_oiAperturemlx.html){target=_blank} illustrates how to calculate the PSF for a rectangular aperture in ISETCam. An image computed using the PSF from a diffraction limited rectangular pinhole, and the PSF for that pinhole, are shown in @fig-pinhole-rectangle. The images illustrate a case for the rectangular aperture is three times wider (x) than high (y). The larger vertical height causes less blur in the y-direction, making the image sharper for the horizontal stripes.

![Simulating a diffraction-limited rectangular pinhole that is 3x higher than wide. The test pattern has spatial frequency increasing from left to right, and orientation varying up to down. The horizontal lines retain their contrast as frequency increases; the vertical lines lose theirs. The PSF (550 nm) for the rectangular aperture is plotted on the right. See [fise_oiAperture](../code/02Optics/fise_oiAperturemlx.html).](images/optics/06-geometric/pinhole-rectangle-both.png){#fig-pinhole-rectangle width="80%"}

There is a formula for the rectangular diffraction-limited PSF, given in terms of distance on the sensor surface.

$$
\text{PSF}(x',y') \;\propto\;
\left[\operatorname{sinc}\!\left(\frac{\pi a}{\lambda f}\,x'\right)\right]^2
\;\left[\operatorname{sinc}\!\left(\frac{\pi b}{\lambda f}\,y'\right)\right]^2,
$$

where $a$ and $b$ are the aperture widths in the $x$ and $y$ directions, $f$ is the focal length, and $\lambda$ is the wavelength.  We define $\operatorname{sinc}(u) = \tfrac{\sin(u)}{u}$.

In the script, you will see that I didn't use the formula directly.  Rather, I simply defined the shape of the aperture and ran a calculation. In @sec-optics-wavefront I will explain that calculation.  Being able to numerically compute with the wavefront means we can find the PSF for many different shapes.

::: {.callout-note collapse=false title="Animal pupil shapes."}
Approximately rectangular pupils are fairly common in biology, as well, and the pupil shape is associated with how they live their lives (@banks2015-animaleyes). Vertically elongated pupils are associated with ambush predators that are active both day and night. So beware! Horizontally elongated pupils are more likely to be found in prey, who also have laterally placed eyes that helps them look all around. 

![The cat has a vertical pupil - appropriate for a killing machine.  There are many, many images of the cat pupil on the web. The cat is capable of closing its pupil nearly completely. The images on the right are examples provided by @banks2015-animaleyes.](images/optics/06-geometric/catpupil.png){#fig-cat-pupil width=60%}
:::

### Regular polygons
Classic cameras with mechanical shutters often had regular polygon shapes (left) or the interesting 'leaf' pattern at the right. These apertures introduce structure into the PSF that differs from a circularly symmetric aperture. 

![A sampling of mechanical shutter shapes.  The array on the left are different regular polygons.  The one on the right is called a 'leaf' shutter.  I have wanted to simulate its PSF, but I haven't gotten around to it.  Let me know if you try.  You might start with the script described above, and introduce the aperture shape from an image. Or start with the image and define a mathematical function for the shape.  You can see why I never did it.  I just can't choose.](images/optics/06-geometric/mechanical-shutters.png){#fig-pinhole-polygon width="60%"}

<!--
This is a mechanical shutter.  This is a leaf https://www.photoreview.com.au/tips/shooting/mechanical-vs-electronic-shutters/
This is a polygon https://stackoverflow.com/questions/56467558/trying-to-create-a-camera-shutter-effect-with-divs
-->

The impact of the regular polygon shape is quite visible in high dynamic range (HDR) scenes that include light sources.  The script [fise_oiAperture](../code/02Optics/fise_oiAperturemlx.html){target=_blank} simulates an HDR scene, superimposing some very bright light sources on the background image.  These apertures produce the flare pattern that one often sees in professional productions, including movies and sports shows. The three images show the flare pattern for polygons with different numbers of sides.

![High dynamic range images simulated through a lens with a regular polygon aperture.](images/optics/06-geometric/pinhole-shape-hdr.png){#fig-pinhole-hdr width="90%"}

 For the simulation in @fig-pinhole-hdr, I also added some scratches and dust on to the lens for realism. The brightest light in each scene (left) is five orders of magnitude ($10^5$) more intense than the dimmest light (right), which is barely visible.  The lights are all the same size, but the bright ones appear larger because of the blurring by the PSF.

### Human PSF

Human eyes have approximately circular pupils. In bright light the pupil is contracted to about 3 mm diameter, and the PSF can be roughly circularly symmetric. In darker environments, the pupil widens and imperfections of the human optics (cornea, lens) often have a very large and irregular impact on the PSF. The pupil aperture is circular, but the optical imperfections distort the PSF and it takes on a very irregular shape (@thibos2020-arvs @thibos2002-statisticalvariationaberration).

<!-- Isn't there some notion that the astigmatism can be well-modeled as two types (horizontal and vertical)?  Is that true, or just old fashioned stuff.-->
Even though the PSF is quite irregular, we often approximate its shape. One approximation summarizes whether or not the PSF is very different in two directions. If it is very different in two perpendicular directions, we say the person is **astigmatic**. @fig-astigmatism shows PSFs with some defocus and astigmatism.  These were simulated using the same wavefront methods I described above and that will be covered in @sec-optics-wavefront.

![Illustration of astigmatism.  s_wvfAstigmatism.  Top row of the plot.](images/optics/06-geometric/astigmatism-defocus.png){#fig-astigmatism width=100%}

 I will show simulations of a range of human PSFs in @sec-human.  You can assess your own PSF easily.  Glasses or contact lenses are typically designed to sharpen the PSF and counter any astigmatism. To see the PSF of your lens, take off your glasses or contact lenses, and look with one eye at a small spot of light in the dark -maybe a night light from across the room, or one of the LED lights on electronic gear- against in the presence of a uniform background such as a wall. The image you see is the PSF of your own visual system. If you are looking in a dark room, your pupil is probably relatively large. By squinting, you reduce the size of your eye's aperture, and this is likely to sharpen the PSF.  The squinting reduces how much the lens contributes to image formation.  If the aperture is made quite small, say by using an artifical pupile, the image will be diffraction limited.
