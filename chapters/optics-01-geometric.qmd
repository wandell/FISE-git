# Geometric optics {#sec-geometric-optics}

## Geometric optics overview 

Optical modeling of light as rays, also called **geometric optics**, is a useful and widely used approximation for many calculations.  For example, suppose we imagine light as a collection of rays: then, it is easy to understand Leonardo's explanation of why imaging through a pinhole produces an image  (@fig-pinhole-basic). The rays from a distant point, **A**, radiate in a wide range of directions. But only a small portion of those rays arrive at the pinhole aperture. The incident rays from **A** rays will be parallel to one another. According to the ray model of light, this collection of rays will pass straight through the pinhole aperture and form an image of the point on the recording surface (e.g., Leonardo's wall).

![Pinhole camera geometry. (A) The rays from a distant, on-axis point arrive at in parallel at the pinhole. Were there no diffraction, the rays would continue on to form an image the size of the pinhole. (B) Rays from a distant off-axis point also arrive in parallel, but they are at an angle to the pinhole aperture. Hence, fewer rays pass through the aperture, making the image dimmer and the blur smaller. For some pinhole sizes, this design is workable. But at a certain size, diffraction makes this design unworkable.](images/lightfields/pinholePSF.png){#fig-pinhole-basic fig-align="center" width="50%"}

Consider a distant but off-axis point, **B**. Its rays, too, will start in many directions but only a narrow, collimated subset of rays will arrive at the pinhole aperture. Because of the angle between the collimated rays and the pinhole, a smaller fraction of the rays will pass through the pinhole aperture. The point spread from **B** will be smaller and dimmer. Its location on the image surface will be displaced from **A** by an amount that depends on the positions of the two points in the scene. Thus, the wall records the relative intensity and spectrum from the different points in the scene at different locations on the wall.  Also, why the image is inverted is well-explained by ray-tracing.

@fig-ayscough illustrates an image formed by a great many points. Each point in the scene is blurred and rendered at a unique position. If the image intensity through the pinhole is adequate -we do not mind the blurring- we will have a satisfactory image.

In @fig-pinhole-chessset I rendered a chess set scene with the pieces, each a few cm tall, positioned about 0.5 meters from the pinhole camera. The four pictures were rendered using different pinhole diameters. The upper left allows only one ray through from each location in the scene. The aperture diameters for the next three pictures are for three different pinhole sizes. The images are brighter as the pinhole size increases. For this example, the image at the two smaller pinhole sizes are tolerable. Depending on your viewing distance from the screen or page, the third pinhole image might be usable. But the largest pinhole, which lets in the most light, loses so much spatial information that the individual pieces blur together in the image (@sec-airy-pattern).

![A simulated scene rendered through a pinhole camera, using only ray tracing. The size of the pinhole diameter increases from the upper left to the lower right. The relative intensity is preserved in the renderings so that the scene becomes brighter as the pinhole diameter increases. Rendered with [@pharrPBRTVersion4] and [@iset3d2022].](images/lightfields/01-pinhole-chessset.png){#fig-pinhole-chessset width="80%" fig-align="center"}

## Diffraction {#sec-lightfields-diffraction}

Useful as the ray model has been, for more than 300 years scientists have known that geometric optics, describing light as rays, is not completely accurate. Consider the simple prediction of the ray model in @fig-ray-wave. The parallel rays from the point source **A** should pass through the pinhole and continue in a straight line. An image cast on a surface behind the pinhole should have the diameter of the pinhole; a person to the side of the pinhole would see it as dark because no rays are heading to his/her eyes. Try the experiment, and you will be able to see the pinhole. So did the Jesuit scientist, Grimaldi, who worked in the time of Newton. He described this experiment and others in a manuscript [@Grimaldi1665-physico], and he called the phenomenon **diffraction**.

![@Grimaldi1665-physico introduced a pencil of light into a dark room through a hole. According to the ray theory of light, the image on the wall should be the same size as the pinhole, and the rays should not be visible to an observer looking from the side. Grimaldi found that under some conditions the image on the image plane was larger than the pinhole itself, inconsistent with the ray theory of light. Newton confirmed the experiment but continued to use the ray theory because it remained useful for many purposes (A History of Physics, Cajori, p. 88-89). In modern times, we accept the wave theory but often use the ray theory because it works well in many circumstances.](images/lightfields/01-ray-wave.png){#fig-ray-wave width="80%" fig-align="center"}

## Huygens wave model {#sec-huygens-wave}

The Dutch scientist Christiaan Huygens, also working at the same time as Newton, suggested an alternative to the ray model: he proposed modeling light as waves that expand to fill space. On Huygen's theory, the light emitted from a point expands as a spherical wave in all directions. At each moment in time the expansion, called the wavefront, can be considered as an array of points that each emits a secondary wave. This model leads to many quantitative predictions, including how light will be reflected from a mirror and how the light direction will change as the wave passes from one medium (air) into a second medium (glass) (@fig-huygens-waves).

![Light modeled as a wavefront. (A) A point source is shown emitting a circular (or 3D, spherical) wave. Each point on the expanding wavefront emits a new spherical wave. The leading edge of these waves reinforce one another to form the expanding wavefront. (B) At a large distance from the source, the small part of the wavefront appears to be a plane wave. Again, each point on the plane emits a spherical wavefront. These are aligned and the wavefront remains planar. (C) When the wavefront arrives at a small aperture only a small part of the wave passes through. This is like the original source, revealing the spherical wavefront from that point.](images/lightfields/01-huygens-wave.png){#fig-huygens-waves fig-cap-location="bottom" width="80%" fig-align="center"}

A consequence of the wave theory is that as light passes through a pinhole, or near an edge, the spherical waves from each point on the wavefront are revealed. This is because the aperture limits the region of the plane wave that continues on. If there is a small number of points passing through the aperture, each emitting a spherical wave, the result will be closer to spherical but certainly no longer planar. Instead, the sum of the spherical waves from the few points will sum to a new wavefront that spreads in multiple directions. When the pinhole diameter is small, and only a small portion of the plane wave compared to the wavelength of light enters the pinhole, the spherical wavefront becomes quite large and this blurs the image (@fig-huygens-waves). Were there only a single point, a spherical wave would be revealed. 

::: {.callout-note collapse="false" title="Rays and waves and hypotheses"}

<!-- History.  https://chatgpt.com/c/67098b1d-ae24-8002-be3d-d55f2bc87045 -->

Although the ray and wave theories were proposed at about the same time, Newton's 1704 framing of light as rays was widely accepted for roughly a century. Widespread recognition of the accuracy of Huygen's wave theory was delayed until Thomas Young's 1804 demonstration of the interference pattern created by light from two coherent, nearby sources. I find it interesting to learn about the [the history of these ideas.](../resources/optics-diffraction.html).

I have worked in fields where scientists rely mainly on hypothesis testing: they perform experiments to see if a theory is provably wrong. Surely Newton's theory of light as a ray is provably wrong, and it was so proved nearly 400 years ago! And yet, we use rays to describe light routinely. This is because in many cases the ray theory is an excellent approximation, and we use it as a simple way to reason about radiation - approximately.

This is a very pragmatic approach, which is deeply embedded in the mind of many scientists engineers: Use the tool that is accurate enough for the problem at hand. Approach your problem with a toolbox of methods, and choose the one that gets the job done. In this spirit, the phrase 'all models are wrong, some are useful', @box-science-1976 is widely quoted in many engineering disciplines. In these fields hypotheses that are useful are included in the toolbox. It is essential to understand the scope over which the tool can be reasonably relied upon. <!-- Gemini link

Some scientific fields rely strongly on hypothesis testing - asking whether a theory can be proven wrong by experiment.  Other fields accept that theories are largely wrong, but they can still be useful as tools to compute approximations and make devices or products.  Can you describe which fields rely more on the hypothesis testing approach and which rely more on theories as useful tools and approximations? 

Gemini puts basic sciences into hypothesis and engineering into tools.
https://g.co/gemini/share/9013b83cc4f6 -->
:::

## Pinhole size or diffraction: which blurs more? {#sec-airy-pattern}
From these simple considerations, we have seen that the image is blurred by two effects: the pinhole size and diffraction. Increasing the pinhole would create a larger spot on the wall, but decreasing the pinhole size reveals the spherical nature of the wavefront and also increases the size of the spot on the wall.  We can compare the size of these two effects numerically.

![The Airy pattern of a pinhole camera.](images/lightfields/01-blur-comparison.png){#fig-blur-comparison fig-cap-location="margin" width="80%"}

First, consider what we expect from the ray model. If the pinhole diameter is $D$, a far-away point on the main axis will produce a blurred spot in the image of size $D$. Also, the pinhole-blur predicted by the ray model is the same no matter how far the image plane is from the pinhole.

Second, consider the light pattern we expect for a plane wave passing through a pinhole aperture. This pattern can be calculated using a formula derived by the astronomer, George B. Airy [@airy-1835-diffraction] and is shown in @fig-blur-comparison. The Airy pattern has a central bright spot (the Airy disk), which is surrounded by a series of concentric rings. The size of the pattern depends on the wavelength of the light $\lambda$, the diameter of the pinhole $D$.  Unlike the ray model, for the diffraction case the rays are expanding so that the distance $L$ from the pinhole to the image plane matters. The image is radially symmetric with a bright spot in the center, surrounded by a set of concentric rings of decreasing intensity. The Airy disk contains about 85% of the total energy. The mathematical notation for the Airy pattern is a bit complex, but the diameter of the Airy disk, $d$, has a simple formula

$$
d = 2.44~L~(\lambda / D)
$$ {#eq-airy1}

Suppose we calculate the size of the diffraction diameter when the image plane is 1 m away, so $L=1$, and for a wavelength of light is 550 nm. Suppose the pinhole diameter is $D = 10^{-4} m$. The diameter of the Airy disk, $d$, will be

$$
d = 2.44 \times (1 m) (550 \times 10^{-9} m )/ 1 \times 10^{-4}m) = 0.0134 m
$$ {#eq-airydisk1}

```{=html}
<!-- 
The diffraction spread is larger than the pinhole spread when $d$ exceeds $D$. We do the calculation in the scripts in this [ISETCam script](https://htmlpreview.github.io/?https://github.com/wandell/FISE-git/blob/main/code/fise_diffraction.html).  For $L = 1m$ the pinhole blur is larger than the diffraction blur for a diameter of about $1 mm$.  When $L$ is much closer, say $10 mm$, the pinhole blur exceeds the diffraction blur when the diameter is $100 \mu$.
-->
```

The diffraction spread exceeds the pinhole spread when $d$ exceeds $D$. We do the calculation for different assumptions about the distance to the image plane [ISETCam script](/code/fise_diffraction.html). As an example, we find that when the distance to the image plane is $L = 1m$, the pinhole blur is larger than the diffraction blur for a pinhole diameter of about $1 mm$. When the image plane distance, $L$, is closer, say $10 mm$, the pinhole blur exceeds the diffraction blur when the diameter is $100 \mu$.

::: {.callout-note collapse="false" title="The diameter of the diffraction point spread"}

In a paper entitled "On the Diffraction of an Object-glass with Circular Aperture", George Airy provided the mathematical description of the diffraction pattern [@airy-1835-diffraction]. A modern derivation of the full point spread function for both the circular aperture and other shapes is in @goodman2022 (pages 88-94). The computation is implemented and frequently used in ISETCam. It is explained [in this tutorial](https://htmlpreview.github.io/?https://github.com/ISET/isetcam/blob/main/tutorials/optics/t_opticsAiryDisk.html).

In the main text, we expressed the formula for a particular distance from the pinhole to an image plane. For a pinhole, the formula is usually given in terms of the angle of the bundle of rays emerging from the pinhole.

$$sin(\theta) = 1.22 \lambda / D$$

When the angle is small, $\theta < 10 \deg$, the formula is very accurately approximated as

$$
\theta = 1.22 \lambda / D
$$

The size of the spot on the image plane depends on the distance how far away the pinhole is from the pinhole, as you can see in [@eq-airy2]. In @sec-optics-thinlens we provide a formula for the Airy disk size for ideal lenses.
:::

## Point spread functions {#sec-pointspread}
Throughout this section, we have discussed how a single point of light is imaged by an optical system. The resulting image is called the **point spread function (PSF)**, and it is a fundamental measure of optical performance. The Airy pattern, for example, is the PSF produced by a circular aperture due to diffraction. We will encounter other types of PSFs when we analyze optical systems using linear systems theory (@sec-optics-linear-space).

It is important to note that most optical systems, including lenses, do not have a single, fixed PSF. The PSF can vary depending on the distance to the point source and its position in the field of view. For systems with circular symmetry, the position is often described by the **field height**, which is the angle between the optical axis and the point's location.

Even in pinhole imaging, the PSF is not unique. There are two main diffraction regimes to consider. When the point source is far from the pinhole, the incoming wavefront is essentially planar, and the resulting diffraction pattern is described by **Fraunhofer diffraction** (or [far-field diffraction](https://en.wikipedia.org/wiki/Fraunhofer_diffraction)). In this case, the Airy pattern accurately describes the PSF.

When the point source is close to the pinhole, the wavefront is curved (spherical), and the diffraction pattern changes. This situation is described by **Fresnel diffraction** (or [near-field diffraction](https://en.wikipedia.org/wiki/Fresnel_diffraction)). Here, the PSF depends on the distance from the source to the aperture.

We will explore the role of the PSF in lens simulation, characterization, and computational imaging methods in  @sec-optics-linear-space and the following chapters.
