<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-10-28">
<meta name="description" content="An integrated overview of image systems, from physical scene formation through sensors, optics, and human vision.">

<title>22&nbsp; Human visual encoding – Foundations of Image Systems Engineering</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/human-03-metrics.html" rel="next">
<link href="../chapters/human-01-seeing.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles/hover.css">
<link rel="stylesheet" href="../styles/callouts.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/part-human.html">Human</a></li><li class="breadcrumb-item"><a href="../chapters/human-02-encoding.html"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Human visual encoding</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Foundations of Image Systems Engineering</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Preface</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Scenes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-scenes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part I: Scenes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/lightfields-01-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Light and seeing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/lightfields-02-measurement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Measuring light</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/lightfields-03-properties.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Light field properties</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/lightfields-04-properties-spectral.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Spectral regularities</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/lightfields-05-properties-spatial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Spatial regularities</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Optics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-optics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part II: Optics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/optics-01-geometric.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Geometric optics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/optics-02-lenses.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Lens principles</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/optics-03-thinlens.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Thin lenses</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/optics-04-morelenses.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Lenses and ray transfer</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/optics-05-linear-space.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Spatial domain</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/optics-06-linear-transform.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Transform domain</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/optics-07-wavefront.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Wavefronts</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Sensors</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-sensors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part III: Sensors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/sensors-01-photoelectric.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Photons and Electrons</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/sensors-02-pixels.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Pixels and sensors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/sensors-03-parameters.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Sensor parameters</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/sensors-04-components.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">System components</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/sensors-05-control.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Control systems</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/sensors-06-characterization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Image system modeling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/sensors-07-innovations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Sensor innovations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Human</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-human.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part IV: Human Vision</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/human-01-seeing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Seeing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/human-02-encoding.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Human visual encoding</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/human-03-metrics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Human visual metrics</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Displays</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-displays.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part V: Displays</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/displays-01-principles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Display Principles</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Image processing</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-processing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part VI: Image processing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/imgprocessing-01-hardware.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Hardware processing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/imgprocessing-02-rendering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Rendering</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/part-appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part VII: Appendix</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/appendix-01-linearsystems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Linear systems</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/appendix-02-spaceinvariance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Linear Space-Invariant (LSI) Systems</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/appendix-03-isetcam.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Image Systems Simulation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-human-encoding-overview" id="toc-sec-human-encoding-overview" class="nav-link active" data-scroll-target="#sec-human-encoding-overview"><span class="header-section-number">22.1</span> Human visual encoding overview</a></li>
  <li><a href="#sec-human-encoding-systems" id="toc-sec-human-encoding-systems" class="nav-link" data-scroll-target="#sec-human-encoding-systems"><span class="header-section-number">22.2</span> The Two Stages of Encoding</a></li>
  <li><a href="#physiological-optics" id="toc-physiological-optics" class="nav-link" data-scroll-target="#physiological-optics"><span class="header-section-number">22.3</span> Physiological optics</a></li>
  <li><a href="#retina" id="toc-retina" class="nav-link" data-scroll-target="#retina"><span class="header-section-number">22.4</span> Retina</a></li>
  <li><a href="#cone-spatial-sampling" id="toc-cone-spatial-sampling" class="nav-link" data-scroll-target="#cone-spatial-sampling"><span class="header-section-number">22.5</span> Cone spatial sampling</a></li>
  <li><a href="#psf-at-the-cones" id="toc-psf-at-the-cones" class="nav-link" data-scroll-target="#psf-at-the-cones"><span class="header-section-number">22.6</span> PSF at the cones</a>
  <ul class="collapse">
  <li><a href="#psf-wavelength-dependence." id="toc-psf-wavelength-dependence." class="nav-link" data-scroll-target="#psf-wavelength-dependence."><span class="header-section-number">22.6.1</span> PSF Wavelength dependence.</a></li>
  <li><a href="#psf-field-height-dependence" id="toc-psf-field-height-dependence" class="nav-link" data-scroll-target="#psf-field-height-dependence"><span class="header-section-number">22.6.2</span> PSF field height dependence</a></li>
  </ul></li>
  <li><a href="#photoreceptor-spatial-sampling" id="toc-photoreceptor-spatial-sampling" class="nav-link" data-scroll-target="#photoreceptor-spatial-sampling"><span class="header-section-number">22.7</span> Photoreceptor spatial sampling</a></li>
  <li><a href="#photoreceptor-wavelength-encoding" id="toc-photoreceptor-wavelength-encoding" class="nav-link" data-scroll-target="#photoreceptor-wavelength-encoding"><span class="header-section-number">22.8</span> Photoreceptor wavelength encoding</a></li>
  <li><a href="#wavelength-encoding" id="toc-wavelength-encoding" class="nav-link" data-scroll-target="#wavelength-encoding"><span class="header-section-number">22.9</span> Wavelength encoding</a>
  <ul class="collapse">
  <li><a href="#color-matching" id="toc-color-matching" class="nav-link" data-scroll-target="#color-matching"><span class="header-section-number">22.9.1</span> Color-matching</a></li>
  <li><a href="#human-chromatic-aberrations" id="toc-human-chromatic-aberrations" class="nav-link" data-scroll-target="#human-chromatic-aberrations"><span class="header-section-number">22.9.2</span> Human chromatic aberrations</a></li>
  </ul></li>
  <li><a href="#retinal-prostheses" id="toc-retinal-prostheses" class="nav-link" data-scroll-target="#retinal-prostheses"><span class="header-section-number">22.10</span> Retinal prostheses</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/part-human.html">Human</a></li><li class="breadcrumb-item"><a href="../chapters/human-02-encoding.html"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Human visual encoding</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-human-encoding" class="quarto-section-identifier"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Human visual encoding</span></span></h1>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 28, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Work in Progress
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>The book is still taking shape, and your feedback is an important part of the process. Suggestions of all kinds are welcome—whether it’s fixing small errors, raising bigger questions, or offering new perspectives. I’ll do my best to respond, but please keep in mind that the text will continue to change significantly over the next two years.</p>
<p>You can share comments through <a href="https://github.com/wandell/FISE-git/issues" target="_blank">GitHub Issues</a>.</p>
<p>Feel free to open a new issue or join an existing discussion. To make feedback easier to address, please point to the section you have in mind—by section number or a short snippet of text. Adding a label characterizing your issue would also be helpful.</p>
<p>Last updated: October 28, 2025</p>
</div>
</div>
</div>
<!--
# The chapters with David have a lot of the material for this chapter.
-->
<p>The material about human vision in this chapter is under development, and the text is not ready to be reviewed.</p>
<p>Please refer to the chapters in <a href="https://foundationsofvision.stanford.edu" target="_blank">Foundations of Vision</a>.</p>
<ul>
<li><a href="https://wandell.github.io/FOV-1995/chapter-4-wavelength-encoding.html" target="_blank">Wavelength encoding</a></li>
<li><a href="https://wandell.github.io/FOV-1995/chapter-7-pattern-sensitivity.html" target="_blank">Pattern sensitivity</a></li>
</ul>
<section id="sec-human-encoding-overview" class="level2" data-number="22.1">
<h2 data-number="22.1" class="anchored" data-anchor-id="sec-human-encoding-overview"><span class="header-section-number">22.1</span> Human visual encoding overview</h2>
<p>When you design a digital camera, how good does it need to be? The answer depends on who you’re designing it for. If the images are for a human to look at, then the camera’s design must be guided by the capabilities and limits of the human eye. This simple principle has profound consequences for engineering.</p>
<p>Vision scientists have learned a great deal about the first stages of vision. We have excellent measurements of how the eye’s optics (the cornea and lens) transform light from the world into an image on the retina, and we know how the retina’s photoreceptors encode that image into neural signals. This knowledge is not just academic; it’s a practical guide for designing any system that reproduces images for people.</p>
<p>Consider color. A camera designed for human viewing should capture the same portion of the electromagnetic spectrum that we see: visible light. Capturing less of the spectrum would lead to poor color reproduction. Capturing more—like infrared or ultraviolet—would be wasteful, consuming resources to record information we can’t see anyway. In this sense, human wavelength sensitivity sets a clear target for camera design.</p>
<p>Spatial resolution presents a different challenge. It would be a disappointment if a camera failed to capture details as fine as those the human eye can resolve. We expect our photos to be at least as sharp as what we see. However, unlike with color, people are often pleased if a camera captures a scene at a <em>finer</em> resolution than the eye can perceive. We can always zoom in on the digital image to see details we might have missed. This extra information doesn’t interfere with the viewing experience; it just requires more storage and processing power.</p>
<p>So, we have two different engineering constraints derived from human vision:</p>
<ul>
<li><strong>Wavelength:</strong> Human vision sets a <em>target range</em>. Capturing more is wasteful.</li>
<li><strong>Spatial Resolution:</strong> Human vision sets a <em>minimum bar</em>. Capturing more can be beneficial.</li>
</ul>
<p>In this section, we will review the key properties of the eye that define these limits. The way our visual system samples space and encodes wavelength creates fundamental bottlenecks on what we can perceive. Understanding these limits doesn’t explain everything about what we see, but it tells us what we <em>cannot</em> see—essential knowledge for the field of image systems engineering.</p>
</section>
<section id="sec-human-encoding-systems" class="level2" data-number="22.2">
<h2 data-number="22.2" class="anchored" data-anchor-id="sec-human-encoding-systems"><span class="header-section-number">22.2</span> The Two Stages of Encoding</h2>
<p>The process of converting light from the world into a neural signal that the brain can interpret happens in two main stages, as illustrated in <span class="quarto-unresolved-ref">?fig-eye-and-retina</span>.</p>
<p>First, the <strong>physiological optics</strong>—the cornea and lens—act like a camera lens. They gather the light entering the eye and focus it to form an image on the retina. This stage transforms the light from the environment into a focused optical image.</p>
<p>Second, the <strong>retina</strong>, a thin layer of neural tissue lining the back of the eye, converts this optical image into electrical signals. This process, called transduction, is performed by specialized cells called <strong>photoreceptors</strong>. The signals from the photoreceptors are then processed by a complex network of other retinal neurons. The final output is sent to the brain by the <strong>retinal ganglion cells (RGCs)</strong>, whose axons bundle together to form the optic nerve.</p>
<div class="tabset-margin-container"></div><div id="fig-eye-and-retina" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">Eye Anatomy</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Retinal Location</a></li></ul>
<div id="fig-eye-and-retina" class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div id="fig-human-eyeball" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-human-eyeball-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/human/02-encoding/2048px-3D_Medical_Animation_Eye_Structure.jpg" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-human-eyeball-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22.1: A cross-section of the human eye, showing the cornea, lens, iris, and retina.
</figcaption>
</figure>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div id="fig-retina-color" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-retina-color-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/human/02-encoding/retina-fovea-color.png" class="img-fluid figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-retina-color-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22.2: This diagram shows how the retina lines the back of the eyeball and highlights the fovea, the region of highest visual acuity.
</figcaption>
</figure>
</div>
<figcaption>
The two stages of visual encoding. Light is first focused by the eye’s optics onto the retina (left), where it is converted into neural signals for the brain (right). Image sources: <a href="https://www.scientificanimations.com">Scientific Animations</a> (left).
</figcaption>
</div>
</div>
</div>
<p>A key feature of the retina is that it operates as a feed-forward system; there is no direct neural feedback from the brain to the retina. This simplifies our analysis, as we can study the retina’s input-output relationship without accounting for top-down signals from other brain regions—a luxury not often afforded when studying the nervous system.</p>
<p>However, the brain also sends signals to the eye that control the size of the pupil and the optical power of the lens. The brain also provides an important indirect form of feedback by controlling eye, head, and body positions. These signals determine which part of the visual world is projected onto the retina. All of these signals are essential for seeing.</p>
</section>
<section id="physiological-optics" class="level2" data-number="22.3">
<h2 data-number="22.3" class="anchored" data-anchor-id="physiological-optics"><span class="header-section-number">22.3</span> Physiological optics</h2>
<p>The cornea and the flexible lens work together to focus light, forming an image on the retina, as shown in <span class="quarto-unresolved-ref">?fig-physiological-optics</span>. This optical system is dynamic, constantly adjusting both the amount of light it lets in and its focal point.</p>
<p>The amount of light entering the eye is controlled by the <strong>pupil</strong>, the aperture that can dilate (open) to about 8 mm in diameter in dim light or constrict (close) to about 2 mm in bright light. This change in area adjusts the light intake by a factor of about 16 (or 1.2 log units). While significant, this is a small adjustment compared to the vast range of light levels in the natural world, which can span over 10 log units. The pupil’s size changes automatically in response to light, but it is also influenced by cognitive and emotional states, such as arousal or mental effort.</p>
<div class="tabset-margin-container"></div><div id="fig-physiological-optics" class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">Eyeball image</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Eyeball sketch</a></li></ul>
<div id="fig-physiological-optics" class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div id="fig-eyeball-image" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-eyeball-image-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/human/02-encoding/eyeball-image.png" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-eyeball-image-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22.3: Image of the physiological optics
</figcaption>
</figure>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<div id="fig-eyeball-sketch" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-eyeball-sketch-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/human/02-encoding/eyeball-sketch.png" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-eyeball-sketch-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22.4: Schematic of the physiological optics
</figcaption>
</figure>
</div>
<figcaption>
The physiological optics of the human eye. The cornea provides most of the eye’s fixed optical power, while the lens adjusts its shape to change focus.
</figcaption>
</div>
</div>
</div>
<p>The eye changes its focus through a process called <strong>accommodation</strong>. Neural signals control the ciliary muscles, which are connected to the lens. To focus on distant objects, the ciliary muscles contract, which increases the diameter of the ring they form and pulls on the zonule fibers, flattening the lens. To focus on nearby objects, the muscles relax, allowing the lens to return to its natural, more rounded shape, which increases its optical power.</p>
<p>This remarkable flexibility is not permanent. With age, the lens gradually stiffens, reducing its ability to change shape. This condition, known as <strong>presbyopia</strong>, makes it difficult to focus on near objects. It typically becomes noticeable in one’s early to mid-40s and is a natural part of aging, commonly corrected with reading glasses. It happens to all of us.</p>
<!-- 
https://commons.wikimedia.org/wiki/File:3D_Medical_Animation_Eye_Structure.jpg 
https://www.scientificanimations.com, CC BY-SA 4.0 <https://creativecommons.org/licenses/by-sa/4.0>, via Wikimedia Commons
-->
</section>
<section id="retina" class="level2" data-number="22.4">
<h2 data-number="22.4" class="anchored" data-anchor-id="retina"><span class="header-section-number">22.4</span> Retina</h2>
<p>Since the 1990s, vision scientists have been able to measure the quality of the physiological optics. In the sections below, I will summarize these measurements and the techniques that were invented to make them. I will also explain how to simulate how the incident light field is transformed into the retinal image using ISETBio. For me, it is important to understand these optics in terms of the photoreceptor sampling array. Knowing that an image is spread over 5 microns can mean one thing if the photoreceptors are sampled every 2 microns and something quite different if the photoreceptors are sampled every 10 microns. So before we talk about the physiological optics, let’s consider the retina and particularly the photoreceptor mosaic.</p>
<p>The retina is approximately <span class="math inline">\(200–300\)</span> microns thick near the posterior pole, varying from about <span class="math inline">\(100\)</span> to <span class="math inline">\(500\)</span> microns across the retina. Its total area is on the order of <span class="math inline">\(10–12~cm^2\)</span>. It is a laminated neural tissue comprising three nuclear layers separated by two plexiform layers. There are on the order of 80 different cell types that can be identified through their genetic expression, responses to light, and anatomical form. The retinal cells form stereotyped connections, which we call retinal circuits. We believe that there are about 20 such circuits. The circuit outputs, carried on the retinal ganglion cell axons in the optic nerve, project to a variety of locations in the brain.</p>
<p>The vast majority of light-driven activity is initiated in the photoreceptors (rods and cones). The rods are the dominant source under very low light levels, and the cones are the dominant source under moderate to high light levels. The typical retinal circuit is driven by activity that starts in a local region of the photoreceptors. The same basic circuit will be present throughout the retina, tiling the photoreceptor mosaic, though the absolute size of the cells and their input regions generally vary across the retina. The size of the region increases as one measures from the highly specialized central fovea into the periphery.</p>
<p>There is one important and interesting exception, only recently discovered. There exists a class of retinal ganglion cells that contain a light-sensitive pigment (melanopsin). These cells, called the intrinsically photosensitive RGCs (ipRGCs), absorb photons and respond to overall light level. There are not a lot of these cells, but their outputs are important for circadian rhythms and pupillary control. They may also influence other aspects of vision.</p>
<!-- The Massey 2006 retinal anatomy paper has lots of great images.  Use that as a resource!  Some better than the ones here. -->
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">Retinal layers</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Five retinal cell types</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-3" role="tab" aria-controls="tabset-3-3" aria-selected="false">Peripheral retinal layers</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-4" role="tab" aria-controls="tabset-3-4" aria-selected="false">Fovea</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div id="fig-retina-ej" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-retina-ej-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/human/02-encoding/retina-ej.png" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-retina-ej-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22.5: This image shows the different layers of the retina very clearly. The different cell types are stained with different materials. Source: <a href="https://www.newscientist.com/gallery/dn14971-small-world-gallery/">New Scientist</a>
</figcaption>
</figure>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<div id="fig-retina-rodieck" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-retina-rodieck-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/human/02-encoding/retina-rodieck.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-retina-rodieck-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22.6: This sketch illustrates the different cell types and how they form specific circuits. The five principal cell types are illustrated. Source: Rodieck
</figcaption>
</figure>
</div>
</div>
<div id="tabset-3-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-3-tab">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/human/02-encoding/retina-massey.png" class="img-fluid figure-img" style="width:90.0%"></p>
<figcaption>This Differential Interference Contrast (DIC) microscopy image gives a sense of the density and interconnectedness of the different retinal layers and cells. It may also make it clear why it is such an accomplishment that scientists have painstakingly identified individual cell types and their circuits. Source: <span class="citation" data-cites="massey2006-retinalanatomy">Massey (<a href="references.html#ref-massey2006-retinalanatomy" role="doc-biblioref">2006</a>)</span></figcaption>
</figure>
</div>
</div>
<div id="tabset-3-4" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-4-tab">
<div id="fig-retina-fovea" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-retina-fovea-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/human/02-encoding/retina-fovea.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-retina-fovea-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22.7: The primate retina—but not all retinas—has a very important specialization: the fovea. This is a cone-dominated region; inner retinal layers are laterally displaced, creating a pit and enabling very high acuity. GCL: Ganglion cell layer. INL: Inner nuclear layer (sometimes labeled “bipolar layer” in schematics). REC/PR: Photoreceptors. RPE: Retinal pigment epithelium. Source: I have had this forever. I have searched for the source. Better image from Massey paper, maybe.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>
</p><figcaption>
A variety of ways of visualizing and characterizing the retina.
</figcaption>
<p></p>
<!-- 
DIC optics refers to **Differential Interference Contrast microscopy**.

It's a type of optical microscopy technique that enhances the contrast in unstained, transparent specimens, like the layers of a retina, by making features visible that would otherwise be nearly invisible in a brightfield microscope.

### How DIC Optics Work

DIC microscopy converts gradients in specimen thickness or refractive index (which naturally occur at the boundaries of structures like cell layers, membranes, and organelles) into differences in light intensity (contrast) that the human eye or a camera can detect.

1.  **Light Manipulation:** It uses specialized optical components, primarily **polarizers** and **Nomarski prisms** (or Wollaston prisms), to split a single beam of light into two beams that are slightly offset from each other.
2.  **Phase Shift:** These two beams pass through adjacent regions of the specimen. Since the specimen has a varying refractive index (e.g., one beam passes through a cell membrane, the other through the surrounding cytoplasm), the light waves emerge with a slight **phase difference**.
3.  **Interference:** The beams are then recombined. Due to the phase difference, they **interfere** with each other. This interference creates a high-contrast, pseudo-three-dimensional relief image, making structures like the cell layers and fine details mentioned in the caption (e.g., cone pedicles) much more distinct and easier to observe without the need for staining. 

In the context of the figure caption, using DIC optics allowed the researchers to clearly delineate the layered structure of the macaque retina—the **plexiform layers** and the **nuclear layers (ONL, INL, ganglion cell layer)**—in a fresh or relatively unstained preparation.
-->
</section>
<section id="cone-spatial-sampling" class="level2" data-number="22.5">
<h2 data-number="22.5" class="anchored" data-anchor-id="cone-spatial-sampling"><span class="header-section-number">22.5</span> Cone spatial sampling</h2>
<p>The rod and cone photoreceptors are specialized neurons whose principal function is to convert electromagnetic radiation into a neural signal. Both types of photoreceptors accomplish this using a light-sensitive pigment (photopigment). This pigment absorbs photons and, in so doing, initiates a chain reaction of events within the cell (<span class="citation" data-cites="stryer1986-annrev">Stryer (<a href="references.html#ref-stryer1986-annrev" role="doc-biblioref">1986</a>)</span>). These events, the transduction cascade, result in a change in the synaptic signal from the photoreceptor. The spatio-temporal pattern of changes across the photoreceptor mosaic is the signal that the nervous system interprets and the basis of our sight.</p>
<p>The arrows at the bottom indicate the direction of the incoming light (the lens is below). The light arrives at the photoreceptor layer, brought into focus by the physiological optics. Some of the light enters the cell through the inner-segment aperture. Because of the refractive-index contrast between the inner segment and surrounding medium, the inner segment acts as a waveguide that directs the light toward the outer segment, where it initiates the transduction cascade.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">Simple rod and cone</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Detailed rod and cone</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div id="fig-photoreceptor-baylor" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-photoreceptor-baylor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/human/02-encoding/photoreceptor-baylor.png" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-photoreceptor-baylor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22.8: Denis Baylor’s Proctor Medal award included this very simple diagram, which he entitled ‘A physiologist’s diagram of a rod and cone.’ The horizontal lines show the stacks of photosensitive pigment molecules within the outer segment of these cells. The arrangement differs between the rods and cones. In the rods, the photopigment is mainly contained in discs (saccules) that are not continuous with the cell’s surface membrane. In the cones, the photosensitive membrane is continuous with the cell surface. The absorption of a photon initiates a series of events (transduction cascade) that modulates the membrane potential and the rate of synaptic transmitter release. The transmitter itself is packaged in synaptic vesicles, shown by the circles. Source: <span class="citation" data-cites="baylorPhotoreceptorSignalsVision1987">Baylor (<a href="references.html#ref-baylorPhotoreceptorSignalsVision1987" role="doc-biblioref">1987</a>)</span>
</figcaption>
</figure>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<div id="fig-photoreceptor-anatomy" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-photoreceptor-anatomy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/human/02-encoding/photoreceptor-cote.png" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-photoreceptor-anatomy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22.9: Cote’s review article paints a more detailed picture of the anatomical and functional elements of the rod and cone receptors. Source: <span class="citation" data-cites="cote2006-photoreceptor">Cote (<a href="references.html#ref-cote2006-photoreceptor" role="doc-biblioref">2006</a>)</span>, Fig 8.1
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>
</p><figcaption>
The photoreceptors capture light. The light enters the photoreceptor through the inner segment and is absorbed by the photosensitive molecules in the outer segment.
</figcaption>
<p></p>
<p>The rod and cone photoreceptors are two largely distinct systems. The rods are mainly used to provide vision under low light levels (scotopic; e.g., nighttime). There is only one type of rod photopigment, rhodopsin. For this reason the rod system provides no information to compare the different wavelengths of light incident at the retina.</p>
<p>The cone photoreceptors dominate vision at modest to high levels of illumination. There are three types of cones, containing three different photopigments. These photopigments absorb over a fairly broad wavelength band, but they have different peak sensitivities in the long-, middle-, and short-wavelength parts of the visible spectrum. I will cover more on this in the color section below.</p>
<p>The spatial resolution of the human eye depends on the aperture size and spacing of the photoreceptor inner segments, particularly for the cones. A great deal was discovered about the sampling mosaic in the 1980s and 1990s <span class="citation" data-cites="curcioHumanPhotoreceptorTopography1990">Curcio et al. (<a href="references.html#ref-curcioHumanPhotoreceptorTopography1990" role="doc-biblioref">1990</a>)</span>. Prior to that time, the nature of the cone sampling mosaic and the importance of sampling were not widely appreciated. The importance of sampling was emphasized by Yellott and colleagues, who analyzed the spatial sampling. William Miller and Joy Hirsch, at Yale, were among the first to crisply show the dense packing (<span class="citation" data-cites="miller1987-conesampling">Hirsch and Miller (<a href="references.html#ref-miller1987-conesampling" role="doc-biblioref">1987</a>)</span>). Over small patches of the primate retina the packing is quite dense (<a href="#fig-inner-segment-miller" class="quarto-xref">Figure&nbsp;<span>22.10</span></a>), in a spatial arrangement called a triangular (hexagonal) packing.</p>
<div id="fig-inner-segment-miller" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-inner-segment-miller-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/human/02-encoding/inner-segments-foveal.png" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-inner-segment-miller-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22.10: Miller cone inner segment spatial sampling. Source: Based on <span class="citation" data-cites="miller1987-conesampling">Hirsch and Miller (<a href="references.html#ref-miller1987-conesampling" role="doc-biblioref">1987</a>)</span> (personal communication)
</figcaption>
</figure>
</div>
<p>How does the spatial sampling of the cones compare to the optical PSF? One comparison we can make is for the central fovea. There the inner-segment apertures are about 1.5–2 microns in diameter. Using ISETCam we can calculate the diffraction-limited Airy disk diameter (first minimum) for a 550 nm light. For a 3 mm pupil, the f-number of the human optics is 17 mm / 3 mm ≈ 5.6. Using <a href="optics-01-geometric.html#eq-airydisk1" class="quarto-xref">Equation&nbsp;<span>7.2</span></a>, this is:</p>
<pre><code>&gt;&gt; radius = airyDisk(550,5.6,'units','um','diameter',true)
radius =
    7.5152</code></pre>
<p>Thus, a tiny point in the scene -say star light- will be spread over a diameter of about 7 microns on the retinal surface, which corresponds to a little more than 3 cones. Under typical natural vision conditions, no stimulus excites a single photoreceptor. The nervous system must always interpret the signal from multiple cones, even if it draws the inference that the source is a single, tiny point.</p>
<p>One reason for creating such a system is that it enables us to judge the wavelength of the source better. By spreading the light across 5-10 cones, we are likely to sample the light using more than one type of photopigment. We saw a similar principle when reviewing the color filter array in cameras; early camera designers introduced blur the light from a small point to be measured by the R,G and B camera pixels (<a href="sensors-04-components.html#sec-sensor-cfa" class="quarto-xref"><span>Section 17.3.2</span></a>). But, what is the arrangement of the different cone types in the human eye?</p>
<p>Data on this point also emerged in the 1980s and 1990s.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">Cone types</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">S-cones sampling</a></li></ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div id="fig-scones-wikley" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scones-wikley-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/human/02-encoding/s-cone-sampling.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scones-wikley-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22.11: L,M cone types, intermixed with rods, and some S-cone hints. Lots of rods. Near periphery. Source: <span class="citation" data-cites="wikler1990-photoreceptor-subtypes">Wikler and Rakic (<a href="references.html#ref-wikler1990-photoreceptor-subtypes" role="doc-biblioref">1990</a>)</span>
</figcaption>
</figure>
</div>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<div id="fig-scones-schein" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scones-schein-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/human/02-encoding/scones-schein.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scones-schein-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22.12: S-cone procion yellow staining from de Monasterio and Schein. Source <span class="citation" data-cites="demonasterior1981-scones">(<a href="references.html#ref-demonasterior1981-scones" role="doc-biblioref"><strong>demonasterior1981-scones?</strong></a>)</span> see also <span class="citation" data-cites="demonasterio1985-scones">Monasterio et al. (<a href="references.html#ref-demonasterio1985-scones" role="doc-biblioref">1985</a>)</span>
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>
</p><figcaption>
Cone mosaics of the different cone types are interleaved. The L and M cone mosaics are interleaved approximately randomly at high resolution. The S-cone mosaic samples the image much more coarsely, and it is relatively more uniform.
</figcaption>
</section>
<section id="psf-at-the-cones" class="level2" data-number="22.6">
<h2 data-number="22.6" class="anchored" data-anchor-id="psf-at-the-cones"><span class="header-section-number">22.6</span> PSF at the cones</h2>
<!-- See fise_humanConePSF.m in code/human -->
<p>We are ready to describe the optical spread with respect to the cone mosaic image. We needed the retina and the photoreceptor sampling mosaic defined so we could make sense of the whoe system.</p>
<p>Illustrate a white light? Show a range of eccentricities here with a FISE script that gets the proper wvf as a function of field height.</p>
<section id="psf-wavelength-dependence." class="level3" data-number="22.6.1">
<h3 data-number="22.6.1" class="anchored" data-anchor-id="psf-wavelength-dependence."><span class="header-section-number">22.6.1</span> PSF Wavelength dependence.</h3>
<p>Illustrate large impact of chromatic aberration</p>
<p>The short wavelength light is focused at the RGC layer when the middle wavelengths are in good focus at the inner segment.</p>
<!-- See fise_humanConePSF.m in code/human -->
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true">PSF for 550nm</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false">PSF for 480nm</a></li></ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<div id="fig-psf-550nm" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-psf-550nm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/human/02-encoding/conePSF-550.svg" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-psf-550nm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22.13: Foveal cone mosaic PSFs for a 550nm light
</figcaption>
</figure>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<div id="fig-psf-480nm" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-psf-480nm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/human/02-encoding/conePSF-480.svg" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-psf-480nm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22.14: Foveal cone mosaic PSFs for a 480 light
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>
</p><figcaption>
Point spread function for different wavelengths, superimposed on the foveal sampling mosaic.
</figcaption>
</section>
<section id="psf-field-height-dependence" class="level3" data-number="22.6.2">
<h3 data-number="22.6.2" class="anchored" data-anchor-id="psf-field-height-dependence"><span class="header-section-number">22.6.2</span> PSF field height dependence</h3>
<p>Artal data. Point to ISETBio and maybe the other book.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Measuring the human optical PSF">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Measuring the human optical PSF
</div>
</div>
<div class="callout-body-container callout-body">
<p>This callout is a mess. Too much going on. Lots of rewriting ahead.</p>
<section id="sec-wavefront-sensor" class="level3" data-number="22.6.3">
<h3 data-number="22.6.3" class="anchored" data-anchor-id="sec-wavefront-sensor"><span class="header-section-number">22.6.3</span> Shack–Hartmann wavefront sensor</h3>
<p>Johannes Franz Hartmann was a German astronomer working on the problem of detecting optical defects in telescope objectives. Reasoning from the ray theory of light, he measured the optical light field from a simple stimulus: an on-axis point at the focal length of the lens. In principle, the rays emerging from an ideal lens would all be parallel to the main axis. To look for deviations, he created a screen comprising an array of pinholes. If the rays were parallel, the light through the pinhole would be nicely centered behind the pinhole. If the rays were not quite parallel, the image behind the pinhole would be displaced by some distance and amount from the center. The deviations could be considered defects in the lens that could be corrected.</p>
<p>As I observed above, the image behind each pinhole measures the intensity of the rays incident at different angles. But in practice, a small pinhole produces a blurry spot due to diffraction. Thus Hartmann did not try to extract an image but he just estimated the central position of the blurry spot. Also, because the pinholes only let through a small amount of light, the technique was not very sensitive.</p>
<p>Because there is an array of these pinholes, the accumulation of pinhole images measures the rays at multiple angles at multiple positions. In principle, by performing this measurement for different wavelengths and polarizations, we sample the optical light field (<a href="lightfields-01-intro.html#eq-lightfield-optical" class="quarto-xref">Equation&nbsp;<span>2.3</span></a>).</p>
<!--
The Raskar version in which you put spots behind the lenslet array and adjust the spots to make the array uniform is kind of funny.  It is intended to measure the optical aberrations of the eye
https://en.wikipedia.org/wiki/Shack%E2%80%93Hartmann_wavefront_sensor
-->
<!--
# What about the color matching experiment? Maybe James Clerk Maxwell mentioned but referred to FOV 
-->
<p><a href="https://www.optics.arizona.edu/sites/default/files/2022-07/Historical-Development-Shack-Hartman-Wavefront-Sensor.pdf?utm_source=chatgpt.com">Arizona History of the Shack work.</a></p>
</section>
<section id="sec-telescopes" class="level3" data-number="22.6.4">
<h3 data-number="22.6.4" class="anchored" data-anchor-id="sec-telescopes"><span class="header-section-number">22.6.4</span> Ground-based telescopes</h3>
<p>These same technologies can be used to look inward, within the eye, rather than outward toward the stars. Realizing this was a very important insight that continues to lead to important insights about the peripheral human visual system (<a href="human-01-seeing.html#sec-human-seeing-overview" class="quarto-xref"><span>Section 21.1</span></a>).</p>
</section>
<section id="sec-adaptive-optics" class="level3" data-number="22.6.5">
<h3 data-number="22.6.5" class="anchored" data-anchor-id="sec-adaptive-optics"><span class="header-section-number">22.6.5</span> Adaptive optics</h3>
<p>Where should the adaptive optics measurement method be? Here or FOV? Adaptive optics measurements of wavefront aberrations, expressed as point spread functions. Thibos and Artal data.</p>
<p>The ability to measure certain properties of the optics was revolutionized by adpative optics - a method that makes real time measurements of the wavefront aberrations of the physiological optics using a Shack-Hartmann wavefront sensor. Just the measurement of the aberrations alone is useful. In addition, it has proben possible to engineer systems that correct for these aberrations in real time, and thus visualize the apertures of the photoreceptors (1-5 <span class="math inline">\(\mu \text{m}\)</span> diameter) cells in the retina. Further, using video tracking of the eye movements it has proven possible to deliver stimuli to specific, targeted photoreceptors.</p>
<p>First order approximations of the human optics. Simulations with ISETBio of maybe the Westheimer or Ijspeert functions. Eye models?</p>
</section>
</div>
</div>
</section>
</section>
<section id="photoreceptor-spatial-sampling" class="level2" data-number="22.7">
<h2 data-number="22.7" class="anchored" data-anchor-id="photoreceptor-spatial-sampling"><span class="header-section-number">22.7</span> Photoreceptor spatial sampling</h2>
<p>Maybe point mainly to the other book. Image showing the fovea and inhomogeneous sampling of the photoreceptor mosaics. Maybe Curcio. Maybe the S-cone image sampling mosaic. Adaptive optics measurements of retinal sampling Rods, ipRGCs, too in here. Other book - ISETBio: Examples of simulation. David also has these new measurements.</p>
</section>
<section id="photoreceptor-wavelength-encoding" class="level2" data-number="22.8">
<h2 data-number="22.8" class="anchored" data-anchor-id="photoreceptor-wavelength-encoding"><span class="header-section-number">22.8</span> Photoreceptor wavelength encoding</h2>
<p>The neural tissue of the retina lines the curved surface at the back of the eye. The retina is about 5 x 5 cm, and its properties vary considerably across space. The retinal image is converted into a neural signal by a special class of neurons, the photoreceptors. The retina contains many types of specialized cells that combine into stereotypical local circuits. Multiple copies of these local circuits, but usually with different parameters, are present throughout the retina. The circuit outputs leave the retina via the optic nerve. One of the ways we can identify these circuits is that their outputs are transmitted to multiple brain regions. The circuit properties are dynamic in the sense that the circuit response to a simple stimulus, say a small flashed spot, varies with changes in the mean and variance of the retinal image.</p>
<p>There are some similarities between the eye and a conventional camera. For example, the optics and light sensing components are integrated into a single package, and the components are adaptive with respect to light level and focus. But there are lots of differences, as well. One major difference is that the retinal encoding does not sample the image uniformly; it is very inhomogeneous compared to modern cameras. The central human retina is specialized for the cone photoreceptors, which have small (~ 1.5 um) apertures and are tightly packed. The size of the photoreceptor apertures increases significantly from fovea to periphery, and the receptors for nighttime vision (rods) are inserted between the cones, further increasing their center-to-center spacing. This spatial sampling is quite unlike a typical image sensor whose pixels are all of the same size. Finally, the human visual system relies on eye movements to bring regions of interest into focus at the fovea. The keep integration of eye movements is very important for such a spatially inhomogeneous system.</p>
<p>I will describe measurements of the optics and encoding in several sections below. These are selected to support calculations of image quality and engineering design. For more about the biology and the scientific methods used to derive these measurements, consult <span class="citation" data-cites="wandellFoundationsVision2024">(<a href="references.html#ref-wandellFoundationsVision2024" role="doc-biblioref">Wandell 2024</a>)</span></p>
</section>
<section id="wavelength-encoding" class="level2" data-number="22.9">
<h2 data-number="22.9" class="anchored" data-anchor-id="wavelength-encoding"><span class="header-section-number">22.9</span> Wavelength encoding</h2>
<!--
https://chatgpt.com/s/t_68af5af69c688191b21118844094d0b5

By Henry Brougham in Edinburgh Review, an ardent admirer of Newton, criticizing Thomas Young’s Bakerian Lectures.

>  ...this paper contains nothing which deserves the name, either of experiment or of discovery, and as it is, in fact, destitute of every species of merit. We now dismiss, for the present, the feeble lucubrations of this author, in which we have searched without success for some traces of learning, acuteness, and ingenuity, that might compensate his evident deficiency in the powers of solid thinking, calm and patient investigation … 

Thomas Young wrote a reply (@young1804-reply)

 > A MAN who has a proper regard for the dignity of his own character, although his sensibility may sometimes be awakened by the unjust attacks of interested malevolence, will esteem it ingeneral more advisable to bear, in silence, the temporary effects of a short lived injury, than to suffer his own pursuits to be interrupted, in making an effort to repel the invective, and to punish the aggressor. 
-->
<section id="color-matching" class="level3" data-number="22.9.1">
<h3 data-number="22.9.1" class="anchored" data-anchor-id="color-matching"><span class="header-section-number">22.9.1</span> Color-matching</h3>
</section>
<section id="human-chromatic-aberrations" class="level3" data-number="22.9.2">
<h3 data-number="22.9.2" class="anchored" data-anchor-id="human-chromatic-aberrations"><span class="header-section-number">22.9.2</span> Human chromatic aberrations</h3>
<p>fise_human* script exists.</p>
<p>Wavelength dependence (chromatic aberration)</p>
</section>
</section>
<section id="retinal-prostheses" class="level2" data-number="22.10">
<h2 data-number="22.10" class="anchored" data-anchor-id="retinal-prostheses"><span class="header-section-number">22.10</span> Retinal prostheses</h2>
<p>Now that we know so much about the retinal encoding, the Palanker project would fit well.</p>
<p>THe Chichilnisky project gets thrown in at the end as next generation. Palanker fits well with the cones going forward. The Chichilnisky project fits well with motivating why we want to know what the retinal circuitry does so we address diseases when the bipolar cells (inner nuclear layer) are damaged.</p>



<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-baylorPhotoreceptorSignalsVision1987" class="csl-entry" role="listitem">
Baylor DA (1987) <a href="https://www.ncbi.nlm.nih.gov/pubmed/3026986">Photoreceptor signals and vision. <span>Proctor</span> lecture</a>. Investigative Ophthalmology and Visual Science 28:34–49
</div>
<div id="ref-cote2006-photoreceptor" class="csl-entry" role="listitem">
Cote RH (2006) <a href="http://dx.doi.org/10.1201/9781420020847-8/photoreceptor-phosphodiesterase-pde6-protein-activated-pde-regulating-visual-excitation-rod-cone-photoreceptor-cells-rick-cote">Photoreceptor phosphodiesterase (<span>PDE6</span>): A <span>G</span>-protein-activated <span>PDE</span> regulating visual excitation in rod and cone photoreceptor cells</a>. In: Cyclic nucleotide phosphodiesterases in health and disease. CRC Press, pp 165–193
</div>
<div id="ref-curcioHumanPhotoreceptorTopography1990" class="csl-entry" role="listitem">
Curcio CA, Sloan KR, Kalina RE, Hendrickson AE (1990) Human photoreceptor topography. Journal of Comparative Neurology 292:497–523
</div>
<div id="ref-miller1987-conesampling" class="csl-entry" role="listitem">
Hirsch J, Miller WH (1987) <a href="https://opg.optica.org/abstract.cfm?uri=josaa-4-8-1481">Does cone positional disorder limit resolution?</a> Journal of the Optical Society of America A 4:1481–1492
</div>
<div id="ref-massey2006-retinalanatomy" class="csl-entry" role="listitem">
Massey SC (2006) Functional anatomy of the mammalian retina. In: Retina. Elsevier, pp 43–82
</div>
<div id="ref-demonasterio1985-scones" class="csl-entry" role="listitem">
Monasterio FD de, McCrane E, Newlander J, Schein S (1985) <a href="https://iovs.arvojournals.org/article.aspx?articleid=2177000">Density profile of blue-sensitive cones along the horizontal meridian of macaque retina</a>. Invest Ophthalmol Vis Sci 26:289–302
</div>
<div id="ref-stryer1986-annrev" class="csl-entry" role="listitem">
Stryer L (1986) <a href="http://dx.doi.org/10.1146/annurev.ne.09.030186.000511">Cyclic <span>GMP</span> cascade of vision</a>. Annu Rev Neurosci 9:87–119
</div>
<div id="ref-wandellFoundationsVision2024" class="csl-entry" role="listitem">
Wandell BA (2024) <a href="https://github.io.fov2024">Foundations of <span>Vision</span>, 2nd ed.</a> Quarto
</div>
<div id="ref-wikler1990-photoreceptor-subtypes" class="csl-entry" role="listitem">
Wikler KC, Rakic P (1990) <a href="http://dx.doi.org/10.1523/JNEUROSCI.10-10-03390.1990">Distribution of photoreceptor subtypes in the retina of diurnal and nocturnal primates</a>. J Neurosci 10:3390–3401
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/human-01-seeing.html" class="pagination-link" aria-label="Seeing">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Seeing</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/human-03-metrics.html" class="pagination-link" aria-label="Human visual metrics">
        <span class="nav-page-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Human visual metrics</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>