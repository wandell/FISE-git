# Light field properties {#sec-lightfield-properties}

Many image systems are designed to measure the scene. These measurements might be used to identify an object and its properties, such as its size, distance, and material. These systems are fundamental to applications like industrial inspection, autonomous vehicles, and medical imaging. Even in consumer photography applications, whose primary mission is to reproduce the light field, estimating scene physical characteristics - such as the ambient lighting - can be useful.

In many image systems applications the problem is under constrained, by which I mean that many different scenes or objects might have produced the measured image. There is a useful principle that applies to these situations, often attributed to Thomas Bayes, is quite simple. If many potential solutions exist to a problem, Bayes' Rule tells us to select the most likely one. The general principle seems pretty obvious, no? The hard part, of course, is how to know which answer is the most likely one.

We do not always have information about the relative likelihood of different solutions, but sometimes we do. One way to make better guesses is to learn about regularities in the world. In this section we describe some regularities about the spectral (wavelength) and spatial properties of natural images. In certain specific applications, such as medical imaging or industrial inspection conditions, the regularities may narrow the set of possible answers greatly.

## Representing regularities

### Bayes Rules

How to specify regularities in the scene, and how to take advantage of them, will be a recurring theme as we describe various image systems. There are two classical mathematical tools that are widely used to specify regularities throughout science and engineering, and both will come up in this book. I just mentioned Bayes' Rule, which is extremely famous and simple. If we know the probability of a specific condition, $C$, being true given a measurement, $d$, we use the laws of probability to write

$$
P(C | d) = \frac{P(d \cap C)}{P(d)} = \frac{P(d \cap C) P(C)}{P(d) P(C)}= \frac{P(d | C) P(C)}{P(d)}
$$

::: {#Bays-terms .callout-note style="color: gray" appearance="simple"}
### The terms in Bayes' Rule

-   $P(C | d)$ - **posterior probability** of C given d.
-   $P(d|C)$ - likelihood of d given C.
-   $P(C)$ - **prior probability** of C.
-   $P(d)$ - marginal probability of d.
:::

The challenge in using Bayes' Rule is that in many cases we have very little idea about the prior; and, for many applications we do not know how to even compute the likelihood of $d$ given $C$.

## Linear models

Linear models are a second way to capture the regularity in the data. These are a standard linear algebra tool, in which we express the data - which is usually a large collection of vector measurements - as the weighted sum of a known, fixed, set of possible vectors called the *basis* vectors. To connect the idea to the case at hand, suppose we consider the data to be a spectrum, $d(\lambda)$, where we measure over the visible range from 380 nm to 780 nm in 1 nm steps (hence, \$d\$ is 401 dimensions). After making a few thousand (or million) measurements we might discover that we can closely approximate the $j^{th}$ measurement as the weighted sum of $N$ basis functions.  We write that approximation this way:

$$
d_j(\lambda) \approx \sum_{i=1}^{N} B_i(\lambda) w_{ij}
$$ {#eq-linear1}

This linear model representation can efficiently capture many types of regularities in the data. As an example, it is common to make measurements at a large number of samples, so that the vector $d_j(\lambda)$ may be large, in this example 401. We may find that over the collection of measurements we can approximate all the data with a relatively small number of basis functions ($N$ is 5, 10, 20). We might then representing each observation using only $N << 401$ values (along with the values in the $N$ basis functions).

Most commonly the basis functions $B_i$ are chosen to be orthogonal to one another. For example, this is the choice when people use the principal components method. Basis vector orthogonality means that the inner product[^lightfields-properties-1] of any pair of basis vectors is zero. The formula for the inner product, in this example is,

[^lightfields-properties-1]: Widely used synonyms for the term inner product are *dot product* and *scalar product*.
$$
0 = \sum_{\lambda} B_i(\lambda) B_j(\lambda)
$$

Some of you will notice that we can use matrix notation to express the linear model. The linear model simply expresses the data, $\mathbf{d_j}$ vector as the product of a weight vector, $\mathbf{w_j}$ and the basis vectors placed in the columns of the matrix $\mathbf{B}$.

$$
\mathbf{d_j} = \mathbf{B} \mathbf{w_j}
$$
{#eq-linearmatrix}

Linear models appear in many places in this book, with many different applications. When you are ready to read more about them as a general mathematical tool, go to the Appendix chapter on linear models. It has a chatty discussion that can help you find your way into the more advanced literature, as well as a guide to learn about nonlinear methods that - in some circumstances - can be very helpful @DiCarlo2003-spectralestimationtheory also ISOMAP.

## Spectral regularities

```{=html}
<!-- [https://chatgpt.com/share/679ebc49-5a7c-8002-a282-598e7f1bbb30 ]
Solar spectrum. Fraunhofer lines.  Stability of the solar spectrum 

https://chatgpt.com/c/679ebbfc-b510-8002-b372-489cd173d5d0

CIE Data downloaded to ISETCam from here.  Placed in data/lights/daylight and data/lights/solar  These appear to be distinguished, for now, based on Earth's surface or Sun's surface.

https://cie.co.at/datatable/components-relative-spectral-distribution-daylight
-->
```

### Solar Radiation

The Sun serves as Earth's primary radiation source. The radiation emitted from the Sun's surface in the visible spectrum remains relatively consistent over time. Due to its significance for imaging and human vision, skylight became an early subject of scientific investigation.

In 1814, Joseph Fraunhofer observed and carefully documented numerous dark lines in the solar spectrum, now known as **Fraunhofer lines** It was subsequently discovered that these lines are present because light generated in the Sun's hot, dense interior (photosphere) travels through its cooler outer layers (chromosphere and corona). During this passage, atoms and ions absorb specific wavelengths of light that correspond precisely to their electron transitions. The reliability of these solar absorption lines allows scientists to use them as reference points to calibrate laboratory instruments for spectral measurements. For example, James Clerk Maxwell used these lines to calibrate the first experimental rig for human color-matching.

![The black curve displays the relative solar spectrum, which is stable over time. The red lines indicate are drawn at wavelengths where the spectrum exhibits narrow intensity reductions, known as Fraunhofer lines, that originate from ions and atoms in the Sun's outer layers. The blue dotted lines mark intensity reductions caused by atmospheric water vapor.](images/lightfields/01-solar-lines.png){#fig-solarspectrum width="60%" fig-align="center" width="70%"}

::: {#fraunhofer .callout-note collapse="true" appearance="simple"}
## [Joseph Fraunhofer (1787-1826)](https://en.wikipedia.org/wiki/Joseph_von_Fraunhofer)

Fraunhofer was a brilliant applied researcher who worked on the physical properties of materials, particularly glass. He also made important contributions to the theory of image formation and optics.

The Fraunhofer lines, which he discovered while building a device to measure the spectral transmissivity of glass, are reported in a paper reviewing the properties of glass. These relative intensity of these lines are determined by the material composition of the stars, and these measurements are stilled used in astronomy to determine the composition of celestial bodies. Fraunhofer died at the age of 39, poisoned by heavy metal vapors used in his material research. Europe's largest body for the advancement of applied research, the Fraunhofer Society, is named to honor him.

![](images/people/Fraunhofer.png){fig-align="center" width="391"}

This is a good historical review of the [Fraunhofer lines](https://joachimweise.github.io/post/2020-10-20-fraunhofer-lines/) and subsequent work.
:::

### Atmospheric Effects

Some of the spectral absorption lines observed at Earth's surface originate from a different source: water vapor (H₂O) and other molecules in Earth's atmosphere. Unlike the stable solar absorption lines, these atmospheric absorptions fluctuate relatively quickly with changing weather conditions. There is also atmospheric variation in the skylight spectral power with the time of day, as the radiation's path length through the atmosphere varies. Longer path lengths — such as during sunrise or sunset — modify the spectral composition of radiation reaching Earth's surface.

A number of different groups have reported measurements of solar radiation at the Earth's surface at varying times of day and weather conditions [@Judd1964-daylight]. Figure #fig-daylights shows examples of typical variation in the shape of the spectral power distribution in Granada, Spain [@Hernandez2001-daylight] and Stanford, California [@DiCarlo2000-daylight].

![The spectral power distribution of daylights sampled at the Earth's surface in Granada, Spain (left) and Stanford, California (right) at different times of day and weather conditions. The spectra have been scaled to be equal at 450 nm. The curves have different slopes, and their shapes vary with weather and time-of-day. Identifiable Fraunhofer lines and water vapor lines are present in the measurements.](images/lightfields/01-solar-samples.png){#fig-daylights width="90%" fig-align="center" width="90%"}

These combined factors—atmospheric composition and path length variations—create a complex and dynamic radiation environment at Earth's surface. To account for these complexities, scientists and engineers have created linear models that can represent the natural variations of skylight incident upon Earth's surface. The original model was introduced by Judd, Macadam and Wyszecki [@Judd1964-daylight]. They analyzed skylight at the Earth's surface from about 650 different conditions. They found that the spectral power distributions, normalized to remove absolute radiance, could be modeled as the weighted sum of three terms: a mean and two basis functions (Figure @fig-ciedaylight). Such a model is useful because it enables us to represent any particular sample using just three numbers, the two weights and an overall scalar to match the level. The model is also useful for applications in which a scene is acquired under full sky illumination, and we would like to estimate the spectral power distribution of the skylight. We only need to estimate the weights, and from those we can make a good estimate of the full spectrum.

![The solid curve shows the mean daylight spectrum measured by Judd, Macadam and Wyszecki @Judd1964-daylight. Their measurements evolved into a CIE standard linear model for daylights. The solid circles are placed at the wavelengths of Fraunhofer and atmospheric water vapor lines. The dotted and dashed curves are basis functions. Together with the mean, they form a linear model of daylight spectral power distributions.](images/lightfields/01-solar-basis.png){#fig-ciedaylight width="50%" fig-align="center"}

```{=html}
<!--
Moonlight regularities. Used for space travel.https://chatgpt.com/share/67410dd0-ff54-8002-9b73-65294a849fe6 “The Potential of Moonlight Remote Sensing: A Systematic Assessment” explores the potential of using moonlight in remote sensing for nighttime Earth observation. The study uses data from VIIRS, the ISS, and UAV systems to evaluate moonlight’s capabilities.“Simulation Study of the Lunar Spectral Irradiances and the Earth-Based Moon Observation Geometry” focuses on modeling the spectral irradiance of moonlight using the Hapke model and its applications in satellite radiometric calibration.
-->
```

::: {#california-sun .callout-note collapse="true" appearance="simple"}
## Do it yourself daylight spectra

When he was a student at Stanford, Jeff DiCarlo decided to measure the daylight outside his office for himself [@DiCarlo2000-daylight]. Checking things for himself is in his nature. Jeff pointed a spectral radiometer at a calibrated surface outside his window and configured a computer to make about ten thousand measurements, one a minute, during the course of a few rainy weeks in California (January 28, 2000 to February 16, 2000). I included a sample of 1000 of these measurements in ISETCam, and I have the whole group along with time stamps if you want them.

![Average daylight measurements on the Stanford campus (solid) and CIE daylight basis fit to the measured average (dotted). The solid circles are placed at the locations of Fraunhofer and water vapor wavelengths.](images/lightfields/01-solar-stanford.png){#fig-stanfordsun fig-cap-location="bottom" width="50%" fig-align="center"}

@fig-stanfordsun shows the mean spectral power distribution of these measurements. You can see that the instrument recorded several 'notches' the spectrum at wavelengths corresponding to the Fraunhofer and water vapor lines. We also asked whether these data could be fit by the CIE linear model - and the least-squares fit is shown by the dotted line. I suspect there is an instrument calibration error of a few nanometers at wavelengths above 700nm, and were I to write a research paper based on these data, I would probably introduce the correction because I believe the physics on the locations of these wavelengths is secure. This analysis might provide you with a sense of the relative accuracy of measuring and approximating spectra with conventional lab equipment.
:::

```{=html}
<!-- Later in the book use these daylights to show the appearance (chromaticity) of the different daylights.  The Granada paper does this nicely. "Color and spectral analysis of daylight in southern Europe"
-->
```

In which we say something about the weights can be correlated, even though the basis functions are orthogonal. Non-negativity constraint, for example. See what I put in the DiCarlo article illuminating bases. Also, there are plots of the tight relationship that will show up in the human vision part for the Granada data.

::: {#daylight-weights .callout-note collapse="true" appearance="simple"}
### Correlated weights

![The daylight basis weights from the Granada and Stanford data sets. The weights are clustered within a plane, although there are occasional outliers. The orthogonality of the basis functions does not imply independence or orthogonality of the measured basis weights.](images/lightfields/01-dayweights3d.gif){#fig-dayweights fig-align="center" width="372"}
:::

## Surface spectral reflectance regularities

Vision is a remarkable invention that enables us to interpret the environment by recording the how the ambient illumination interacts with it. Four things can happen when electromagnetic radiation interacts with a surface. The radiation arriving at a surface might be (a) reflected, (b) absorbed, (c) pass through, or (d) interact with the material and generate new radiation (fluorescence). We will consider each of these interactions in different sections of this book. Here, we describe some regularities in the surface spectral reflectance of many common materials.

A full description of surface spectral reflectance can include many parameters. The radiation incident on a small, planar patch of material can come from many different angles (two dimensions). The radiation may be reflected in many different directions (two more dimensions). The reflected light might be measured with respect to both wavelength and polarization (two more dimensions). We will set aside fluorescence for the present, returning to it later.

Despite this potential complexity, there are many relatively simple cases that are simpler to describe and still useful. Perhaps the simplest and most important are materials that reflected light equally in all directions, no matter what direction the light is coming from. Such materials have *diffuse reflectance*, also called *Lambertian reflectance*.

You can judge to what extent a material is diffuse if you have a laser pointer. Direct the laser pointer onto a planar surface patch and then move about, checking what the reflected light looks like as you view it from positions. In many cases, the reflected light appears pretty much as the same intensity as you move around. Also, you can change the position of the laser, but still illuminate the same point. For diffuse materials the reflected light will be about the same. These materials reflect diffusely because their surfaces have rough microscopic facets, oriented in many directions. When the incident light arrives, it may be reflected by facets oriented randomly, in many different directions.

::: {#Lambert .callout-note collapse="true" appearance="simple"}
## Johan Lambert

The term Lambertian surface honors the Swiss physicist, [Johann Lambert](https://en.wikipedia.org/wiki/Johann_Heinrich_Lambert) (1728-1777) who formalized the mathematical description. Many surfaces are modeled as Lambertian in computer graphics, or assumed to be Lambertian in computer vision estimates of the environment. Examples of materials with Lambertian reflectance include chalk, plaster, uncoated paper, matte paints made from pigments.

Adding additional details about the surface reflectance can improve the system performance, but it is common to start with a Lambertian approximation.

![Johann Lambert. His ideas were spread widely.](images/people/Lambert.png){#fig-lambert fig-align="center" width="180"}

Lambert worked on many topics concerning geometric optics, and he contributed an important book **Photometria** that incorporated many important geometric ideas, explaining the relative brightness of objects as seen from different points of view. Using his excellent mathematics, and the assumption that light travels in straight lines, he showed that illumination is - proportional to the strength of the source, - inversely proportional to - the square of the distance of the illuminated surface, and - the [sine of the angle](https://en.wikipedia.org/wiki/Lambert%27s_cosine_law "Lambert's cosine law") of inclination of the light's direction to that of the surface. He also wrote a classic work on [perspective](https://en.wikipedia.org/wiki/Perspective_(visual) "Perspective (visual)") and contributed to [geometrical optics](https://en.wikipedia.org/wiki/Geometrical_optics "Geometrical optics").

I was interested to learn that Lambert was the first to show that $\pi$ is an irrational number, a claim that the great Euler sought to prove as well.
:::

In the case of diffuse reflectance, we can summarize the material relatively simply. We only need to measure the fraction of incident light, for each wavelength, is reflected. This is called the spectral reflectance function

The spectral reflectance is measured wavelength-by-wavelength, that is they are functions of wavelength. In the visible band, these functions are typically quite smooth, and it is possible to summarize them using only a few parameters. It is not realistic to obtain a sample of all surfaces, but we might consider the surfaces in a particular context (e.g, walking in a forest, the interior of a commercial office building, driving on a highway, or medical images of the body). The likely surfaces in some context can be sampled and usefully summarized with a linear model [@Cohen1964-linearmodel, @Maloney1986-linearmodels-surface, @Hardeberg2002-reflectancedimensionalty]. The best basis functions will depend, somewhat, on the where you are measuring (forrest, desert, city, countryside). The number of basis functions needed will depend on the task requirements (e.g., 5% or 1% accuracy). But the general usefulness of a linear model approximation as a computational tool is not in doubt.

![Sample spectral reflectance functions of clothing. The fraction of reflected light, wavelength-by-wavelength, is between 0 and 1. Such smooth spectral reflectance curves are typical of many surfaces. Surfaces that are not diffuse can be modeled as having a diffuse component with a smooth spectral reflectance.](images/lightfields/01-reflectance-clothes.png){#fig-reflectance-cloths fig-align="center" width="60%"}

::: {#Things-stuff .callout-note collapse="true" appearance="simple"}
## Things and Stuff

We introduce the notion of surface reflectance as a general property, allowing that it depends on context. In an insightful paper, Ted Adelson further divided the environment into *things and stuff*" @Adelson2001-stuff. Things are the countable, discrete objects with defined shapes and boundaries (e.g., cars, chairs, animals). Stuff is amorphous materials or textures without fixed boundaries (e.g., water, grass, sky, sand). Dividing the environment into these categories also helps us set computational goals.

![Illustration of *things* and *stuff*. I am not sure how to count the grass - the collection of stuff or the blades of grass. Is the ocean stuff but a wave a thing? The sky, and beach (globally) seem like stuff. The rabbit and birds are definitely things, but their coats might be considered stuff. It is worth thinking about the difference. It is also worth noticing how Imagen3 produced some pretty odd animal faces.](images/paste-1.png){#fig-things-stuff fig-align="center" width="70%"}

For example, segmentation applies to *things* which are analyzed for object identity and function; in contrast, *stuff* is regionally based on texture and material properties. A great deal of computer vision focuses on tasks such as naming or counting cars on the road, people in the room, airplanes in the sky. We wish to be able to recognize such things whatever their material might be. A vision system must also be able to make judgments about a sandy beach, a cloudy sky, a grassy hillside. We wish to be able to recognize such stuff whatever its shape might be.

A related challenge in human vision is quantifying the appearance of things and stuff, and for this challenge surface reflectance, texture, and context (e.g., ambient illumination, or what is nearby) all play a role @Schmid2023-materialperception. Whether there is a corresponding concept - something we might call appearance for a computer vision system - is less studied. Perhaps the meaning of appearance for a computer vision system might be explained by its estimate of material reflectance and texture.
:::

Over the decades a number of imaging groups have measured the reflectance of many types of materials, including paints, minerals, plants, clothing, and various biological specimen such as skin and teeth. Government agencies, particularly those involved in remote sensing, have measured the reflectance of many materials that might be seen in satellite images. As a general rule, the spectral reflectances of the samples reported in the literature are approximated to an accuracy of a few percent by linear models using between 3 and 8 basis functions.

A Finnish group, for example, measured 1269 different color swatches from the Munsell Book of Colors. This widely used book spans a wide range of color samples that provides designers with a method for identifying, selecting, matching, and communicating about color. @Parkkinen1989-munsellspectra made their spectral measurements at 1 nm resolution. A linear model using three basis functions fits all the measurements with an error of about 2.5%. A linear model with 5 basis functions fits the data to within about 1%. This accuracy is usually often enough for image systems applications.

![Three basis functions for the Munsell Book of Color, from measurements by @Parkkinen1989-munsellspectra. The first linear model function is very close to the mean and is all positive. The 2nd and 3rd functions capture the principal variation in the samples. The three basis functions, calculated using the singular value decomposition, are orthogonal to one another. Notice the location of the zero-crossing of the 2nd function, which is near 560 nm, and the two zero-crossings of the 3rd function which are near 490 nm and 600 nm.](images/lightfields/01-munsell-basis.png){#fig-munsell-basis fig-align="center" width="60%" fig-cap-location="bottom"}

The linear models calculated for several types of common materials are often similar. This is illustrated in a set of measurements Vrhel and colleagues @Vrhel1994-MeasurementAnalysisObject. Their data, also included ISETCam, measures a few dozen surfaces from several different groups (paint, natural objects, man-made objects, food). It is likely the authors chose the samples to have similar means by insisting on a broad representation of color appearances. Had they chosen only the leaves in a forest, or only the rocks in the desert, the means might have differed. The properties of the 2nd and 3rd basis functions are also similar, and this is not likely to be a selection artifact. The measured spectral reflectance functions are relatively smooth with respect to wavelength, and thus the basis functions are smooth. The zero-crossings of these basis functions fall at locations that divide the visible spectrum into three, similar sections - bluish, greenish, and reddish.

![Three basis functions comparing the basis functions derived from the @Parkkinen1989-munsellspectra Munsell Color Book data (upper left) and three different categories measured by @Vrhel1994-MeasurementAnalysisObject. The basis functions are not identical, but they have many similarities, including the zero-crossings of the 2nd and 3rd basis functions.](images/lightfields/01-reflectance-bases.png){#fig-reflectance-bases fig-align="center" width="80%"}

```{=html}
<!-- 
Scripts to look over: s_surfaceMunsell, s_reflectanceBasis, s_sceneReflectanceChartBasisFunctions 
Maybe illustrate the visual size of the errors, as I have in other scripts.\
-->
```

### Dichromatic reflectance model (DRM)

The DRM is a useful surface reflectance model that is somewhat more complex than diffuse (Lambertian) materials, but simpler than a full reflectance model. This model is still used in computer vision applications where the user would like to identify specular reflections. The DRM is a good approximation for light reflected from **inhomogeneous dielectric materials** (non-conductors like plastics, paints, wood, skin, etc.). The model approximates reflectance as a weighted sum of a diffuse term and a mirror-like (specular) term.

The idea is that light is reflected by two mechanisms. Some of the light is reflected at the material's **interface** with air. This light does not interact with the material, and thus its spectral power is the approximately the same as the light source. Another portion of the light enters into the material (**subsurface**). In the subsurface it interacts with the material's pigments, both by scattering and absorption. The light that emerges from the subsurface determines the object's spectral reflectance. The subsurface portion is approximately Lambertian, as the subsurface pigments are randomly positioned and oriented.

The DRM represents the reflected light, $C(\lambda)$ as the sum of the interface and subsurface terms

$$
C(\lambda) = m_s(g) I(\lambda) E(\lambda) + m_d(g) D(\lambda) E(\lambda)
$$

Where, $E(\lambda)$, is the spectral power distribution of the light, $I(\lambda)$ is the interface spectral reflectance (often assumed to be constant across wavelengths). $D(\lambda)$ is the diffuse subsurface reflectance, which is characteristic of the material. The terms $m_s(g)$ and $m_d(g)$ are geometric scaling factors whose values depend on the illumination and viewing angle. These are typically represented with respect to the surface normal at the surface point $g$. The reflected light, $C(\lambda)$ is sometimes called the *color signal* because this spectral radiance is an important contributor to the visual system's color judgment.

The DRM finds application in topics such as illuminant estimation, specular highlight identification and removal, and material classification. It is, however, limited in various ways because it does not accurately model complex surfaces, and it does not apply well to scenes with multiple light sources or very large light sources, say spanning the sky.

### Bidrectional reflectance distribution function (BRDF) {#sec-properties-brdf}

An empirical description of the surface reflectance is called the *bidirectional reflectance distribution function* (BRDF). This characterizes how a light ray of wavelength $\lambda$ arriving at a point on the surface is reflected. The function specifies the intensity of reflected light from an incident ray at an angle $\omega_i$ with respect to the surface normal. The intensity of the reflected light is also specified at all angles $\omega_o$, with respect to the surface normal. These two directions (input and reflected) are why the measurement is bidirectional.

![Redraw, but like this:  Illustration of the two BRDF angle parameters. These are used to define both the angle of the incident light ray and the angle of the reflected light rays. If we fix the wavelength and angle of the incident light ray, we can specify the relative intensity of the reflected ray as an image that spans the two angle parameters.](images/lightfields/01-azimuthelevation-1.png){#fig-azimuth-elevation fig-align="center" width="50%"}

The input and output angles are 2-vectors that define the angle around the surface normal in the tangent plane (azimuth) $\phi_i, \phi_o$ and the angle elevation $\theta_i, \theta_o$ of the rays. Thus the BRDF is a scalar function. Given a light ray of unit intensity, incident at $\omega_i$, the output intensity at different angles $\omega_o$ will be given by

$$
f_r(\phi_i,\theta_i,\phi_o,\theta_o,\lambda) = f_r(\omega_i, \omega_o, \lambda)
$$

```{=html}
<!-- 
I created a Gemini document about data driven papers 
[Document on data-driven BRDFs](https://docs.google.com/document/d/1Wy2ygwu30i5quFX21kgz34OGSszNwUXn39Dfh4ypavA/edit?usp=sharing)

[Source for spherical azimuth and elevation and zenity.](https://www.researchgate.net/publication/334197029_A_new_model_for_reduction_of_Azimuth_asymmetry_biases_of_tropospheric_delay/figures?lo=1)

 -->
```

#### Data driven

There are papers measuring BRDFs and modeling them using linear models and nonlinear models. Data driven approach.

@Matusik2003-datadrivenBRDF @Tongbuasirilai2020-BRDF

There is a MERL database.

@MERL-BRDF-Brand

#### Theoretical

Cook Torrance mainly here.

```{=html}
<!--

Sand, reasonable figures. 

Tongbuasirilai2020-BRDF
 - https://opg.optica.org/ao/fulltext.cfm?uri=ao-54-31-F243&id=330097

Excellent source for material models and some simple formula of reflection.  Introduces dielectrics (Plastic, Stone, Wood, Leather, Glass, Water, Air), and conductors (metals)
https://leeyngdo.github.io/blog/computer-graphics/2024-03-22-reflection-model/?utm_source=chatgpt.com

Fermat's principle: light will follow the path that requires the least amount of time, as compared to other nearby paths, to pass between two points.

This web page has no graphs illustrating the microfacet theory from Ken Torrance and his students.  It has a nice introduction to the formulae for Cook Torrance, from Sparrow Torrance, as well.

-->
```

## Spatial regularities

Something about fractals. Textures. Other stuff.

### Natural scenes and the 1/f spatial frequency falloff

Who first pointed this out? Relationship to the scale invariant idea of fractals, and the fractal nature of many things.

Ruderman and Bialek paper on natural image statistics.

Field, Olshausen

David M - famous mathematician guy

### Natural scenes: The dead leaves model

Jon's Matlab script as a basis for discussing this.

Also, the deadleaves function in ISETCam.