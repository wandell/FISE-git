# Optics {#sec-optics}

A small enough pinhole renders a perfectly good image. Why do we need the additional complexity of optics? Further, while some animals have a visual system based on pinholes, the vast majority have evolved visual systems with a lens. Let's consider the advantages.

<!--# https://www.perplexity.ai/search/there-are-many-animals-that-ha-QJcp0_O_Ru6a0nVWEFkkmw  About tradeoffs between pinhole optics and lenses, particularly concerning biological systems. -->

The critical limitation of the pinhole is that it only lets in a **small** amount of electromagnetic radiation. I should tell you what I mean by small. I calculated how many photons per area per time are available through the pinhole[^optics-1-1]. Suppose we have a typical cell phone camera - pixel with a 1 micron pixel and a focal length of 3.9mm, and exposure duration of 50 milliseconds. In a dim room illuminated with a broad wavelength spectrum, only about 35 photons arrive at each pixel. Because of unavoidable photon noise, which I describe later, this signal permits us to reliably detect a 20% contrast edge. If we further divide up the wavelength range, because we want to measure in color, the situation worsens. A lens permits us to use a larger aperture to sense more photons from the same scene, and it does so while solving the problem of blur. No wonder so many species decided it was a good idea.

[^optics-1-1]: The script *s_sensorCountingPhotons.m in ISETCam* implements the calculation.

For the next few sections, we are going to stick with Newton and consider light as rays. This will help with the understanding, and it will also be approximately correct. We will fix up the calculations, accounting for the fact that the wave description really is more accurate, later.

## Refraction and Snell's Law

The pinhole doesn't change the ray paths. It achieves a sharp image formation by only letting through a small subset of the rays. When there is a lot of radiation, that's fine. But we can't use a purely rejectionist approach when the radiation is weak. In that case, we must find a way to use the rays that the pinhole would reject.

How do we redirect the rays to converge? A prism.

**FIGURE: Bending the rays**

## Thin lens approximations

How do you make a thin lens? Stack the prisms together, as in FOV.

F-number importance for thin lenses. Why it is the single, key parameter.

Lensmakerâ€™s equation derivation which is from Gauss and I think I teach as Psych 221 slides.

Notice that the object focal plane approaches a constant and stays near that level for a very large distance range.

Question of distance trading off with magnification for constant intensity per unit area with distance to the wall.

Magnification and Zoom. Depth of field formula. The sequence from class slides.

<!--# This link describes the issues in making a diffraction limited thin lens.  I think the problem is a flat sensor surfacewill not work with a spherical lens surface.  You need a aspheric.  It has other interesting facts.  To get close to diffraciton limited you need to use a multicomponent lens to correct for different aberrations.https://chatgpt.com/share/6748e5dc-267c-8002-844c-a83ee0cdb144 -->

## Thick lens approximations

Jensen and White has good text on this. I will look for text from other sources, such as Goodman. But there are some simplifications that should be mentioned, including the two focal lengths and two nodal points.

## Multielement lenses and the ABCD ray transfer matrix

Leads nicely into the Ray Transfer Function concept returns to the optical light field in previous

Maybe write a new ISETCam script with the ABCD implementation?

Double Gauss lens. Fish eye lens.

## Wavefront calculations

The ray transfer idea also leads to the wavefront representation.

Explain the Zernike polynomials as an approximation to the wavefront.

Apodization function for pupil shape can get introduced here.

Scratches and HDR rendering illustrated.

## Lens characterization methods

### Point spread and line spread functions

Shift invariant point spread.

Relationship between point spread and line spread. psf2lsf easy, but to go back you need to assume something about the circular symmetry.

### Chromatic aberration

Abbe concept. Human chromatic aberration.

### Optical Transfer Function

Relationship between OTF and PSF. Emphasis on this for a shift invariant, but not all possible cases. Local shift invariance is called aplanatic.

## Notes

I downloaded these slides. Some good concepts for this book. Overlaps a lot with my class, but additions. Link to PDF http://graphics.cs.cmu.edu/courses/15-463/2020_fall/lectures/lecture3.pdf