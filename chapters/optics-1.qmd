# Optics {#sec-optics}

An appropriately small pinhole renders a perfectly good image. Why do we need to add any optics? The critical reason is that pinhole cameras only measure a small amount of electromagnetic radiation. 

Let me tell you what I mean by **small**. Suppose we design a camera with a 1 mm pinhole[^optics-1-1] and a sensor with 1 micron pixels. Let's make the camera small, say a focal length of 4mm and an exposure duration of 50 milliseconds. In a dim room illuminated with a broad wavelength spectrum (10 $cd/m^2$), only about 35 photons arrive at each pixel. That's not a lot.  Worse yet, because of the unavoidable photon noise which I describe later, this signal only permits us to reliably detect an edge with a contrast difference of 20% (one edge is 20% brighter than the other).  If we want to see in color, we must further divide up the wavelength range and the situation worsens!

A lens is a way to enlarge the entrance aperture and acquire more photons. It does so without paying a big penalty in blur. This must be the reason why it evolved in so many different species.

::: {.callout-note collapse="true" title="Optics in animals"}
### Animals with pinhole optics {.unnumbered}
The most primitive are called 'pigment cup' eyes.  These animals have a small receptor surface is only about 0.1mm in diameter, and it is simply open.  The opening is a bit large to be considered a pinhole.  

The eyes of some animals, in particular mollusks, have more plausible pinhole architectures.  The receptor surface itself is 10 mm in diameter, and the opening is 0.4 - 2.8mm. These eyes evolved about 500 million years ago and have little changed.

A few animals species have a visual system based on pinholes. But the vast majority have evolved visual systems with a lens. 

<!--# https://www.perplexity.ai/search/there-are-many-animals-that-ha-QJcp0_O_Ru6a0nVWEFkkmw  Perplexity search about tradeoffs between pinhole optics and lenses, particularly concerning biological systems. -->

<!-- Details https://www.britannica.com/science/photoreception/Single-chambered-eyes Authored by Michael Land.  Detailed on optics and different species.  -->
:::

[^optics-1-1]: The script [fise_opticsCountingPhotons.mlx](https://htmlpreview.github.io/?https://github.com/wandell/FISE-git/blob/main/code/fise_opticsCountingPhotons.html)* implements the calculation. Use htmlpreview to link to it.

For the next few sections, we are going to stick with Newton and treat light as rays. This will help with the explanations, and is approximately correct. We will fix up the calculations, accounting for the fact that the wave description is more accurate, later.  The ISETCam calculations are based on waves.

## Refraction and Snell's Law
The blur we encounter as the pinhole size increases is because the rays are heading in different directions.  The pinhole achieves a sharp image formation by letting through a small subset of the rays. When there is a lot of radiation, that's fine. But we can't use a purely rejectionist approach when the radiation is weak; we must find a way to use the rays that the pinhole would reject.

How do we redirect the rays? Willebord Snellius () Get to the Snell's law here.

The simplest way is to have the rays pass from one medium to another. 

If the front surface is a sphere, we can't get the rays to converge properly with a single index of refraction.  Clerk Maxwell recognized this and he proposed that fish eyes, which are rather spherical, must have a different index of refraction as we march from on axis to the edge.  These types of lenses are called GRIN lenses for gradient index of refraction.  And it is true of fish eyes (and ours?)

Another way is to have the shape differ from a sphere.  That's what we do.

Calculations are easiest with a sphere, though.  To explain the principles we are going to do spherical lenses and single index of refraction for a while.

**FIGURE: Bending the rays**

## Thin lens approximations

How do you make a thin lens? Stack the prisms together, as in FOV.

F-number importance for thin lenses. Why it is the single, key parameter.

Lensmakerâ€™s equation derivation which is from Gauss and I think I teach as Psych 221 slides.

Notice that the object focal plane approaches a constant and stays near that level for a very large distance range.

Question of distance trading off with magnification for constant intensity per unit area with distance to the wall.

Magnification and Zoom. Depth of field formula. The sequence from class slides.

<!--# This link describes the issues in making a diffraction limited thin lens.  I think the problem is a flat sensor surfacewill not work with a spherical lens surface.  You need a aspheric.  It has other interesting facts.  To get close to diffraciton limited you need to use a multicomponent lens to correct for different aberrations.https://chatgpt.com/share/6748e5dc-267c-8002-844c-a83ee0cdb144 -->

## Thick lens approximations

Jensen and White has good text on this. I will look for text from other sources, such as Goodman. But there are some simplifications that should be mentioned, including the two focal lengths and two nodal points.

## Multielement lenses and the ABCD ray transfer matrix

Leads nicely into the Ray Transfer Function concept returns to the optical light field in previous

Maybe write a new ISETCam script with the ABCD implementation?

Double Gauss lens. Fish eye lens.

## Wavefront calculations

The ray transfer idea also leads to the wavefront representation.

Explain the Zernike polynomials as an approximation to the wavefront.

Apodization function for pupil shape can get introduced here.

Scratches and HDR rendering illustrated.

## Lens characterization methods

### Point spread and line spread functions

Shift invariant point spread.

Relationship between point spread and line spread. psf2lsf easy, but to go back you need to assume something about the circular symmetry.

### Chromatic aberration

Abbe concept. Human chromatic aberration.

### Optical Transfer Function

Relationship between OTF and PSF. Emphasis on this for a shift invariant, but not all possible cases. Local shift invariance is called aplanatic.

## Notes

I downloaded these slides. Some good concepts for this book. Overlaps a lot with my class, but additions. Link to PDF http://graphics.cs.cmu.edu/courses/15-463/2020_fall/lectures/lecture3.pdf