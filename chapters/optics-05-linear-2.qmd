# Image linear models {#sec-optics-image-linear-model}
It is natural to think of images as a set of points. It is far less obvious, and an important insight, to realize that an image can be described in many other ways. Some of these alternative ways are valuable for analyzing and characterizing optical performance of image systems.

Linear models are an important method for exploring alternative image representations. We introduced linear models in @sec-linear-models, and we applied them to characterizing the spectral properties of light fields. Here we use linear models again, but in a different way. We create model the image intensity spatial distribution, $I(x,y)$. The linear model we introduce is widely used to characterize the properties of an optical system. 

## Spatial basis functions

A linear model of the image intensity can be written this way:

$$
I(x,y) = \sum_{i} w_{i} B_{i}(x,y)
$${#eq-linear-model}

The functions $B_{i}(x,y)$ are the **spatial basis functions**, and the scalar values $w_{i}$ are the weights applied to each basis function. The image is equal to the weighted sum of these basis functions. 

When we represent an image as a set of points, the basis functions are points.  That is, $B_i$ is zero everywhere except except at one $(x,y)$ point.  The weights are the image intensity at that point, $I(x,y)$.

## Orthogonal image transforms
For a linear model to be useful, we need a method for finding the weights from the image. A function that maps $I(x,y)$ into the weights, $w_i$ is called an **image transform**.  If we choose a basis functions that are orthogonal to one another, the transform is easy to find.

$$
0 = \sum_{x,y} B_i (x,y) B_j (x,y),
$$ {#eq-spatial-orthogonal}

The simplicity of the transform can be seen by representing @eq-linear-model in discrete form an using matrices. Discrete representations using vectors and matrices is the way we compute, and thus a more practical if less pure.  To emphasize the discrete representation we will shift notation just a bit so that $I(x)$ becomes $I[n]$, and $B(x,y)$ becomes $B[n,m]$. 

We can convert the basis functions, which are matrices, into a column vector by stacking the columns on top of one another. We then group these columns into the columns of a single matrix, $\mathbf{B}$. We similarly stack the columns of the image into a long column vector $\mathbf{I}$.  The weights are already a vector which we write as, $\mathbf{w}$. 

We can write @eq-linear-model as a matrix equation this way

$$
\mathbf{I} = \mathbf{B w} .
$$ {#eq-linear-model-matrix}

The $i^{th}$ weight in the vector $\mathbf{w}$ multiples the $i^{th}$ column of the matrix $\mathbf{B}$.  All of these products are summed, and thus this matrix equation is the same as the @eq-linear-model.

When the basis functions are orthogonal, $\mathbf{B^t B}$ is the identity matrix.  This means we can transform from the image data to the weights quite simply,

$$
\mathbf{w} = \mathbf{B^t I} .
$$ {#eq-linear-model-inverse}

So, that's good.  Now, there are instances when we might make linear models that are not orthogonal.  In that case, we have to find the inverse of $\mathbf{B}$ to move back and forth between the image and its transform. Computers are pretty big these days, so we can live with that.  But it is very nice to have the basis functions be orthogonal.

Linear models are important for image systems and science and engineering broadly. Of the many linear models, having the bases be **harmonic functions** has been the most important. Let's review.

## Harmonics {#sec-optics-harmonics}
For real-valued signals - such as light intensity - the harmonic functions are the *Sine* and *Cosine*. You probably first learned about *Sine* and *Cosine* as one-dimensional functions -they take a single number in and produce a single number out. But in image systems applications we we use Sine and Cosine to represent two-dimensional images,

$$
I(x,y) = M(1 + A sin(2\pi f_x x + \phi_x + 2 \pi f_y y + \phi_y)) .
$${#eq-harmonics-2d}

The mean of the harmonic is $M$, and the **contrast** is $A$. Because image intensities are always non-negative, the value of $A$ for any realizable image must be within the range $[-1 1]$. @fig-optics-harmonics-2d shows four **image harmonics**. When both $f_x$ and $f_y$ are non-zero, the image is oriented[^spatial-frequency].

[^spatial-frequency]:  Different fields use somewhat different terminology and approximations to this one-dimensional gratings.  Vision scientists typically call these images **spatial frequency gratings**.  Engineers often approximate the sinusoidal intensity patterns using evenly spaced bars or sometimes even lines. It is likely more than one person will complain to me that I chose to describe them as harmonics.  Oh well.

![Harmonic images. These have different $f_x$ and $f_y$ values, but all have contrast $A=1$. The image is vertical if $f_y = 0$ and horizontal if $f_x = 0$](images/optics/optics-harmonics.png){#fig-optics-harmonics-2d width="80%"}

We can develop many of the principles of linear models using one-dimensional harmonic images, like the images in @fig-optics-harmonics-1d. These harmonics have different spatial frequencies $f_x$ and a range of contrasts $A$. They are one-dimensional because I set $f_y = 0$.

![These one-dimensional harmonics are of the form in @eq-harmonics-2d, but simplified so that $\phi_x = \phi_y = f_y = 0$. The contrast $A$ varyies from the top to bottom row $(1, 0.5, 0.1)$.  The x-range is $(0,1)$, and the frequencies are $f_x = (1,2,4,8)$](images/optics/optics-harmonics-1d.png){#fig-optics-harmonics-1d width="60%"}

### Lines from harmonics
Around 1805, **Jean Baptiste Joseph Fourier** discovered that most of the functions we encounter in daily life can be expressed as the weighted sum of harmonics. This surprised, or perhaps annoyed, the mathematicians of the French academy [see the historical note](#fourier-history). 

To many people it is counterintuitive that a thin line can be constructed by summing harmonics, each of which extends across the entire image. How does the combination of these broad functions result in a localized feature like a line? 

@fig-optics-reconstruction provides insight into this process. The figure shows how the image evolves as we sum increasing numbers of harmonics: starting with just a few, the result is broad and diffuse, but as more harmonics are added, the image becomes increasingly concentrated. The key is that the positive and negative regions of the harmonics cancel each other out everywhere except at the center, where all the cosine terms are positive ($\cos(0)$). With enough harmonics, the sum converges to a single, sharp line.

In this example, we reconstruct a line at the center (column 65) of a 129-column image by setting all harmonic weights to $w_f = 1$. Because the target image is even symmetric, only the cosine terms are needed. The red traces in the figure show the intensity profile: as more harmonics are added, the central peak narrows and side ripples diminish. By the 64th harmonic, the line is well-formed; adding more harmonics briefly reintroduces some ringing, which disappears when the full set is included. This phenomenon is a classic result in linear systems—ask your instructor for more details!

![Summing harmonics to become a line. The panels show the sum of the first 4, 16, 64, 72, and finally all 128 harmonics. To match a single line in the middle (col=65) of this 129 column image, the weights of each harmonic are all $w_f = 1$. Because the image is even symmetric, we need to sum only the $cos()$ terms. The red traces superimposed on the images are the intensity. The central region becomes thinner and the ripples on the side are eliminated by the 64th harmonic.  They return as we keep going to f = 72, but are eliminated again at f=128.  Ask your linear systems instructor about this; s/he will like you for it.](images/optics/optics-reconstruction.png){#fig-optics-reconstruction width="100%"}

::: {.callout-note collapse="true" title="Line reconstruction: the movie"}
This movie illustrates how the sum converges as harmonics are added one by one. Initially, the harmonics are distributed across the image. As more are included, their contributions cancel everywhere except at the central position ($0$), where all are positive ($\cos(0)$). 

Adding harmonics from $f=0$ to $f=64$ produces the line; adding $f=65$ to $f=128$ introduces some ringing, which is eliminated when the sum is complete. This is a special case for even symmetric functions, where only cosines are required.

![A line reconstructed by adding many harmonics at different frequencies. ](images/optics/lineReconstruct.mp4){#fig-optics-reconstruction-movie width="60%" fig-align="center"}

:::

### Discrete Fourier Series
The **Fourier series** represents functions as sums of harmonics. The Fourier series can be written in several equivalent forms. What follows are three common representations. 

In these formulae, rather than using $I(x)$, which implies $x$ is a continuous variable, we use $I[n]$ to signify that we are sampling at discrete points. For that reason, these formulae represent the **Discrete Fourier series**

**1. Sine and Cosine Form**

$$
I[n] = \frac{a_0}{2} + \sum_{f=0}^{N-1}  s_f \sin(2 \pi f n ) + c_f \cos(2 \pi f n)
$$ {#eq-fourier-series}

**2. Amplitude and Phase Form**

$$
I[n] = \frac{a_0}{2} + \sum_{f=0}^{N-1}  a_f \sin(2 \pi f n + \phi_f)
$$ {#eq-fourier-series-phase}

**3. Complex Exponential Form**

$$
I[n] = \sum_{f=0}^{N-1} w_f \, e^{i 2 \pi f n / N}
$$

where $w_f$ are complex numbers ($i = \sqrt{-1}$).

### Calculating the weights: Discrete Fourier transform
To analyze images using the Discrete Fourier Series, we need a way to transform the sampled image intensities, $I[n]$, into the Fourier weights, $w_f$. The most common method is the **Discrete Fourier Transform (DFT)**:
$$
w_f = \frac{1}{N} \sum_{n=0}^{N-1} I[n] \, e^{-i 2 \pi f n / N}
$$ {#eq-discrete-fourier-transform}

At first glance, this formula might look intimidating, but it's actually quite elegant. On the right, we have the sampled image values multiplied by a complex exponential. Thanks to **Euler's formula**, we know that any complex exponential can be written in terms of sine and cosine:

$$
e^{i\theta} = \cos(\theta) + i\sin(\theta).
$$ {#eq-Eulers-formula}

This means the DFT is really just combining the familiar sine and cosine terms into a single, compact expression using complex numbers. Many people find this complex formulation neater than keeping track of separate sine and cosine coefficients.

It's important to note that while $I[n]$ is real-valued, the DFT coefficients $w_f$ are generally complex. For a real signal, there is redundancy: the coefficients satisfy $w_{f} = \overline{w_{N-f}}$, where $\overline{w_f}$ is the complex conjugate of $w_f$.[^dft-coefficients]

[^dft-coefficients]:  The complex conjugate of $a + i b$ is $a - i b$.

If you prefer to work with real numbers, you can compute the sine and cosine coefficients, $s_f$ and $c_f$, directly from the image intensities:

$$
\begin{align}
a_0 &= \frac{2}{N} \sum_{n=0}^{N-1} I[n] \\
s_f &= \frac{2}{N} \sum_{n=0}^{N-1} I[n] \sin\left(\frac{2\pi f n}{N}\right) \\
c_f &= \frac{2}{N} \sum_{n=0}^{N-1} I[n] \cos\left(\frac{2\pi f n}{N}\right)
\end{align}
$$

Here, $a_0$ gives twice the mean value of $I[n]$, which is why the Discrete Fourier Series (@eq-fourier-series) starts with $\frac{a_0}{2}$.

### Relating the representations

There are several equivalent ways to write the Discrete Fourier Series, and it's helpful to know how the parameters relate:

- $\frac{a_0}{2}$ and $w_0$ both represent the mean value of the signal $I[n]$.

- The amplitude and phase parameters relate to the sine and cosine coefficients as follows:

$$
\begin{align}
a_f & = \sqrt{{s_f}^2 + {c_f}^2} \\
\phi_f & = \arctan\left(\frac{c_f}{s_f}\right)
\end{align}
$$

- The complex weights $w_f$ are related to the sine and cosine coefficients by

$$
w_f  = \frac{1}{2} (c_f - i s_f ) \qquad \text{for } f > 0
$$

- And the complex weights $w_f$ are related to the amplitude and phase by

$$
w_f = \frac{a_f}{2} e^{i (\phi_f - \pi/2)} \qquad \text{for } f > 0
$$

So, whether you prefer to think in terms of sines and cosines, amplitudes and phases, or complex exponentials, you can always translate between these forms.

::: {.callout-note title="About Jean Baptiste Joseph Fourier" collapse="false" #fourier-history}
Here is a link to a nice website with a  <a href="https://mathshistory.st-andrews.ac.uk/Biographies/Fourier/" target="_blank">biography of Fourier and many others</a> . The material below is extracted from that site and wikipedia.

:::{.columns}

::: {.column width="50%"}
- Son of a tailor
- Orphaned at 9
- Educated by Benedictines
- Promoted the French Revolution
- Accompanied Bonaparte as scientific adviser to Egypt
- Appointed Governor near Grenoble
- A statue of Fourier, in Grenoble, was melted down for armaments!
:::

::: {.column width="50%"}
![Jean Baptiste Joseph Fourier](images/optics/optics-fourier.png){#fig-optics-fourier width="80%"}
:::
:::

While serving as Governor in Grenoble, Fourier made his major mathematical contributions to the theory of heat. He began this work around 1804, and by 1807 had completed his influential memoir, "On the Propagation of Heat in Solid Bodies." Fourier presented this memoir to the Paris Institute on December 21, 1807, where a committee of prominent mathematicians—Lagrange, Laplace, Monge, and Lacroix—was assigned to review it. Although the memoir is now highly regarded, it was controversial at the time.

The committee had two main concerns. First, Lagrange and Laplace objected to Fourier's use of trigonometric series to expand functions—what we now call Fourier series. Despite further explanations from Fourier, they remained unconvinced. As noted by J. Herivel in his biography of Fourier:

> All these are written with such exemplary clarity—from a logical as opposed to calligraphic point of view—that their inability to persuade Laplace and Lagrange ... provides a good index of the originality of Fourier's views.

Second, Biot criticized Fourier's derivation of the equations for heat transfer, noting that Fourier did not reference Biot's 1804 paper on the topic. However, Biot's paper was later shown to be incorrect. Laplace and Poisson also raised similar objections.

In 1811, the Institute announced a prize competition on the propagation of heat in solid bodies. Fourier submitted his 1807 memoir along with additional work on the cooling of infinite solids and on terrestrial and radiant heat. Only one other entry was received. The prize committee—Lagrange, Laplace, Malus, Haüy, and Legendre—awarded Fourier the prize.

However, their report was mixed, stating: “... the manner in which the author arrives at these equations is not exempt of difficulties and that his analysis to integrate them still leaves something to be desired on the score of generality and even rigour.” As a result, there was no immediate move in Paris to publish Fourier's work.
:::




