# Sensors {#sec-sensors}
Up to now we have been considering the properties of the CMOS imager, one pixel at a time.  In this section we consider the entire array of pixels, including factors such variations between pixels, the color filter array, and the microlens array.  Once we have established the basic sensor properties, we spend some time discussing recent innovations in the pixel and sensor circuitry.  This is an active field and I view this section as a guide to lead you into some of the new developments.  The book itself, is about Foundations, so hold me responsible for that.

## Sensor noise
Just as there are factors that introduce noise into the pixel readouts, so too there are factors that introduce unwanted features in the sensor as a whole. For example, when manufacturing arrays of millions of pixels, it is possible that there are minor differences between the circuits themselves: the size of the photodiode might vary by one percent, the capacitance on the floating diffusion node might vary ever so slightly from pixel to pixel, the material doping might vary.  

These fluctuations across the array are considered to be **sensor noise**.  Because these variations do not change over time, they are called **fixed pattern noise (FPN)**. They are variations that are meaningful across the sensor array. Here are the two main types of fixed pattern noise.

### Dark signal nonuniformity
DSNU dark signal nonuniformity

### Photoresponse nonuniformity
PRNU photoresponse nonuniformity

In addition to the photodiode and underlying circuitry, CMOS image sensors incorporate several crucial optical components that play a vital role in capturing high-quality images. These elements -color filter arrays and microlens arrays- are engineered to enhance light collection and enable accurate color reproduction, making them essential for modern imaging performance.

![The color filter array and microlens array above the photodiode array. Not sure where.  Lookup.](images/sensors/03-components-overview1.png){#fig-components-overview width=50%}

To make a color image, sensors use a color filter array (CFA) placed above the photodiodes. Since a photodiode alone cannot distinguish between different wavelengths, the CFA ensures that each pixel is sensitive to a specific spectral band. The most common CFA pattern is the Bayer arrangement, which uses red, green, and blue filters distributed across the sensor. This allows the sensor to sample the visible spectrum at different locations, and the resulting data can be combined to reconstruct a full-color image. Some sensors use alternative filter patterns or additional spectral bands for specialized applications. Together, microlens arrays and color filter arrays are essential for the function and versatility of modern digital cameras.

The original sensors were  built using a technology that required stacking multiple metal layers above the substrate that contained the photodiode. This architecture, called front-side illuminated (FSI), required photons incident at the pixel to make their way down a tunnel to arrive at the light sensitive photodiode. With this architecture, photons incident at an angle This  shown 

![The improved design, Backside Illuminated (BSI) CMOS, is similar in concept to regular CMOS, but these chips arrange the components differently. In short, the photosites are further forward on the die and the line-by-line readout speed is brisker. This change enables practical advantages: Generally speaking, a BSI CMOS is around an f-stop better when it comes to image noise. That means a BSI CMOS shows as much noise at ISO 12800 as a similar CMOS chip would at ISO 6400. It also means that APS-C and Micro Four Thirds cameras with BSI chips play on more even footing with full-frame CMOS cameras. Those aren't hard-and-fast rules, but they're good guidelines to follow. Stacked CMOS chips improve upon the BSI CMOS concept. They place components in a similar arrangement, but the design also stacks the image signal processor and its ultra-fast DRAM memory into the same silicon. This makes readout speeds even faster. The first mainstream Stacked CMOS camera, the Sony a9 from 2019, made waves by offering an interruption-free photographic experience—you can use it to fire off photos at 20fps without losing view of your scene.](images/sensors/03-sensor-evolution.png){#fig-sensor-evolution width=80%}

<!--# https://www.pcmag.com/how-to/whats-the-difference-between-cmos-bsi-cmos-and-stacked-cmos -->

![The color filter array and microlens array above the photodiode array. From the El Gamal and Eltoukhy article](images/sensors/03-microlens-cfa.png){#fig-components-overview2 width=50%}

The microlens array is a layer of tiny lenses placed above the color filter array. Each microlens is precisely positioned relative to the main lens, color filter, and photodiode. It serves to focus incoming light from the main lens onto the photodiode within the pixel. The microlens increases light-gathering efficiency, which is especially important as pixel sizes shrink. It also prevents cross-talk, a condition in which light passes at a large angle through a color filter and ends up generating electrons in a pixel that has a different color filter. Over time, microlens arrays have evolved to support additional functions, such as optimizing focus and enabling advanced imaging techniques like light field capture.

### Color filter array


### Microlens arrays

Light field possibility.

## Circuit innovations {#sec-sensor-innovations}
Over time, as technology has scaled, more complex electrical circuitry has been placed on the sensor. Modern image sensors frequently include circuitry that performs local processing to increase the dynamic range of the sensor (well recycling), or to reduce the intrinsic noise (correlated double sampling). Some of this processing is *adaptive*, that is the circuit actions depend on the property of the input image. Consequently, the sensor output can depend upon both the control parameters set by the user and the image content.

### Global shutter
Instead of using a floating diffusion as a memory element, Aptina has utilized a surface-pinned storage node in the pixel to address dark current challenges. Available in its newest global shutter sensor, the MT9M031, the storage node also enables using a true correlated double sampling technique to reduce readout noise to four electrons, resulting in excellent low-light performance. The combination of the effective use of an anti-reflective metal light shield in close proximity to the memory node and careful doping and potential profile design results in a high GSE.

Global Shutter Pixel Technologies and CMOS Image Sensors – A Powerful Combination – (Aptina white paper)


### Stacked pixel structures

### Dynamic range enhancement
Another source of nonlinearity arises from the photodiode itself. At high irradiance levels, the photodiode can saturate, meaning that it cannot generate additional electrons regardless of the incoming light. This saturation effect imposes a hard limit on the dynamic range of the sensor.

Understanding and modeling these nonlinearities is critical for applications that require high precision, such as scientific imaging or computational photography. Calibration techniques, such as measuring the sensor response under controlled conditions, can help correct for these nonlinearities in post-processing.

### Color technologies

#### Foveon {#sec-sensors-foveon}

#### Multipsectral {#sec-sensors-spectricity}



