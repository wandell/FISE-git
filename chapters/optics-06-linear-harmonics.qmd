# Linear optics - harmonics {#sec-optics-linear-harmonics}
We have mainly been analyzingd optical systems using point-based stimuli (impulses and point spread functions). This is one of many useful signal representations (@sec-appendix-linear-systems, ). In this section, we introduce a second class of stimuli: image harmonics. These stimuli are commonly used in the image systems engineering literature for both theory and measurement. They provide a valuable and insightful approach to measuring how image systems behave.

There are two practical motivations for considering alternative stimuli. First, point stimuli are not convenient tool for predicting how finely a system can resolve detail; the spatial resolution of an image system is often easier to analyze using harmonics. Second, point stimuli are photon-inefficient and thus difficult to measure precisely. Extended harmonic targets deliver more light, produce higher signal-to-noise measurements, and allow precise control of spatial frequency, orientation, and phase.

The next sections define image harmonics and show how to use them to characterize system performance. The mathematical foundations underpinning this representation appear in @sec-appendix-linear-systems. In brief: for linear, shift-invariant systems, harmonics form a spatial basis for arbitrary stimuli (@sec-ls-spatial-basis) and are nearly eigenfunctions of the system (@sec-ls-eigenfunctions). These properties make harmonics especially valuable for analysis and design.

## Image harmonics {#sec-optics-harmonics}
For real-valued signals —such as light intensity— the harmonics are built upon the sine and cosine functions. You likely first met these as one-dimensional functions: they take a single input and produce a single output that varies from $[-1,1]$.

$$
I(x) = \sin(2\pi f_x x + \phi_x)
$${#eq-harmonics-1d}

Here, $f_x$ is the spatial frequency (in cycles per unit distance) and $\phi_x$ is the phase (a spatial shift).  Image intensities are positive numbers, so to model them with harmonics we add $1$ to the value.

$$
I(x) = 1 + \sin(2\pi f_x x + \phi_x)
$${#eq-harmonics-1d-v2}

In imaging, we typically need a two-dimensional representation to describe variation across both $x$ and $y$. A useful form that keeps intensities non-negative and includes two dimensions is

$$
I(x,y) = M\big(1 + A \sin(2\pi f_x x + \phi_x + 2\pi f_y y + \phi_y)\big).
$${#eq-harmonics-2d}

- $M$ is the mean (DC) intensity.
- $A$ is the contrast or modulation depth. To ensure $I(x,y) \ge 0$, we require $|A| \le 1$. In practice, we often take $A \in [0,1]$ and absorb any sign into the phase.
- The pair $(f_x, f_y)$ is the 2D spatial frequency. When both are nonzero, the pattern has an orientation; the bars are perpendicular to the vector $(f_x, f_y)$, with angle $\theta = \mathrm{atan2}(f_y, f_x)$.

@fig-optics-harmonics-2d shows four image harmonics. When $f_y = 0$ the pattern is vertical (varies only along $x$); when $f_x = 0$ it is horizontal (varies only along $y$).[^spatial-frequency]

[^spatial-frequency]: Different fields use different terminology. Vision scientists often call these spatial frequency gratings. Engineers sometimes approximate sinusoidal patterns with evenly spaced bars or lines. We use the term harmonics.

![Harmonic images. These have different $f_x$ and $f_y$ values, but all have contrast $A=1$. The image is vertical if $f_y = 0$ and horizontal if $f_x = 0$.](images/optics/optics-harmonics.png){#fig-optics-harmonics-2d width="80%"}

For many linear-systems analyses, say when the system is circularly symmetric, it is enough to consider one-dimensional harmonics by fixing $f_y = 0$. The examples in @fig-optics-harmonics-1d vary only along $x$ and illustrate different spatial frequencies $f_x$ and contrasts $A$.

![A set of one-dimensional image harmonics. They vary in $x$ with $f_y = 0$. The contrast $A$ varies from top to bottom $(1, 0.5, 0.1)$. The $x$-range is $(0,1)$, and the spatial frequencies are $f_x = (1, 2, 4, 8)$.](images/optics/optics-harmonics-1d.png){#fig-optics-harmonics-1d width="60%"}

## Harmonics and lines {#eq-optics-harmonics-lines}
To many people it is counterintuitive that a thin line can be constructed by summing harmonics. The line is very compact, but each harmonic extends across the entire image. How can the sum of these harmonics functions result in such a localized image?

@fig-optics-reconstruction shows how the image evolves as we sum increasing numbers of harmonics: Starting with just a few, the result is broad and diffuse, but as more harmonics are added, the image becomes increasingly concentrated. The key is that the positive and negative regions of the higher frequency harmonics cancel each other out everywhere except at the center, where all the cosine terms are positive ($\cos(0)$). With enough harmonics, the sum converges to a single, sharp line.

In this example, we reconstruct a line at the center (column 65) of a 129-column image by setting all harmonic weights to $w_f = 1$. Because the target image is even symmetric, only the cosine terms are needed. The red traces in the figure show the intensity profile: as more harmonics are added, the central peak narrows and side ripples diminish. By the 64th harmonic, the line is well-formed; adding more harmonics briefly reintroduces some ringing, which disappears when the full set is included. This phenomenon is a classic result in linear systems—ask your instructor for more details!

![Summing harmonics to become a line. The panels show the sum of the first 4, 16, 64, 72, and finally all 128 harmonics. To match a single line in the middle (col=65) of this 129 column image, the weights of each harmonic are all $w_f = 1$. Because the image is even symmetric, we need to sum only the $cos()$ terms. The red traces superimposed on the images are the intensity. The central region becomes thinner and the ripples on the side are eliminated by the 64th harmonic.  They return as we keep going to f = 72, but are eliminated again at f=128.  Ask your linear systems instructor about this; s/he will like you for it.](images/optics/optics-reconstruction.png){#fig-optics-reconstruction width="100%"}

::: {.callout-note collapse="false" title="Line reconstruction: the movie"}
This movie illustrates how the sum converges as harmonics are added one by one. Initially, the harmonics are distributed across the image. As more are included, their contributions cancel everywhere except at the central position ($0$), where all are positive ($\cos(0)$). 

Adding harmonics from $f=0$ to $f=64$ produces the line; adding $f=65$ to $f=128$ introduces some ringing, which is eliminated when the sum is complete. This is a special case for even symmetric functions, where only cosines are required.

![A line reconstructed by adding many harmonics at different frequencies. ](images/optics/lineReconstruct.mp4){#fig-optics-reconstruction-movie width="60%" fig-align="center"}

:::

## Harmonic characterization {#sec-optics-characterization}
There are many reasons why people would like to describe the quality of an optical system.  Commercial vendors that sell parts may need to specify the quality and the tolerance of the quality measure.  We may want to optimize the properties of a design, using the image quality measure as a metric for the optimization.  We may wish to simulate the system and learn which signals are preserved by the optics and which are lost to image quality.

The point spread function characterizes the system using many values measured from a single stimulus. The harmonic characterization uses only two parameters, but from multiple stimuli (@fig-optics-harmonic-eigen).  For each harmonic frequency, we measure how much its amplitude is scaled, $s_f$, and how much the image has been shifted $\delta_f$.

![A shift invariant linear system transforms a one-dimensional image harmonic by a scale factor and a shift.  ](images/optics/harmonics-eigen.png){#fig-optics-harmonic-eigen width=70%}

## Transfer Functions {#sec-optics-transfer-function}

### Optical Transfer Function {#sec-OTF}

The **optical transfer function (OTF)** represents the full effect, both amplitude and phase, of a shift-invariant image system.  The scale factor is a real-value, and the shift (in radians) is in the exponent of the complex exponential

$$
OTF(f) = s_f ~ e^{-i \delta_f}
$$ {#eq-otf-definition}

The complex representation is immediately useful because to calculate how an image, $I(x)$, is transformed to its output, $O(x)$. We express the image using its Fourier representation $\mathscr{F}(I(x))$. Then we multiply the Fourier representation by the OTF. Finally, we use the inverse Fourier transform to express the result into spatial coordinates.

$$
O(x) = \mathscr{F}^{-1}(\mathscr{F}(I(x))~OTF(f))
$$ {#eq-otf-calculation}

The OTF contains all of the information needed to describe the how the shift invariant linear system transforms the image, just as the point spread function does.

### Modulation Transfer Function {#sec-MTF}
Perhaps the most common use of the harmonic analysis is the **modulation transfer function (MTF)**.  The MTF(f) is the scale factors, $s_f$. 

$$
MTF(\mathbf{f}) = \left| OTF(\mathbf{f}) \right| = \left| s_f ~ e^{-i \delta_f} \right|  = s_f
$$ {#eq-MTF-defined}

 It is quite common for systems to have very little phase shift, $\delta_f \approx 0$.  In that case, the OTF is simply $s_f$, which is also the MTF.  This approximation may be good enough for a simulation.

### Contrast Sensitivity Function {#sec-CSF}

## Local shift-invariance 

Say stuff about how they apply to isoplanatic regions (shift-invariant) but not to the image as a whole. 

The point spread depends on parameters such as the pupil aperture, which often changes as people adjust for light level.  Hence, it is not always possible to have a unique point spread for a point.

It is tough, by the way, to have depth dependent point spreads and to interpolate between point spreads.

What else?

## More examples

Slides from class for inspiration here. Define the MTF and the OTF.
Start an image of the 2D FFT amplitude, perhaps.  

Get to image representations of the harmonic images, and then images more broadly.

Parts of the Fourier representation (center, edges, and so forth)

High frequency fall off.

Develop the ISO 12233 standard, relating edges and MTF50

Illustrate aliasing for the whole system?  Even if we aren't through the image sensor?

Separability for 2D might be good.  Not sure which formulae to add.


:::{.callout-note title='2D Fourier Transforms' collapse='false'}
Bracewell and Goodman for introducing the 2D Fourier transform for image applications.

[Link to Google resource.](resources/history-2D-fourier-transform.html){target=_blank}

:::






