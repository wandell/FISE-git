# Circuits {#sec-sensors-circuits}

CMOS image sensors use a photodiode—and the photoelectric effect—to measure and store the optical light field at the sensor surface. The key technical breakthrough that enabled CMOS sensors was the integration of circuitry that stores and transmits the accumulated charge (number of electrons) from the photodiode to the computer. We can think of the photodiode and its local circuitry as a pixel. The logical flow of the circuitry is as follows:

-   Before image capture, the circuitry resets each pixel to clear any residual charge from previous exposures.
-   During image acquisition, the photodiode array collects electrons generated by incoming light; these electrons are stored within the photodiode or in a nearby capacitor.
-   During readout, the circuitry transfers the stored charge to an analog-to-digital converter (ADC), where it is converted to a digital value.
-   The resulting digital image array records the amount of light captured by each pixel.

CMOS circuitry is the main focus of this section (@sec-sensors-circuits). Most CMOS image sensors also include essential components such as color filter arrays and microlenses, which redirect light from the main lens onto each photodiode within the pixel, and these components are introduced in @sec-sensors-components. Section @sec-sensors-characterization uses describes how to characterize and model sensor performance, from the scene light field to image capture.

## 3T circuitry

![The original CMOS 3-transistor (3T) circuit design (@Fossum1997-early).](images/sensors/03-3T-circuit.png){#fig-sensor-3T-circuit}

The original CMOS pixel design uses a three-transistor (3T) circuit to store and read out the charge collected by the photodiode (@fig-sensor). Each pixel contains three key transistors: $M_{rst}$ (reset), $M_{sel}$ (select), and $M_{sf}$ (source follower). The $M_{rst}$ transistor resets the photodiode by connecting it to the supply voltage (Vdd), clearing any residual charge before image capture. The $M_{sel}$ transistor selects a specific row of pixels, connecting them to the readout circuitry. The $M_{sf}$ transistor acts as a buffer, transferring the stored charge to the analog-to-digital converter (ADC) for measurement. In most sensors, each column has its own ADC, but some designs use a single ADC shared among multiple columns—a technique known as multiplexing (mux).

Ideally, the photodiode’s response to light is linear, with the number of generated electrons following Poisson statistics. However, the surrounding circuitry introduces additional sources of noise and nonlinearity. For example, the storage capacitor has a limited capacity, so it can saturate at high light levels. The transistors used for readout can also introduce noise and small nonlinearities. Furthermore, variations in pixel properties across the sensor array can cause fixed-pattern noise. In modern CMOS sensors, these nonlinearities and noise sources are typically small—on the order of a few percent @Wang2017-CMOSLinearity—but they can still affect image quality. Careful characterization and calibration are necessary to minimize these effects and produce high-quality images.

```{=html}
<!-- 
 (http://encyclopedia2.thefreedictionary.com/Vdd also the drain voltage), Vrst is the reset voltage Vee is the negative supply voltage Ground is ground
http://en.wikipedia.org/wiki/Active_pixel_sensor , http://encyclobeamia.solarbotics.net/articles/vxx.html , 
http://en.wikipedia.org/wiki/Active_pixel_sensor , http://encyclobeamia.solarbotics.net/articles/vxx.html , 
Vdd is positive supply voltage  (http://encyclopedia2.thefreedictionary.com/Vdd also the drain voltage), Vrst is the reset voltage Vee is the negative supply voltage Ground is ground
-->
```

## 4T circuitry

![The 4T pixel circuit introduces a pinned photodiode and an additional transistor. When activated, the new transistor transfers the accumulated charge from the photodiode to a storage capacitor (the floating diffusion node, $C_{fd}$). The rest of the circuit, including readout and row select, is similar to the 3T design.](images/sensors/03-4T-circuit.png){#fig-sensor-4T-circuit}

Since about 2000, most CMOS image sensors have moved from the three-transistor (3T) pixel design to the four-transistor (4T) pixel circuit [@Fossum2014-pinnedpd]. The 4T pixel adds two important features: a pinned photodiode (PPD) and a transfer gate transistor (@fig-sensor-4T-circuit). The pinned photodiode improves charge storage and reduces noise, while the transfer gate allows precise movement of the collected charge from the photodiode to a storage node called the floating diffusion, which has a capacitance $C_{fd}$. The other circuit elements—reset, row select, and source follower—remain the same as in the 3T design.

The transfer gate and floating diffusion give the circuit better control over when and how charge is transferred and measured, which helps reduce noise and improve image quality.

Today, the 4T pixel is the standard in almost all high-performance CMOS image sensors, including those found in smartphones, industrial cameras, cars, and scientific instruments.

<!--
There is also Theuwissen diagram, with five transistors that he calls a 4T circuit.  In the paper 'Linearity analysis ...' @Wang2017-CMOSLinearity.  He says the source follower is shared by multiple rows of pixels. It is Figure 2.  

The text: "Figure 2 shows the schematic of a typical voltage mode 4T pixel. The pixel circuit consists of a pinned photodiode, a charge
transfer switch (M1), a reset switch (M2), a source follower (M3) and a row select switch (M4). The current source transistor (M5) is shared by multiple rows of pixels. VDD is the power supply while VPIX is the output voltage of pixel. VLN provides an adjustable bias current. In the following analysis, the nonlinearity caused by the row select transistor (M4) is omitted to simplify the analysis."
-->

The 4T design offers several key advantages over the earlier 3T architecture. Most notably, it enables correlated double sampling (CDS), which significantly reduces reset noise (also known as $kTC$ noise). In the 4T pixel, the circuit first measures the voltage on the floating diffusion node before transferring charge from the photodiode (capturing a baseline), and then again after the charge is transferred. The difference between these two measurements represents the pixel signal. This subtraction cancels much of the noise introduced during the reset phase, improving signal-to-noise ratio.

Further improvements in materials and circuit architecture have led to even lower noise and higher quantum efficiency. Additional innovations, such as dual conversion gain and advanced pixel structures, have also expanded the dynamic range of CMOS sensors. We will explore some of these developments after reviewing the basic pixel circuit and other key sensor components.

## Circuit properties and parameters
Simulations of the CMOS circuitry can -and do- become very complex during the design phase. Engineers use specialized software that incorporates the foundry's design rules that account for material properties and feature sizes. This design software helps circuit designers achieve a working system from the foundry.

After the chip is built, it is impractical to characterize each different line, device and junction. Designers may place certain test circuits within the chip.  But more generally systems are evaluated with respect to a set of objective measurements using images as input and digital values of output.  This process is called called **system characterization** or **system calibration**. The characterization measurements specify the limitations of system performance, including light sensitivity, system noise, dynamic range, and color accuracy. 

The characterization measurements are chosen to be practical and insightful about potential system errors. They are chosen to characterize key limitations based on knowledge of the circuit properties.

### Sensitivity:  Fill factor and back illumination
The pixels in electronic image sensors are quite small, on the order of $1 \text{ }\mu\text{m}^2$ on a side. Consequently, even using a favorable lens with a large aperture (e.g., f/# 2), we often have images that produce only a small number of photons are incident at the photodiode.  For example, in a dimly lit room we can expect no more than an average of 100 photons over an area of $1 \text{ }\mu\text{m}^2$. (See [this script](../code/fise_opticsCountingPhotons.html) for the ISETCam calculation.) The number photons will be Poisson distributed, so the standard deviation is 30!  That's not a very reliable signal.

Furthermore, the photodiode occupies only part of each pixel; the remaining area is taken up by circuitry that does not detect light. The proportion of the pixel area that is sensitive to light—the photodiode area—directly limits the pixel’s light sensitivity. This proportion is called the **fill factor**. A higher fill factor means more of the pixel is used to detect light, increasing sensitivity. Fill factor is usually expressed as a value between 0 and 1, or as a percentage between 0% and 100%.

The original CMOS image sensors were built with semiconductor technology with feature size on the order of 350 nm, and thus the circuitry might occupy as much as half of the pixel area (fill factor of 0.5).  Over years the feature size has shrunk considerably and the fill factor of modern pixels can be greater than 0.9. 

The original sensors were also built with a technology that included multiple metal layers.  The aperture that led down to the 



### Well capacity and dynamic range
The photodiodes and floating diffusion nodes serve as storage devices, often called **storage wells**. The capacity to store charge (electrons) in the 3T and 4T circuits is called the **well capacity** or **full-well capacity**, which is the maximum number of electrons that can be stored. If the number of photo-generated electrons exceeds the well capacity, the additional electrons cannot be stored and the output no longer increases with light intensity. Hence, the well capacity is an important number for determining the dynamic range of the sensitivity. It is an important factor that determines when the pixel stops encoding photons. 

The well capacity can also have an impact on the response characteristics of the sensor.  An estimate of the number of stored electrons as a function of number of incident photons, for a real sensor, is shown in @fig-sensor-responselinearity. The curve shows how the number of stored electrons increases over a large part of the range.  Initially, the electron count increases linearly.  After a certain level, as we approach the storage limit, the curve trails off and starts to saturate. Finally, as the light intensity increases even further, the curve completely saturates at the well capacity, in this case about 70,000 electrons.

![A CMOS sensor response curve, showing the number of electrons captured as a function of the number of incident photons.  From @Bohndiek2008-sensorlinearity, Figure 7.](images/sensors/03-responselinearity.png){#fig-sensor-responselinearity width=60%}.

### Response curve and nonlinearity
The relationship between the number of incident photons and the number of electrons stored in a pixel is not perfectly linear, especially as the pixel approaches its storage limit. At low and moderate light levels, nearly all photo-generated electrons are successfully stored in the well, resulting in a linear increase in stored charge with increasing light intensity. However, as the well nears its full capacity, several effects cause the response to become sublinear and eventually saturate.

First, when the storage well is almost full, some newly generated electrons cannot be stored and may leak out or recombine, reducing the efficiency of charge collection. Second, some electrons generated by photons may diffuse into neighboring regions of the sensor substrate rather than being stored in the intended circuit element (e.g., floating diffusion noise). Both leakage and diffusion become more significant at higher light intensities, causing the response curve to flatten out as it approaches saturation.

The exact onset and severity of this nonlinearity depend on the specific circuit design and material properties of the sensor. In practice, careful sensor design and calibration can minimize these effects, but some degree of nonlinearity is unavoidable as the well capacity is approached. Understanding the response curve is important for accurately interpreting sensor measurements, especially in applications that require high dynamic range or precise quantitative imaging.

### Temporal noise

Reset noise.
Readout noise.

### Dark current

### Fixed pattern noise
I don't want it called noise.  It is really variation, not noise.

DSNU dark signal nonuniformity

PRNU photoresponse nonuniformity

Temperature dependence of circuit and sensor noise.

Temperature variations can also affect the linearity of the sensor. Changes in temperature can alter the behavior of the photodiode and the associated circuitry, leading to temperature-dependent nonlinearities. Modern sensors often include compensation mechanisms to mitigate these effects, but residual nonlinearities may still remain.

## Circuit innovations

Over time, as technology has scaled, more complex electrical circuitry has been placed on the sensor. Modern image sensors frequently include circuitry that performs local processing to increase the dynamic range of the sensor (well recycling), or to reduce the intrinsic noise (correlated double sampling). Some of this processing is *adaptive*, that is the circuit actions depend on the property of the input image. Consequently, the sensor output can depend upon both the control parameters set by the user and the image content.

### Global shutter

Global shutter (with additional circuitry),

Instead of using a floating diffusion as a memory element, Aptina has utilized a surface-pinned storage node in the pixel
to address dark current challenges. Available in its newest global shutter sensor, the MT9M031, 
the storage node also enables using a true correlated double sampling technique to reduce readout noise to four electrons, resulting in excellent low-light performance. 
The combination of the effective use of an anti-reflective metal light shield in close proximity to the memory node and careful doping and potential profile design results in a high GSE.  
Global Shutter Pixel Technologies and CMOS Image Sensors – A Powerful Combination – (Aptina white paper)


### Dynamic range enhancement

Dynamic range extensions

Another source of nonlinearity arises from the photodiode itself. At high irradiance levels, the photodiode can saturate, meaning that it cannot generate additional electrons regardless of the incoming light. This saturation effect imposes a hard limit on the dynamic range of the sensor.

Understanding and modeling these nonlinearities is critical for applications that require high precision, such as scientific imaging or computational photography. Calibration techniques, such as measuring the sensor response under controlled conditions, can help correct for these nonlinearities in post-processing.