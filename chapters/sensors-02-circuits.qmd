# Circuits {#sec-sensors-circuits}
CMOS image sensors use a photodiode‚Äîand the photoelectric effect‚Äîto measure and store the optical light field at the sensor surface. The key technical breakthrough that enabled CMOS sensors was the integration of circuitry that stores and transmits the accumulated charge (number of electrons) from the photodiode to the computer. We can think of the photodiode and its local circuitry as a pixel. The logical flow of the circuitry is as follows:

* Before image capture, the circuitry resets each pixel to clear any residual charge from previous exposures.
* During image acquisition, the photodiode array collects electrons generated by incoming light; these electrons are stored within the photodiode or in a nearby capacitor.
* During readout, the circuitry transfers the stored charge to an analog-to-digital converter (ADC), where it is converted to a digital value.
* The resulting digital image array records the amount of light captured by each pixel.

CMOS circuitry is the main focus of this section (@sec-sensors-circuits). Most CMOS image sensors also include essential components such as color filter arrays and microlenses, which redirect light from the main lens onto each photodiode within the pixel. The following sections introduce these components and demonstrate how to simulate sensor performance. Section @sec-sensors-modeling uses ISETCam to model sensor performance, from the scene light field to image capture.

## 3T circuitry
The original CMOS pixel design uses a three-transistor (3T) circuit to store and read out the charge collected by the photodiode (@fig-sensor-3T-circuit). Each pixel contains three key transistors: $M_{rst}$ (reset), $M_{sel}$ (select), and $M_{sf}$ (source follower). The $M_{rst}$ transistor resets the photodiode by connecting it to the supply voltage (Vdd), clearing any residual charge before image capture. The $M_{sel}$ transistor selects a specific row of pixels, connecting them to the readout circuitry. The $M_{sf}$ transistor acts as a buffer, transferring the stored charge to the analog-to-digital converter (ADC) for measurement. In most sensors, each column has its own ADC, but some designs use a single ADC shared among multiple columns‚Äîa technique known as multiplexing (mux).

Ideally, the photodiode‚Äôs response to light is linear, with the number of generated electrons following Poisson statistics. However, the surrounding circuitry introduces additional sources of noise and nonlinearity. For example, the storage capacitor has a limited capacity, so it can saturate at high light levels. The transistors used for readout can also introduce noise and small nonlinearities. Furthermore, variations in pixel properties across the sensor array can cause fixed-pattern noise. In modern CMOS sensors, these nonlinearities and noise sources are typically small‚Äîon the order of a few percent @Wang2017-CMOSLinearity‚Äîbut they can still affect image quality. Careful characterization and calibration are necessary to minimize these effects and produce high-quality images.

![The original CMOS pixel used a 3-transistor (3T) circuit (@Fossum1997-early).](images/sensors/03-3T-circuit.png){#fig-sensor-3T-circuit}
<!-- 
 (http://encyclopedia2.thefreedictionary.com/Vdd also the drain voltage), Vrst is the reset voltage Vee is the negative supply voltage Ground is ground
http://en.wikipedia.org/wiki/Active_pixel_sensor , http://encyclobeamia.solarbotics.net/articles/vxx.html , 
http://en.wikipedia.org/wiki/Active_pixel_sensor , http://encyclobeamia.solarbotics.net/articles/vxx.html , 
Vdd is positive supply voltage  (http://encyclopedia2.thefreedictionary.com/Vdd also the drain voltage), Vrst is the reset voltage Vee is the negative supply voltage Ground is ground
-->

## 4T circuitry

Since around 2000, the three-transistor (3T) pixel design has been largely replaced by the four-transistor (4T) pixel circuit [@Fossum2014-pinnedpd]. The 4T architecture introduces a pinned photodiode (PPD) and adds a transfer gate transistor [@fig-sensor-4T-circuit]. The transfer gate moves the accumulated photo-generated charge from the photodiode to a nearby storage node known as the floating diffusion, which is associated with a capacitance denoted $C_{fd}$. 

Today, the 4T pixel is the standard in nearly all high-performance CMOS image sensors, including those used in smartphones, machine vision, automotive systems, and scientific imaging.

![The 4T pixel circuit introduces a pinned photodiode and an additional transistor. When activated, the new transistor transfers the accumulated charge from the photodiode to a storage capacitor (the floating diffusion node, $C_{fd}$). The rest of the circuit, including readout and row select, is similar to the 3T design.](images/sensors/03-4T-circuit.png){#fig-sensor-4T-circuit}

The 4T design offers several key advantages over the earlier 3T architecture. Most notably, it enables a technique called correlated double sampling (CDS), which significantly reduces reset noise (also known as $ùëòùëáùê∂$ noise). In the 4T pixel, the circuit first measures the voltage on the floating diffusion node before transferring charge from the photodiode (capturing a baseline), and then again after the charge is transferred. The difference between these two measurements represents the pixel signal. This subtraction cancels much of the noise introduced during the reset phase, improving signal-to-noise ratio.

Over time, further improvements in materials and circuit architecture have led to even lower noise and higher quantum efficiency. Additional innovations, such as dual conversion gain and advanced pixel structures, have also expanded the dynamic range of CMOS sensors. We will explore some of these developments after reviewing the basic pixel circuit and other key sensor components.

## Circuit innovations

Global shutter (with additional circuitry),

Dynamic range extensions

Another source of nonlinearity arises from the photodiode itself. At high irradiance levels, the photodiode can saturate, meaning that it cannot generate additional electrons regardless of the incoming light. This saturation effect imposes a hard limit on the dynamic range of the sensor.

Temperature variations can also affect the linearity of the sensor. Changes in temperature can alter the behavior of the photodiode and the associated circuitry, leading to temperature-dependent nonlinearities. Modern sensors often include compensation mechanisms to mitigate these effects, but residual nonlinearities may still remain.

Understanding and modeling these nonlinearities is critical for applications that require high precision, such as scientific imaging or computational photography. Calibration techniques, such as measuring the sensor response under controlled conditions, can help correct for these nonlinearities in post-processing.

Over time, as technology has scaled, more complex electrical circuitry has been placed on the sensor. Modern image sensors frequently include circuitry that performs local processing to increase the dynamic range of the sensor (well recycling), or to reduce the intrinsic noise (correlated double sampling). Some of this processing is *adaptive*, that is the circuit actions depend on the property of the input image. Consequently, the sensor output can depend upon both the control parameters set by the user and the image content.

## Well capacity

These capacitors have a finite capacity, which is called the **well capacity** or **full-well capacity**. The well capacity is simply the maximum number of electrons that can be stored in the capacitor before it saturates. When the number of photo-generated electrons exceeds the well capacity, the photodiode is saturated and its output no longer increases with increasing light intensity. This limits the dynamic range of the sensor and is an important consideration in sensor design and performance evaluation.

## Circuit noise