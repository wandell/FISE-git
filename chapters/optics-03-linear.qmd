# Optics and Linear Systems {#sec-optics-linear}
Geometric optics is valuable for understanding and characterizing many properties of optical systems. Its concepts are closely linked to the physical characteristics of lenses, making geometric optics especially useful in lens design.

Another perspective is to view an optical system from as a signal processing device:  it converts the radiation entering the aperture into radiation at the sensor surface. This approach treats the optics as mapping one spectral image (the incident light field) into another (the irradiance at the sensor). Thinking of the system in terms of signal processing is a powerful method for system simulation and analysis.

This perspective is particularly important because many optical systems are approximately linear. Specifically, they satisfy the **Principle of Superposition**, a property that can be tested experimentally. Linear systems are common in science and engineering, and we will encounter linear systems repeatedly throughout the book.

## Principle of Superposition
A system $L$ is linear if it satisfies the superposition rule:

$$
L(x + y) = L(x) + L(y).
$$ {#eq-superposition}

Here, $x$ and $y$ are two possible inputs, and $L(x)$ is the system's response to the input $x$. The input variable can be a scalar, vector, matrix, or tensor. For example, in an optical system, $x$ might represent the incident light field at the entrance aperture, and $L(x)$ could be the spectral irradiance measured at the sensor .

### Real-World Linearity 

No real system is perfectly linear over all possible signals. Extreme inputs with a massive amount of energy may behave unpredictably or even break! However, many systems are linear over an input range that covers all the likely use cases. 

### Local Linearity 
Some systems are only **locally linear**.  This means they behave linearly within a limited region, such as near a particular input $x_1$.  A system might be approximately linear in different ways depending on the input region. For example, the linear approximation near $x_1$ could be different from the one near $x_2$. This idea of local linearity is a fundamental concept in mathematics, physics, and engineering.[^taylor-series]

 [^taylor-series]: If you’ve seen the Taylor series expansion in calculus, you may recognize the principle of local linearity in mathematics!

### Principle of Homogeneity
A special case of superposition is **homogeneity**:

$$
L(\alpha x) = \alpha L(x)
$$ {#eq-homogeneity}

Homogeneity follows from superposition. For example, adding an input to itself:

$$\begin{aligned}
L(x + x) &= L(2x) \nonumber  \\ 
&= L(x) + L(x) \nonumber \\
&= 2L(x). \nonumber
\end{aligned}
$$

This generalizes to any integer $m$:

$$
L(m x) = m L(x).
$$

::: {.callout-note title="Extension to Rational Numbers" collapse="true"}

For real-valued systems that obey superposition, homogeneity holds for any rational number. If $\alpha = \frac{p}{q}$ is rational:

$$
L(\alpha x) = L\left(\frac{p}{q}x\right) = p L\left(\frac{x}{q}\right).
$$

Let $x' = x/q$, so

$$
L(x) = L(q x') = q L(x') \implies L(x') = \frac{1}{q} L(x).
$$

Therefore,

$$
L(\alpha x) = p L(x') = p \frac{1}{q} L(x) = \frac{p}{q} L(x) = \alpha L(x).
$$

To extend this to all real numbers, continuity is required. But for most engineering purposes, this is sufficient.
:::

It is important to note that a system can be homogeneous without being linear. For example, $f(x) = |x|$ and the vector length function

$$
f(\mathbf{x}) = \|\mathbf{x}\|_2 = \sqrt{x_1^2 + x_2^2 + \cdots + x_n^2}
$$

are homogeneous but not linear. The function $ReLU(x) = \max(0, x)$, widely used in neural networks, is also homogeneous for $\alpha > 0$ but not linear:

$$
1 = ReLU(2 + -1) \neq ReLU(2) + ReLU(-1) = 2 + 0.
$$


## Point spread functions

Linearity is a very imortant foundation for think about how optics turns an input scene into a sensor image. Imagine the scene as the intensity at a collection of points, each with its own intensity $I(\mathbf{p})$, where $\mathbf{p} = (p_x, p_y, p_z)$ is the location of each point in the scene. For each of these points, the optics spreads out the light in a certain way—this is called the point spread function, or $PSF_\mathbf{p}(x, y)$. Here, $(x, y)$ are positions in the image.

If we know all these point spread functions, and if the system is linear (so superposition holds), we can figure out what the image will look like for any scene. We just add up the contribution from every point in the scene. The formula looks like this:

$$
O(x, y) = \sum_{\mathbf{p}} I(\mathbf{p})\, PSF_\mathbf{p}(x, y)
$$ {#eq-pointspread-1}

Here, $O(x, y)$ is the brightness at each spot in the image. Each point in the scene sends out its own little blur, and the image is just the sum of all those blurs.

::: {.callout-note title="A limitation of PSFs" collapse="true"}
There’s a catch: in real scenes, objects can block each other (occlusion). That means the point spread from one spot might be blocked or changed by something else in the scene, so the formula above isn’t always perfect.

But if all the points are on a flat surface, or if everything is far away (so nothing blocks anything else), this approach works well. The main idea is that you can build up the whole image by adding up the point spreads from each part of the scene. It’s a great starting point for understanding how images form.
:::

## Shift-invariant linear systems
A practical limitation of characterizing a general linear systems is that it can have many different point spread functions - one for every point! But there are real systems that are much simpler. These systems have essentially the same point spread function across many points, with the only difference being that the point spread function is shifted. We say that the shape of the point spread function remains the same, apart from being shifted. We say such a system is **shift invariant**. 

The simplicity of shift invariance makes it a very useful tool, and some courses entitled 'linear systems' focus almost entirely on shift-invariant linear systems. Across the many branches of science and engineering, there are a large number of physical phenomena and engineering devices that are well-approximated as shift invariant linear systems. These systems are relatively straightforward to calibrate because we only need to estimate a single point spread function. Also, there are many computational tools that help us simulate shift invariant systems[^time-invariance].

[^time-invariance]: In imaging the point spread function is the key response.  In applications studying systems that are a function of time, the response to a short temporal response is the key response. These are called **impulse response** functions, and they are the equivalent of the point spread function in an imaging system. 

For some readers, a little mathematical notation may be useful. Suppose we write image translation as a function, $T()$. If we shift an image, $x$, by an amount, $\delta$, we write it as $T(x,\delta)$. A shift invariant system means that the output of a linear system, $L()$, to a translated image is the translated linear response

$$
L(T(x,\delta)) \approx T(L(x),\alpha \delta).
$$ {#eq-shiftinvariance-defined}

Notice that @eq-shiftinvariance-defined allows the size of the image shift, $\delta$, to differ from the size of the output shift, $\alpha \delta$. So if we displace an object by an amount $\delta \text{m}$, the image will be displaced by an amount $\alpha \delta \text{m}$ on the sensor. This scale factor depends on the image magnfication. 

The image formation component (optics) of most image systems are typically linear, but they are not globally shift-invariant. Rather, they are shift invariant over some part, but not all, of the full visual field. Usually there is a region near the optical axis that is shift invariant, and the system is also locally shift-invariant at off-axis points. This local shift invariance is similar to a system that is locally linear. In optics the shift invariant region is called an **isoplanatic** region. 

## Point spread functions

### The Airy pattern
The Airy pattern, introduced in @sec-airy-pattern and @fig-blur-comparison, is an example of an important point spread function.  That pattern is the response of a pinhole camera to a point of light, and it is also the pattern we expect an circularly symmetric, ideal (diffraction-limited) optical system.  The Airy pattern is a limit on the size of a point that is imaged given the $f/\#$ of a diffraction-limited optical system.

We wrote the formula for the size of the Airy disk in @eq-airy1 and showed an image of the point spread in @fig-blur-comparison. Because the system is circularly symmetric, the formula for the entire pattern, can be expressed with respect to just one variable, the radius from the center $r$. The intensity distribution $I(r)$ in the image plane for a system with $f/\# = N$, illuminated with monochromatic light of wavelength $\lambda$, is given by:

$$
I(r) = I_0 \left[ \frac{2 J_1\left( \frac{\pi r}{\lambda N} \right)}{ \frac{\pi r}{\lambda N} } \right]^2
$$

Where:

- $I(r)$: Intensity at radial position $r$ on the image plane  
- $I_0$: Maximum intensity at the center of the Airy pattern  
- $J_1$: First-order Bessel function of the first kind  
- $N$: The system's $f/\#$
- $\lambda$: Wavelength of the monochromatic light  
- $r$: Radial distance from the optical axis in the image plane  

Repeating @eq-airy1, but this time using the $f/\# = N$, the diameter of the first dark ring (minimum in intensity) is approximately:

$$
d = 2.44 \, \lambda N
$$

### Lorentzian (Cauchy)


### Gaussian


### Line spread functions

Relationship between point spread and line spread. psf2lsf easy, but to go back you need to assume something about the circular symmetry.

### Harmonics 
Almost eigenfunctions.  Not quite because of phase.  If we treat the harmonics as 2-dimensional vectors, then they are eigenfunctions.

### Optical Transfer Function

### Modulation Transfer

### Contrast sensitivity

## Chromatic aberration

This is already in, earlier.  Maybe an example here? Explain transverse and longitudinal chromatic aberration here? 





